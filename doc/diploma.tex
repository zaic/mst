\documentclass[a4paper,12pt]{extarticle}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}

\usepackage{graphicx}
%\graphicspath{ {./plots/} }

\usepackage{amsmath,amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{textcomp}
%\usepackage{expdlist}
%\usepackage{textpos}
\usepackage{cmap}

\usepackage{pgfplots}

%\usepackage[left=25mm,right=15mm,top=28mm,bottom=29mm]{geometry}

%\usepackage{algorithm}
%\usepackage{algpseudocode} % for \begin{algorithm}
\usepackage[lined,linesnumbered]{algorithm2e}

%\hoffset=-3cm
%\textwidth=18cm
%\voffset=-3cm
%\textheight=23cm

\date{}
\title{Сравнение вариантов алгоритма Борувки в задаче построения минимального остовного дерева\thanks{Работа поддержана Грантом Президента РФ для молодых учёных МК-3644.2014.9}}
\author{Зайцев Вадим, Новосибирский государственный университет, zaic101@gmail.com \\ 
Калгин Константин, ИВМиМГ СО РАН, kalginkv@gmail.com}

\usepackage{indentfirst}
\tikzset{every mark/.append style={scale=1.65}}
\pgfplotsset{compat=1.3}

% Поля и полуторный межстрочный интервал
\usepackage{setspace}
\usepackage[left=30mm,right=15mm,top=20mm,bottom=20mm]{geometry}
\onehalfspacing
% Начинать каждый раздел с новой страницы
\let\stdsection\section
\renewcommand\section{
    \newpage
    \stdsection
}

% add arbitrary notes
%\newcommand\blfootnote[1]{%
%  \begingroup
%  \renewcommand\thefootnote{}\footnote{#1}%
%  \addtocounter{footnote}{-1}%
%  \endgroup
%}

\begin{document}

\maketitle
%\newpage

\tableofcontents
%\newpage
%\blfootnote{Работа поддержана Грантом Президента РФ для молодых учёных МК-3644.2014.9}

\section*{Введение}

Задача обработки и анализа больших данных стоит повсеместно и возникает во множестве областей: известные поисковики, провайдеры, социальные сети, сотовые операторы, такие области науки как биоинформатика (обработка генов и генных сетей) \cite{graph-usage-bio} и многие другие.
Объёмы обрабатываемых данных составляют от десятков гигабайт до терабайт и выше в зависимости от области.
Такие данные зачастую представимы в виде графов, где вся необходимая информация хранится в вершинах и рёбрах или дугах графах и анализ таких данных сводится к классическим алгоритмам на графах.
Большие объёмы данных неизбежно ведут к тому, что размеры получаемых графов так же достаточно велики. В ряде работ исследуется проблематика получения эффективных параллельных реализаций алгоритмов на графах \cite{large-graph-0, large-graph-a, large-graph-b}.

В данной работе рассматривается задача построения минимального остовного дерева (minimum spanning tree --- MST) на мультипроцессоре с ccNUMA архитектурой.
В теории графов остовным деревом называется ацикличный связный подграф данного связного неориентированного  графа, в который входят все его вершины. 
Минимальным остовным деревом называется остовное дерево во взвешенном графе с минимальной суммой весов рёбер.
В случае, когда данный граф не является связным, для каждой компоненты будет построено своё остовное дерево и полученные деревья называются остовным лесом.

Минимальные остовные деревья имеют широкое практическое применение.
Они используются при построении различных сетей: коммуникационных линий, компьютерных сетей, транспортных сетей \cite{mst-usage-network}.
Так же они используются в задачах кластеризации \cite{mst-usage-cluster}, сегментации при обработке изображений \cite{mst-usage-image}, распознавании рукописного ввода \cite{mst-usage-handwrite}.
Минимальные остовные деревья  используются как приближённое решение переборной задачи: например, задачи Штейнера --- построение кратчайшей сети, соединяющей заданный конечный набор точек на плоскости \cite{shtree}.

% нормально описать дальнейшее содержание ???
В первой главе кратко представлен обзор существующих работ по последовательным и параллельным алгоритмам построения остовных деревьев.

Во второй главе Борувка
В третьей главе представлены основные техники оптимизации программ, который были использованы для получения максимальнйо производительности

И в конце будут представлено сравнение исследуемых алгоритмов.



%\newpage
\section{Обзор алгоритмов построения MST}
\label{sec:reviewSeq}

Существуют различные последовательные алгоритмы построения MST, наиболее распространёнными из которых являются алгоритмы Крускала, Прима и Борувки \cite{cormen}.
Не каждый из алгоритмов в его оригинальном варианте возможно эффективно распараллелить, однако, для некоторых из них существуют модификации, за счёт которых использование нескольких ядер одного узла кластера и даже использование нескольких узлов кластера может оказаться оправданным \cite{boruvka-prima,kruskal-parallel}.

\textbf{Алгоритм Крускала} строит остовное дерево в два этапа: сначала все рёбра графа сортируются в порядке неубывания веса (рёбра одинакового веса могут идти в произвольном порядке), затем рёбра последовательно обходятся и в остовное дерево добавляются те из них, которые не создают цикла.

Сортировка рёбер в общем случае может быть выполнена за время $O(E \cdot \log(E))$, проверка образования цикла для каждого ребра может быть реализована с помощью системы непересекающихся множеств и выполняться за время $O(\alpha(E))$, где $\alpha(E)$~---~обратная функция Аккермана, значения которой малы и, например, для тестируемых RMAT и SSCA2 графов, в которых количество рёбер составляет от 10 до 100 миллионов, не превосходят 5. Итоговая оценка времени работы получается $O(E \cdot \log(E) + E \cdot \alpha(E))$.

\textbf{Алгоритм Прима} начинает построение остовного дерева с произвольно выбранной вершины. Затем, пока дерево не будет построено полностью, выбирается ребро минимального веса, соединяющее вершину уже построенной части дерева с вершиной не из дерева, и выбранное ребро добавляется в строящееся остовное дерево.

Число шагов в алгоритме Прима равно числу вершин в графе. Время поиска ребра минимального веса на каждом шаге зависит от выбранной структуры данных: при использовании матрицы смежности для поиска минимального ребра потребуется просмотреть всю строку матрицы за линейное время, а при использовании кучи добавление и удаление каждого ребра будет происходить за логарифмическое время. 
Таким образом, алгоритм Прима возможно реализовать со временем работы $O(V^2)$, что является лучшей оценкой для полных графов, либо со временем $O(E \cdot \log(V))$, что более предпочтительно для разреженных графов.

\textbf{Алгоритм Борувки}.
Это итерационный алгоритм: изначально каждая вершина графа считается отдельной компонентой, затем на каждой итерации для каждой компоненты находится инцидентное ей ребро, соединяющее её с другой компонентой, минимального веса и по найденным рёбрам компоненты объединяются. Алгоритм работает до тех пор, пока не останется одна компонента и пока между имеющимися компонентами есть рёбра.

На каждой итерации алгоритма множество компонент уменьшается не менее, чем в два раза, следовательно количество итераций можно оценить сверху как $\lceil \log_2(V) \rceil$. На каждой итерации в худшем случае необходимо просмотреть все рёбра, при этом процедура обработки одного ребра достаточно простая (определение каким компонентам принадлежат инцидентные вершины и, возможно, обновление рекорда для данных компонент). Итоговая временная сложность получается $O(E \cdot \log(V))$.

\subsection{Параллельные алгоритмы}
\label{subsec:reviewParallel}

С точки зрения параллелизма про алгоритмы Крускала и Прима можно сказать следующее:
\begin{itemize}
	\item они состоят из большого количества шагов, которые зависимы между собой и не могут исполняться параллельно
	\item вычислительная сложность одного шага достаточно маленькая и её распараллеливание будет неэффективно
\end{itemize}
Это делает распараллеливание данных алгоритмов в оригинальном варианте бесперспективным. 

Исключением является реализация алгоритма Прима для плотных графов с обновлением матрицы смежности вместо использования кучи: в этом случае сложность одного шага составляет $O(V)$ и его возможно распараллелить, разделив матрицу между потоками.
Однако, не для плотных графов такой подход асимптотически хуже других алгоритмов и при распараллеливании даже на большое число вычислителей будет медленнее последовательных реализаций других алгоритмов на больших графах.

В то же время алгоритм Борувки обладает противоположными свойствами:
\begin{itemize}
	\item количество итераций небольшое
	\item вычислительная сложность одной итерации большая и может быть распределена между потоками
\end{itemize}
Это делает алгоритм Борувки наиболее пригодным для распараллеливания и в перспективе может дать хорошую масштабируемость.

В статьях \cite{dense-mst,boruvka-prima,boruvka-cm5} представлены различные варианты параллельных реализаций алгоритма Борувки.
Разные реализации используют разные структуры данных для хранения рёбер (хранение рёбер одним большим списком или хранение для каждой вершины списка инцидентных ей рёбер) и разные способы их объединения (слияние и копирование списков, объединение списков за константное время и т. д.).
В разделе \ref{sec:boruvkaIntro} представлен анализ существующих и разработка нового варианта параллельного алгоритма Борувки.

В статье \cite{boruvka-prima} представлен параллельный алгоритм построения MST на основе последовательного алгоритма Прима.
Суть данного алгоритма заключается в том, что каждый поток выбирает случайную вершину в графе и начинает ``растить'' дерево из выбранной вершины, пока не попытается присоединить вершину, уже принадлежащую другому дереву, после чего два дерева встретившихся потоков объединяются, один из них продолжает ``растить'' объединённое дерево, а второй заново выбирает вершину графа. % TODO перечитать их алгоритм
К преимуществам данного подхода относится отсутствие барьерной синхронизации, которая требуется в алгоритме Борувки после каждой итерации и, в зависимости от реализации, между разными шагами одной итерации. Другим преимуществом перед алгоритмом Борувки является то, что каждое ребро будет просмотрено ровно один раз. Более детально анализ параллельного алгоритма Прима представлен в разделе \ref{subsec:algoPrim}.

В статье \cite{kruskal-parallel} представлен параллельный алгоритм построения MST на основе алгоритма Крускала.
Как и в параллельном алгоритме Прима, основная идея заключается в том, что каждый поток независимо строит часть дерева, затем деревья, полученные разными потоками, объединяются.
Схема предложенного параллельного алгоритма Крускала следующая: на первом шаге множество вершин графа разбивается между потоками и каждый поток строит остовное дерево последовательным алгоритмом Крускала на том множестве рёбер, у которых хотя бы одна из двух инцидентных  вершин принадлежит выбранному множеству вершин для данного потока. На последующих шагах выбирается два любых дерева и строится новое остовное дерево на множестве рёбер, равное объединению данных деревьев, до тех пор, пока не останется одно дерево. Полученное дерево и будет минимальные остовным деревом данного графа. Более подробное описание алгоритма представлено разделе \ref{subsec:algoKruskal}.
%Заметим, что объединение всех деревьев, полученных на первом шаге, является надмножеством итогового остовного дерева, поэтому на последующих шагах уже не рассматриваются рёбра, не вошедшие ни в одного из деревьев.
%В то же время, нельзя просто объединить все деревья, полученные на первом шаге, т. к. скорее всего, в полученный простым объединением рёбер граф будет содержать циклы, для исключения которых и требуются следующие шаги алгоритма.

\section{Варианты алгоритма Борувки}
\label{sec:boruvkaIntro}

В данных работах \cite{dense-mst,boruvka-prima,boruvka-cm5} результаты производительности показаны либо для старых архитектур \cite{dense-mst,boruvka-cm5}, либо масштабируемость была ограничена шестью одноядерными процессорами (SMP  UMA, UltraSPARC II) \cite{boruvka-prima}.

Настоящая работа направлена на адаптацию существующих и реализацию новых алгоритмов, ориентированных на высокую эффективность на больших графах на современных вычислителях с общей памятью с ccNUMA архитектурой.
Исследование началось с реализаций, предложенных в статье \cite{boruvka-prima}, а также их модификаций. Затем, в разделе \ref{subsec:BoruvkaEA} на основе сделанных выводов будет предложен собственный подход к хранению графа в алгоритме Борувки.

В частности, далее будут представлены результаты тестирования описанных реализаций на двухсокетной системе $2$~$\times$~Intel Xeon CPU E5-2690 (8 ядер 2.9 GHz, 32KB L1 cache, 256KB L2 cache, 20MB L3 cache). Производительность полученных реализаций будет показана в MTEPS~---~величине, обратно пропорциональной времени. Более подробно об используемом окружение и замерах времени описано в разделе \ref{sec:results}.

\subsection{Списки смежности (Adjacency Lists --- AL)}
\label{subsec:boruvkaAL}

Первый вариант алгоритма Борувки для хранения графа использует списки смежности для каждой компоненты. Изначально каждая компонента представлена одной вершиной и её список смежности совпадает со списком смежности вершины, затем после каждой итерации для каждой образовавшейся компоненты явно строится список всех рёбер, инцидентных данной компоненте.
В качестве списков может быть использована любая структура данных, позволяющая последовательно обходить элементы. В данном подходе использовались динамически выделяемые массивы.

Изначально множество вершин графа разделяется между потоками равномерно по количеству инцидентных вершинам рёбер.
Далее на каждой итерации алгоритма Борувки выполняются следующие шаги, пока не останется одна компонента или между несколькими оставшимися компонентами не будет рёбер:
\begin{enumerate}
    \item \textbf{Минимальное инцидентное ребро}.
        Каждый поток для каждой своей компоненты находит инцидентное ей ребро минимального веса. Это делается последовательным обходом всех инцидентных компоненте рёбер.
    \item \textbf{Объединение деревьев}.
        Компоненты объединяются по найденным рёбрам: выделяются образовавшиеся компоненты, для каждой такой компоненты определяется номер на следующей итерации.
        В качестве номера компоненты используется номер одной из вершин, входящих в данную компоненту.
        Так же решается проблема с возможными циклами (когда более двух компонент по кругу выберут следующую компоненту в качестве ближайшей), которые возможны в алгоритме Борувки при наличии в графе рёбер одинакового веса.
    \item \textbf{Перенумерация компонент}.
          Осуществляется перенумерация компонент: для каждой вершины вычисляется номер компоненты, в которую она входит, используя параллельный алгоритм Pointer Jumping \cite{pointer-jumping}. 
    \item \textbf{Слияние списков}.
        Происходит объединение компонент путём слияния списка рёбер. В модификации с неотсортированными списками рёбер слияние делается последовательным копированием одного списка в другой. При использовании отсортированных по весу списков вместо копирования и последующей сортировки рёбер происходит слияние с использованием приёма, который используется в сортировки слиянием: из голов копируемых списков выбирается минимальный элемент, извлекается и добавляется в создаваемый список.
\end{enumerate}

На шаге \textbf{объединение деревьев} требуется выделять образовавшиеся компоненты связности в неориентированном графе.
Существуют различные алгоритмы, как последовательные так и параллельные, с помощью которых возможно выделение таких компонент. 
Наиболее используемые последовательные алгоритмы~---~это поиск в ширину и в глубину, гарантирующие линейное от числа рёбер время работы.
Среди параллельных для выделения компонент связности используют как различные подходы к распараллеливанию обхода в ширину \cite{bfs-parallel}, так и изначально разработанные под многоядерную архитектуру алгоритмы \cite{comp-parallel-a, comp-parallel-b}.
Изначально использовался обход графа в ширину, который затем был распараллелен.
Затем была взята во внимание особенность графа, на котором происходит выделение компонент.
По итогам шага \textbf{минимальное инцидентное ребро} для каждой компоненты есть ``ссылка'' на другую компоненту, в которую ведёт минимальное ребро.
Есть это представить как ориентированный граф, то в получившемся графе не будет циклов за исключением тех пар компонент, которые ссылаются друг друга, при этом все остальные компоненты имеют ровно одну исходящую дугу и переходя по таким дугам путь закончится в одной из этих двух вершин.
Задачу поиска компонент на таком графе можно свести к тому, чтобы для каждой компоненты выяснить в какую именно вершину мы в итоге попадём, переходя по дугам, и компонентой будут все вершины, которые в итоге перейдут в одну и ту же вершину.
Описанную задачу решает используемой в шаге \textbf{перенумерация компонент} параллельный алгоритм Pointer Jumping с модификацией, позволяющей отлавливать описанного рода циклы длины 2.
% немного криво, но ладно

Важной особенностью алгоритма Борувки является то, что при наличии рёбер одинакового веса возможно появление циклов, которых необходимо избегать.
Самым простым примером цикла является полный граф из трёх вершин, где все рёбра имеют одинаковый вес.
Так, если для первой вершины минимальным будет выбрано ребро, ведущее во вторую, для второй~---~в третью, а для третьей~---~в первую, то получившийся цикл алгоритм будет считать частью остовного дерева, что на самом деле не так.
Такие циклы можно пытаться явно выделять (например, с помощью обхода в глубину) и удалять из них одно любое ребро.
Однако, в реализации был выбран другой подход, заранее предотвращающий появление петель: использовать для сравнения рёбер не только вес, но и индексы инцидентных вершин.
Так, если при равенстве веса считать меньшим ребром то, у которого минимальный из индексов инцидентных вершин меньше, а при равенстве минимальных индексов сравнить максимальный индекс, то равными могут быть только кратные рёбра одинакового веса.
Но кратные рёбра не создают проблемы, описанной выше, а значит только сравнение рёбер вполне допустимо для избежания петель.

Были опробованы два подхода относительно сортированности списков смежности:
\begin{itemize}
    \item \textbf{Отсортированные по весу списки смежности}. 
        Отсортированные списки позволяют осуществлять шаг \textbf{минимальное инцидентное ребро} за константное время, просмотрев лишь голову списка, однако поддержание таких списков сортированными на шаге \textbf{слияния списков} требует дополнительного времени.
    \item \textbf{Неотсортированные списки смежности}.
        Когда поддержание списков отсортированными не требуется, их объединение возможно осуществлять простым копированием памяти, но поиск по неотсортированному списку возможен только за линейное время.
\end{itemize}

На практике подход с сортировкой списков по весу оказался заметно медленнее. 
На рисунке \ref{fig:BorvukaAlCmp} показано сравнение производительности обоих подходов на RMAT и SSCA2 графах: реализация со слиянием отсортированных списков обозначена как AL-Merge, реализация с копированием неотсортированных списков~---~AL-Copy. Подробное описание графов, на которых проводилось тестирование, приведено в разделе \ref{sec:results}.

В  подходе со списками смежности имеется две существенные проблемы. 
Первая из них заключается в том, что на шаге \textbf{слияния списков} происходит копирования большого объёма данных и этот шаг исполняется долго.
Вторая проблема лежит в том, что при распределении компонент между потоками на шагах \textbf{минимальное инцидентное ребро} и \textbf{слияния списков} происходит дисбаланс нагрузки на последних итерациях, когда количество оставшихся компонент становится меньше числа потоков~---~в этом случае некоторые потоки просто простаивают без работы, что негативно сказывается на масштабируемости алгоритма.

Другой проблемой, которая так же приводит к дисбалансу нагрузки, является неравномерное распределение рёбер между потоками после первой итерации.
При объединении нескольких компонент в одну необходимо выбрать какому из потоков будет принадлежать образовавшаяся компонента.
Изначально такой выбор делался случайно среди тех потоков, которым принадлежала хотя бы из объединяемых компонент.
Но такой подход уже спустя две-три итерации приводил к большой разнице между количеством рёбер у разных потоков.
Случайный выбор был заменён на выбор того потока, у которого на данный момент меньше всего рёбер. Такой просто алгоритм балансировки показал хорошие результаты на практике и дисбаланс, вызванный описанной проблемой, был  устранён.

% ширина первого графика ???
\noindent \begin{figure}
\centering
\begin{tikzpicture}
\begin{semilogxaxis}[
    width = 0.45\textwidth,
    legend pos = north west,
    title = RMAT-22-32,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{ 
    AL-Merge, 
    AL-Copy, 
};
\addplot[mark=square] coordinates {
    ( 1, 1.85243)
    ( 2, 0.96154)
    ( 4, 2.34898)
    ( 8, 3.12591)
    (16, 4.84673)
};
\addplot[mark=square*] coordinates {
    ( 1,  6.24148) 
    ( 2, 10.68033) 
    ( 4, 16.07276) 
    ( 8, 18.84003) 
    (16, 22.17363)
};
\end{semilogxaxis}
\end{tikzpicture}
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = SSCA2-22,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{ 
    AL-Merge, 
    AL-Copy, 
};
\addplot[mark=square] coordinates {
    ( 1, 5.50553) 
    ( 2, 2.93712) 
    ( 4, 4.78015) 
    ( 8, 5.19576) 
    (16, 5.96613)
};
\addplot[mark=square*] coordinates {
    ( 1, 12.73893) 
    ( 2, 19.93157) 
    ( 4, 28.35076) 
    ( 8, 37.20304) 
    (16, 35.71294)
};
\end{semilogxaxis}
\end{tikzpicture}
\caption{Сравнение производительности реализаций алгоритма AL}
\label{fig:BorvukaAlCmp}
\end{figure}

\subsection{Списки вершин (Vertexes lists --- VL)}
\label{subsec:boruvkaVL}

В качестве решения первой проблемы предыдущего алгоритма~---~большого объёма копируемых данных после каждой итерации~---~списки смежности каждой компоненты были заменены на список входящих в неё вершин. Во-первых, такая модификация минимально влияет на другие шаги алгоритма. Во-вторых, на шаге \textbf{слияния списков} это позволяет в несколько раз сократить размер объединяемых списков.

Общая схема алгоритма осталась прежней со следующими изменениями:
\begin{enumerate}
    \item На шаге \textbf{минимальное инцидентное ребро} теперь для обхода рёбер требуется обойти не список рёбер, а список входящих в компоненту вершин и уже для каждой вершины обойти список инцидентных ей рёбер.
    \item На шаге \textbf{слияние списков} теперь копируются не списки рёбер, а списки вершин, что значительно сокращает объём перемещаемых данных.
\end{enumerate}

Для хранения списка вершин были опробованы две структуры данных:
\begin{itemize}
	\item \textbf{Односвязные списки}. Их преимущество заключается в возможности объединения за константное время, однако, обход таких списков связан со случайными обращениями в память.
	\item \textbf{Динамические массивы}. Объединение массивов возможно только за линейное время путём копирования одного из них в другой (на практике используется копирование меньшего массива в больший). Но во время обхода массива хорошо работает аппаратная предвыборка, что позволяет в значительной степени избежать кэш-промахов.
\end{itemize}

В качестве решения второй проблемы~---~дисбаланс на последних итерациях~---~шаг \textbf{минимальное инцидентное ребро} был разделён на два: сначала выделяются компоненты с небольшим количеством входящих в них вершин и обрабатываются как и раньше. Затем остаётся несколько компонент, состоящих из большого числа вершин, и работа по таким компонентам уже разделяется между потоками: каждый поток обрабатывает свою часть вершин, находит среди них минимальное ребро и в конце по всеми потокам находится итоговое ребро минимального веса.

На рисунке \ref{fig:BorvukaVLCmp} отображено сравнение производительности обоих описанных подходов: с использованием односвязных списков (график VL-List) и с использование динамических массивов (график VL-Vec).
Для реализации на векторах так же показано её сравнение с оптимизацией (график VL-Vec-Bal), устраняющей дисбаланс и без неё: как видно из графиков, это заметно увеличило производительность и сделало подход более масштабируемым. 
Для реализации на связных списках применить описанную оптимизацию в простом варианте не удастся, поскольку при делении списка между потоками требуется обращение к произвольному элементу списка, чего односвязные списки в простой реализации дать не могут.

\noindent \begin{figure}
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = RMAT-22-32,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{ 
    VL-List, 
    VL-Vec, 
    VL-Vec-Bal,
};
\addplot[mark=o] coordinates {
    ( 1, 15.20612) 
    ( 2, 23.01885) 
    ( 4, 31.61637) 
    ( 8, 38.83494) 
    (16, 35.44427)
};
\addplot[mark=otimes] coordinates {
    ( 1, 21.67135) 
    ( 2, 32.05475) 
    ( 4, 43.63822) 
    ( 8, 50.64322) 
    (16, 37.67731)
};
\addplot[mark=*] coordinates {
    ( 1,  38.68442) 
    ( 2,  67.44000) 
    ( 4, 107.80270) 
    ( 8, 127.65239) 
    (16, 124.82685)
};
\end{semilogxaxis}
\end{tikzpicture}
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = SSCA2-22,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{ 
    VL-List, 
    VL-Vec, 
    VL-Vec-Bal,
};
\addplot[mark=o] coordinates {
    ( 1,  18.38560) 
    ( 2,  31.13012) 
    ( 4,  52.10441) 
    ( 8,  81.05828) 
    (16, 104.69502)
};
\addplot[mark=otimes] coordinates {
    ( 1, 20.33189) 
    ( 2, 32.75858) 
    ( 4, 52.16497) 
    ( 8, 65.35815) 
    (16, 56.73738)
};
\addplot[mark=*] coordinates {
    ( 1,  43.58621) 
    ( 2,  74.22150) 
    ( 4, 114.29355) 
    ( 8, 127.98270) 
    (16, 114.87867)
};
\end{semilogxaxis}
\end{tikzpicture}
\caption{Сравнение производительности реализаций алгоритма VL}
\label{fig:BorvukaVLCmp}
\end{figure}

\subsection{Массив рёбер (Edges Array --- EA)}
\label{subsec:BoruvkaEA}

Поскольку за счёт предыдущей модификации полностью решить проблему копирования больших объёмов данных не удалось, то следующий алгоритм разрабатывался с целью полностью избежать перемещения списков рёбер или вершин после каждой итерации.
Если ранее использовался подход, когда для каждой компоненты хранилась информация, позволявшая восстановить список инцидентных рёбер, то теперь будет использоваться информация для каждой вершины о том, какой компоненте она принадлежит.

Изначально все вершины распределяются между потоками равномерно по количеству рёбер. Далее на каждой итерации алгоритма Борувки выполняются следующие шаги:

\begin{enumerate}
    \item \textbf{Минимальное инцидентное ребро}.
		Каждый поток обходит все свои вершины и находит минимальное ребро для всех компонент, которые представлены в данном потоке хотя бы одной вершиной.
        В результате каждый поток будет иметь массив, содержащий минимальное ребро для каждой компоненты среди просмотренного подмножества.
    \item \textbf{Редукция}.
          Происходит редукция полученного на предыдущем шаге массива: для каждой компоненты находится ребро минимального веса по всем потокам. 
          Таким образом, для каждой компоненты определяется минимальное ребро уже во всём графе.
    \item \textbf{Объединение деревьев}.
          Для каждой компоненты определяется её номер на следующей итерации.
          Так же решается проблема с возможными циклами (когда более двух компонент по кругу выберут следующую в качестве ближайшей), которые возможны в алгоритме Борувки при наличии рёбер одинакового веса.
    \item \textbf{Перенумерация}.
          Осуществляется перенумерация компонент: для каждой вершины вычисляется номер компоненты, в которую она входит, используя параллельный алгоритм Pointer Jumping \cite{pointer-jumping}.
\end{enumerate}

Основная проблема данного подхода заключается в шаге \textbf{редукции}: объём редуцируемого массива растёт линейно с ростом числа потоков, таким образом, среднее время выполнения данного шага почти не уменьшается с ростом количества потоков.
Однако, даже с описанной проблемой подход с уменьшением объёма копируемых данных себя оправдал и данный подход показала лучшие результаты производительности среди описанных алгоритмов.
Далее будут подробно рассмотрены оптимизации, применённые к данному подходу хранения графа.

%\newpage
\section{Оптимизации алгоритма EA}
\label{sec:eaopt}

\subsection{Алгоритмические оптимизации}
\label{subsec:optAlgo}

\textbf{Предварительная сортировка рёбер.}
Алгоритм Борувки предполагает на каждой итерации просмотр всех рёбер графа, что и создаёт наибольшую вычислительную сложность первого шага.
Объём ``лишней'' работы при этом достаточно велик: 
во-первых, постоянно будет просматриваться большое количество петель (рёбер, которые на данной итерации соединяют компоненту саму с собой), которых с каждой итерацией становится всё больше и больше, 
во-вторых, при обходе рёбер на шаге \textbf{поиска минимального ребра} хотелось бы уменьшить количество просматриваемых рёбер за счёт пропуска тех, вес которых уже больше, чем рекорд для текущей компоненты.

Проблему с петлями возможно попытаться решить их удалением, однако, это повлечёт за собой частичное перестроение внутреннего представления графа, что, как было выявлено в ходе исследования, негативно сказывается на производительности.

Решить обе обозначенные проблемы возможно за счёт предварительной сортировки списков смежности каждой вершины по возрастанию веса рёбер. Затем для каждой вершины поддерживается индекс последнего просмотренного ребра: изначальной данный индекс указывает на первое ребро в списке, затем, по мере отбрасывания петель, он сдвигается и на следующей итерации поиск минимального ребра начинается не с начала списка, а с позиции, на которую указывает индекс. С другой стороны, если мы берём очередное ребро и его вес больше, чем текущий рекорд для компоненты, то поиск можно прервать, так как вес последующих рёбер данной вершины заведомо больше текущего рекорда.

Данная оптимизация хорошо масштабируется и на большом количестве потоков время выполнения сортировки невелико. В среднем производительность от данной оптимизации увеличивается на 20\%.



\textbf{Перенумерация вершин.}
В работе \cite{sparse-matrix-renum} предлагается алгоритм перенумерации вершин, который повышает локальность данных при последующих обходах графа, за счёт чего уменьшается количество кэш-промахов. 
Предложенный алгоритм перенумеровывает вершины в порядке обхода в ширину с предварительной отсортировкой списков смежности каждой вершины по возрастанию степени вершины, в которую ведёт ребро.


\textbf{Балансировка больших вершин.}
Одной из особенностей RMAT-графов являет наличие вершин, степень которых значительно отличается от средней степени всех вершин графа. Например, в RMAT-графе с $2^{20}$ вершинами есть 1351 вершина степени выше 1000, а максимальная степень вершины достигает 15078, при этом средняя степень вершины равна 32. Такие вершины создают дисбаланс на последних итерациях, когда просматривается большое количество рёбер и отбрасываются петли.

С целью устранения данного дисбаланса на стадии предварительно обработки графа выделяются вершины степени более 1000 и равномерно распределяются между потоками. Значение степени 1000 было подобрано эмпирически и хорошо показало себя на практике.

В среднем оптимизации \textbf{перенумерация вершин} и \textbf{балансировки больших вершин} дают увеличение производительности в 11\%.



\textbf{Отдельный цикл пропуска петель.}
Шаг \textbf{поиск минимального ребра} с учётом оптимизации \textbf{предварительной сортировки рёбер} выглядит следующим образом:

\begin{algorithm}[H]
    \SetAlgoLined
    \KwData{ $v$ --- индекс обрабатываемой вершины }
%    \KwData{ $component[]$ --- массив компонент }
    $myComp \gets component[v]$\;
    \ForEach{$edgeId$ $\gets$ $edgesIdsBegin[v]$ \textbf{to} $edgesIdsEnd[v]$}{
        $destVertex \gets edges[edgeId].destination$\;
        $destComp \gets component[destVertex]$\;
        \lIf{$destComp = myComp$}{ перейти к следующей итерации }
        \lIf{$edges[edgeId] < currentRecord[myComp]$}{ $currentRecord[myComp] \gets edges[edgeId]$ }
        закончить цикл\;
    }
\end{algorithm}

Б\`oльшая часть времени исполнения цикла находится в строках 2-5 и заключается в пропуске петель до тех пор, пока не найдётся ребро, ведущее в другую компоненту. Явное вынесение этих строк в отдельный цикл и разбиение цикла на две части ведёт к тому, что более простой цикл исполняется быстрее:

\begin{algorithm}[H]
    \SetAlgoLined
    \KwData{ $v$ --- индекс обрабатываемой вершины }
    $myComp \gets component[v]$\;
    $edgeId \gets edgesIdsBegin[v]$\;
    \While{$edgeId \neq edgesIdsEnd[v]$ \textbf{and} $component[edges[edgeId].destination]$ = $myComp$}{
        $edgeId \gets edgeId + 1$\;
    }
    \If{$edges[edgeId] < currentRecord[myComp]$}{
        $currentRecord[myComp] \gets edges[edgeId]$
    }
\end{algorithm}

В среднем данная оптимизация ведёт к увеличению производительности на 10\%.


\subsection{Оптимизация редукции}
\label{subsec:optReduction}

Поскольку основные проблемы масштабируемости лежат именно в шаге \textbf{редукции}, то было сделано несколько оптимизаций, непосредственно затрагивающих данный шаг. 
Приведённые оценки увеличения производительности получены при запуске 32 потоков на всех 16 ядрах процессоров (исполнялось по 2 потока на одно ядро, поскольку в процессоре была включена технология Hyper Threading, использование которой описано далее в разделе \ref{subsec:optArch}) и показывают ускорение не одного только шага \textbf{редукции}, а исполнения всего алгоритма.

\textbf{Отсутствие редукции на первой итерации.}
Поскольку каждая компонента изначально представлена одной вершиной, то от редукции на первой итерации можно отказаться. Данная оптимизация выглядит простой и очевидной, однако, объём редуцируемого массива на первой итерации больше, чем на всех последующих, и данная модификация даёт ускорение в 20\%.

\textbf{Перенумерация и сжатие массива компонент по ходу исполнения алгоритма.}
В начальной реализации при объединении компонент в одну в качестве её номера выбирался один из номеров вершин, которые в неё входят. Таким образом, несмотря на сокращение числа компонент, диапазон используемых номеров не изменялся (минимальный и максимальный номер были приблизительно равны соответственно первой и последней вершине). Такой подход затруднял обход всех компонент на шаге редукции: требовалось либо обходить весь диапазон номеров и совершать лишнюю работу, просматривая ``пустые'' номера, не являющиеся компонентами, либо отдельно поддерживать массив, в которым хранить индексы всех ``живых'' на данный момент компонент, что усложняло реализацию и приводило бы к увеличению кэш-промахов из-за обхода массива с непостоянным шагом.

Явная перенумерация компонент на каждой итерации на последовательные номера позволила решить обозначенную проблему. В среднем производительность увеличилась на 20\%.

%Более того, это позволило уменьшить объём используемой памяти: в начальной реализации для каждого потока создавался двумерный массив размера \texttt{количество\_потоков}$\times$\texttt{количество\_вершин}
%На системах с больш\`{и}м количеством ядер, например, на Intel Xeon Phi, где используется до 240 потоков, объём такого массива заметно превосходит объём всех других данных и его сокращение в 2 раза приводит к значительному уменьшению потребляемой памяти (описать про память более понятно).
%подумать и, возможно, вернуть 

\textbf{Иерархическая редукция.}
Особенностью NUMA архитектуры являются высокие задержки при обращении в память другого узла NUMA.
При стандартном подходе к редукции, когда для каждой компоненты последовательно обходятся все потоки и выбирается лучший результат, таких обращений при двух NUMA узлах будет как минимум половина, а при большем количестве узлов NUMA~---~ещё больше. 
Долю обращений к другому узлу NUMA среди всех обращений в память можно оценить как
$$ \frac{\texttt{число NUMA узлов - 1}}{\texttt{число NUMA узлов}}$$
Ещё одним фактором, увеличивающим время доступа в память другого узла NUMA является то, что на системах с более чем 4 сокетами не каждая пара сокетов связана между собой шиной напрямую и передача данных между ними производится через другие сокеты.

Данную проблему можно решить за счёт иерархического подхода к редукции. При таком подходе шаг редукции разбивается на два этапа: на первом происходит стандартная редукция внутри NUMA узла, а на втором~---~между узлами. Количество обращений к чужому узлу NUMA в этом случае уменьшается в количество раз, равное количеству используемых потоков в одном узле NUMA. Иерархическая редукция повысила производительность на 5\%.
%Может, добавить красивую картинку. Нет, без картинки.

%\textbf{Сообщения в редукции.}
%В редуцируемом массиве много пустых элементов. Через сообщения можно уменьшить объём редуцируемых данных.

\subsection{Архитектурные оптимизации}
\label{subsec:optArch}

\textbf{Программная предвыборка.}
Обход рёбер в общем случае неизбежно связан со случайными обращениями в память: невозможно отсортировать рёбра так, чтобы индексы обеих инцидентных вершин шли последовательно.
Аппаратная предвыборка современных процессоров ориентирована только на последовательные обращения в память (на обход с постоянным, возможно отрицательным, шагом, размер которого не превосходит размер страницы памяти) и подобный обход рёбер вызывает простои, связанные с ожиданием данных.

Однако, адреса случайных обращений в память при таких обходах в большинстве случаев можно предсказать: обходя рёбра последовательно, нам известны индексы обеих инцидентных вершин вершин для следующих итераций цикла.
Как раз в таком случае и помогает программная предвыборка, давая возможность заранее запросить нужные данные для будущих вершин (например, какой компоненте они принадлежат) и сократить время ожидания.

В среднем программная предвыборка позволила повысить производительность на 30\%, а шаг \textbf{перенумерация вершин}, где используется алгоритм Pointer Jumping, ускоряется до 2-3 раз. 

Иногда в одном цикле целесообразно использование программной предвыборки для двух массивов с разным шагом. Так, в коде шага \textbf{поиска минимального ребра}:

\begin{algorithm}[H]
    \SetAlgoLined
    \For{$vertexId$ $\gets$ $1$ \textbf{to} $vertexCount$}{
    	$edgeId \gets startEdge[vertexId]$\;
	    $destComp \gets component[edges[edgeId].destination]$\;
   	    \ldots
    }
%    \caption{возможно, данный заголовок стоит выпилить}
\end{algorithm}
предвыборка для переменной $edgeId$ делается достаточно легко, а вот переменная $destComp$ зависит от значения $edgeId$ и прежде, чем будет возможно сделать предвыборку для $destComp$, необходим получить значение $edgeId$.
Предвыборки для обеих переменных без лишних простоев возможно реализовать, делая их с разным шагом: если предвыбирать $edgeId$ с удвоенным шагом относительно $destComp$, то обе предвыборки не будут зависеть друг от друга:

%\begin{algorithm}[H]
%    \SetAlgoLined
%    \For{$vertexId$ from $1$ to $vertexCount$}{
%    	$prefetch(\&component[edge[startEdge[vertexId + prefetchStep]].dest])$\;
%    	$edgeId \gets startEdge[vertexId]$\;
%	    $destComp \gets component[edges[star%tEdge].dest]$\;
%   	    \ldots
%    }
%    \caption{возможно, данный заголовок стоит выпилить}
%\end{algorithm}ты описал, что бе

%Однако, здесь адрес второй предвыборки зависит от случайного обращения к элементу $edge[startEdge[vertexId + prefetchStep]$ и более эффективным будет заранее загрузить в кэш данный элемент:

\begin{algorithm}[H]
    \SetAlgoLined
    \For{$vertexId$ $\gets$ $1$ \textbf{to} $vertexCount$}{
	    $prefetch(\&edge[startEdge[vertexId + prefetchStep \times 2]])$\;
    	$prefetch(\&component[edge[startEdge[vertexId + prefetchStep].dest]])$\;
    	$edgeId \gets startEdge[vertexId]$\;
	    $destComp \gets component[edges[edgeid].destination]$\;
   	    \ldots
    }
%    \caption{возможно, данный заголовок стоит выпилить}
\end{algorithm}



\textbf{Выделение памяти с учётом NUMA архитектуры}
Как уже отмечалось ранее, обращение в память другого узла NUMA связано с высокими задержками. Выделение памяти на тех ядрах, где она используется, является более правильным на NUMA архитектуре.

Все используемые в реализации массивы ограничиваются двумя размерностями. Более того, во всех двумерных массивах первая размерность соответствует индексу потока, в котором он используется (например, таким является массив, над которым происходит редукция: первая размерность соответствует номеру потока, вторая~---~компоненте, а значением является ребро минимального веса, которое данный поток нашёл для данной компоненты), и с точки зрения NUMA архитектуры такие массивы проблем не создают.

Когда разные части одномерного массива одновременно используют несколько потоков (например,  таким является массив рёбер), то возникает необходимость выделить непрерывную область в памяти на разных узлах NUMA. Ядро Linux предоставляет разработчику возможность явно управлять выделением страниц памяти на NUMA системах с использованием библиотеки libnuma. Однако, в реализациях использовалась особенность ядра Linux известная как memory overcommit: для программы выделение страниц памяти происходит не в момент вызова функции malloc (или аналогичной, запрашивающей у ядра операционной системы страницы памяти, но не инициализирующей их), а в момент первого обращения к странице. 
Таким образом, для разделения массива по узлам NUMA сначала с использованием функции malloc выделялся весь массив нужного размера, далее каждый поток инициализирует те страницы, которые он будет использовать. При таком подходе, конечно, может возникнуть пересечение, когда два потока используют одну страницу, но размеры таких пересечений невелики по сравнению с размером всего массива, а их количество ограничено количеством потоков.

Был также опробован подход с дублированием массива, который используют одновременно несколько узлов NUMA. Одним из примеров таких данных является массив, где для каждой вершины хранится индекс компоненты, в которую она входит на текущей итерации. Однако, из-за необходимости после каждой итерации дополнительно обновлять массив на каждом узле NUMA данный подход себя не оправдал и производительность в лучшем случае не уменьшалась.



\textbf{Аппаратные потоки процессора.}
Современные процессоры позволяют на одном ядре исполнять одновременно несколько аппаратных потоков. Так в процессорах Intel и AMD данные технологии называются соответственно Hyper-Threading и Modules и позволяют запускать по 2 аппаратных потока на ядро, а ускоритель Intel Xeon Phi на данный момент имеет 4 аппаратных потока на каждое ядро. Использование такого вида многозадачности позволяет не только более эффективно использовать процессорные элементы, но и скрыть задержки в память за счёт переключения на другой поток.
% быть может, описать как-нить более литературно

Проблема использования аппаратных потоков для алгоритма EA заключается в увеличении объёма данных на шаге \textbf{редукции}. В начальных реализациях использование Hyper-Threading давало небольшое
%какое?
ускорение на малом количестве потоков, но ухудшало время на 16 потоках. После применения описанных выше оптимизаций редукции Hyper-Threading стал давать выигрыш в среднем 5\%.



\textbf{Linux Huge Pages.}
Объём обрабатываемых данных, находящихся в памяти, составляет гигабайты, что во много раз больше размера одной страницы памяти в процессорах архитектуры x86, равного 4 килобайтам. Использование большого числа страниц виртуальной памяти приводит к частым промахам в TLB кэше, что, конечно же, отрицательно сказывается на производительности.
Размер страницы памяти зависит от архитектуры и во многих архитектурах, в том числе и в x86, реализована поддержка ``больших страниц''~---~страниц, размер которых равен нескольким мегабайтам или даже гигабайтам.

Увеличение объёма страниц памяти ведёт к уменьшению количества используемых страниц, что в свою очередь уменьшает число промахов в TLB кэше.
К сожалению, на данный момент хоть и huge pages включены в ядре Linux, однако, настройки системы по умолчанию не позволяют их использовать без дополнительных действий со стороны администратора системы, потому данная оптимизация не была протестирована на центральном процессоре Intel Xeon.

Лучше дела обстоят на ускорителе Intel Xeon Phi, где Huge Pages разрешены ``из коробки'' и не требуют дополнительных настроек. Использование Huge Pages на данном ускорителе дало выигрыш от 5\% до 15\%.



\section{Разбор ещё пары алгоритмов}
\label{sec:algoOther}

В данном разделе приведён анализ двух других алгоритмов~---~Крускала и Прима~---~на возможность получения параллельных реализаций, на основе данных алгоритмов.

Как было отмечено в разделе \ref{subsec:reviewParallel}, данные алгоритмы состоят из большого числа шагов, которые должны выполняться последовательно, и в своём оригинальном варианте невозможно эффективно распараллелить.
Модификации алгоритмов представлены в статьях \cite{boruvka-prima, kruskal-parallel} и основная идея, которая в них лежит, заключается в явном или неявном разделение графа на части, построении остовного дерева в каждой из частей и последующего объединения остовных деревьев.


\subsection{Алгоритм Прима}
\label{subsec:algoPrim}

В работе такой-то предложено то-то

\subsection{Алгоритм Крускала}
\label{subsec:algoKruskal}

% 1. Написать о статье
В работе \cite{kruskal-parallel} описан параллельный алгоритм на основе последовательного алгоритма Крускала.
Схему алгоритма можно разделить не две части.
Сначала множество вершин графа $V$ каким-либо образом разбивается между потоками и $i$-му потоку достаётся множество вершин $V_i$ ($ \displaystyle \bigcup_{i=1}^T V_i = V $ и $\forall$ $i \neq j$: $V_i \cap V_j = \emptyset$). 
Во множество рёбер $E_i$, с которыми изначально будет работать $i$-й поток, входят все рёбра, у которых хотя бы одна из двух инцидентных вершин принадлежит множеству вершин $i$-ого потока $V_i$: 
$E_i = \{ (u, v) \in E : u \in V_i$ или $v \in V_i \}$.
Очевидно, что каждое ребро исходного графа принадлежит хотя бы одному потоку, но в то же время одно ребро может принадлежать и сразу двум потокам, если инцидентные ему вершин принадлежат разным потокам.
После деления графа каждый поток строит остовное дерево на своём множестве рёбер с помощью последовательного алгоритма Крускала. 
Поскольку подмножество вершин потоков может оказаться и несвязным, то в результате у каждого потока, особенно в разреженных графах, построится остовной лес.

Затем происходит объединение лесов. Это можно представить как следующий итеративный процесс, который происходит до тех пор, пока не останется ровно одно дерево:
\begin{itemize}
    \item Все имеющиеся леса разбиваются на пары произвольным образом.
    \item Каждая пара лесов объединяется в один с помощью алгоритма Крускала на множестве рёбер, равному объединению обоих лесов.
\end{itemize}

Разделить граф между потоками.
Каждый поток строит остовное дерево для своей части.
Пока не останется одно дерево:
....Разбить все имеющиеся деревья на пары
....Кажду пару деревьев слить в одно

остовного дерева, поэтому на последующих шагах уже не рассматриваются рёбра, не вошедшие ни в одного из деревьев.
%В то же время, нельзя просто объединить все деревья, полученные на первом шаге, т. к. скорее всего, в полученный простым объединением рёбер граф будет содержать циклы, для исключения которых и требуются следующие шаги алгоритма.

% 2. Написать про идею распараллелить сортировку, затем по-быстрому запустить Крускала
Другая идея распараллеливания основана на том, что алгоритм Крускала состоит из двух шагов: сортировки рёбер и удаления тех рёбер, которые создают цикл. 
Время работы 
Последовательный алгоритм Крускала был запущен на разных графах и было выявлено, что время работы второго шага составляет от 30 до 40 процентов всего времени работы, а значит таким образом, даже при идеальном масштабировании сортировки, время выполнения уменьшится не более, чем в 3 раза.
Таким образом, данный подход не годится для получения масштабируемого параллельного алгоритма построения минимального остовного дерева.




%\newpage
\section{Результаты}
\label{sec:results}
\noindent \begin{figure}[t]
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = RMAT-22-32,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{ EA, VL-List, VL-Vec-Bal, AL-Copy };
\addplot[mark=triangle*] coordinates {(1, 199.13948252434521) (2, 342.3921632653061) (4, 568.719186440678) (8, 794.1877396449704) (16, 1427.848170212766) };
\addplot[mark=o] coordinates { (1, 15.212255241981184) (2, 23.037715070374187) (4, 31.632742870610414) (8, 38.86988937156096) (16, 35.48855843469064) };
\addplot[mark=*] coordinates { (1, 38.76884113229347) (2, 67.48000402212166) (4, 107.80540401606424) (8, 127.70478401522361) (16, 124.85370046511628) };
\addplot[mark=square*] coordinates { (1, 6.2429753942043815) (2, 10.760661268339614) (4, 16.145522434740766) (8, 18.80063426250175) (16, 22.34727405927406) };
\end{semilogxaxis}
\end{tikzpicture}
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = SSCA2-22,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{ EA, VL-List, VL-Vec-Bal, AL-Copy };
\addplot[mark=triangle*] coordinates {(1, 220.6453687315634055) (2, 397.16166371681413) (4, 673.18902) (8, 868.6309935483871) (16, 1583.9741647058822) };
\addplot[mark=o] coordinates { (1, 18.385607537894305) (2, 31.130128092485545) (4, 52.1044133126935) (8, 81.0582805538832) (16, 104.6950264385692) };
\addplot[mark=*] coordinates { (1, 43.586210424085465) (2, 74.22150165380376) (4, 114.29355178268253) (8, 127.98270342205323) (16, 114.87867235494882) };
\addplot[mark=square*] coordinates { (1, 12.738934998580755) (2, 19.93157720207254) (4, 28.350769425142136) (8, 37.203040618955505) (16, 35.71294535809019) };
\end{semilogxaxis}
\end{tikzpicture}
%\caption{Сравнение производительности разных реализаций}
%\label{fig:resultAllRmatSsca}
%\end{figure}
%
%\noindent \begin{figure}[t]
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = Random-22-27,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{     EA,     VL-List,    VL-Vec-Bal,    AL-Copy };
\addplot[mark=triangle*] coordinates { (1, 155.55555555555) (2, 280.7902259414226) (4, 498.9506617100372) (8, 787.2007507331377) (16, 1420.293417989418) };
\addplot[mark=o] coordinates { (1, 20.05794336098035) (2, 30.709925180185333) (4, 42.96342125480153) (8, 54.82750326797385) (16, 52.46979202501955) };
\addplot[mark=*] coordinates { (1, 50.57186435568953) (2, 88.0116249180328) (4, 141.87920507399576) (8, 158.9315902901125) (16, 152.86757175398634) };
\addplot[mark=square*] coordinates { (1, 4.958264024086149) (2, 8.986490442234945) (4, 13.286253019204118) (8, 18.587138623459353) (16, 20.362243495410755) };
\end{semilogxaxis}
\end{tikzpicture}
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = Grid-8000$\times$8000,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{     EA,     VL-List,    VL-Vec-Bal,    AL-Copy,};
\addplot[mark=triangle*] coordinates { (1, 36.11111111111111111) (2, 65.89470974385378) (4, 119.77912962096396) (8, 179.81594661046717) (16, 317.18463444857497) };
\addplot[mark=o] coordinates { (1, 6.2560918978369795) (2, 11.24022395433088) (4, 19.313238012600443) (8, 30.601709606073285) (16, 33.43801436969301) };
\addplot[mark=*] coordinates { (1, 14.931777745369697) (2, 25.7538987825737) (4, 38.66002114484216) (8, 31.94209771011418) (16, 27.697668127468486) };
\addplot[mark=square*] coordinates { (1, 4.958264024086149) (2, 8.986490442234945) (4, 13.286253019204118) (8, 18.587138623459353) (16, 20.362243495410755) };
\end{semilogxaxis}
\end{tikzpicture}
\caption{Производительности алгоритмов на разных графах}
\label{fig:resultGridRand}
\end{figure}
\noindent \begin{figure}[t]
\begin{tikzpicture}
\begin{axis}[
    legend pos = north west,
    title = RMAT,
    xlabel = {Число вершин, степень 2},
    ylabel = {Производительность, MTEPS},
    xmin = 16,
    xmax = 25,
    xtick = data,
    grid = major,
]
\legend{ EA };
\addplot[mark=triangle*] coordinates {
(16, 419.4304) (17, 699.0506666666666) (18, 699.0506666666666) (19, 932.0675555555556) (20, 1198.3725714285715) (21, 1369.5686530612245) (22, 1412.8181894736842) (23, 1242.7567407407407) (24, 1376.592082051282) (25, 1063.1107168316832)
};
\end{axis}
\end{tikzpicture}
\begin{tikzpicture}
\begin{axis}[
    legend pos = north west,
    title = SSCA2,
    xlabel = {Число вершин, степень 2},
    ylabel = {Производительность, MTEPS},
    xmin = 16,
    xmax = 25,
    xtick = data,
    grid = major,
]
\legend{ EA };
\addplot[mark=triangle*] coordinates {
(16, 352.109) (17, 526.8495) (18, 700.6315) (19, 934.9746666666667) (20, 1246.2312592592593) (21, 1431.997574468085) (22, 1583.9741647058822) (23, 1652.0263312883435) (24, 1709.897834920635) (25, 1717.709658692185)
};
\end{axis}
\end{tikzpicture}
\caption{Сравнение производительности алгоритма EA на графах разного размера}
\label{fig:resultSize}
\end{figure}

Тестирование проводилось на следующих графах:
\begin{itemize}
    \item \textbf{RMAT-графы}. Структура RMAT-графа, процесс генерации которого подробно описан в \cite{rmat-graph}, напоминает структуру социальной сети. Особенностью таких графов является наличие одной большой компоненты, в которую входят почти все вершины графа, а так же множество небольших компонент, в том числе и отдельно висячие вершины. Степень вершин в таких графах различна и может очень сильно отличаться от средней степени вершин во всём графе: присутствуют как множество вершин небольшой степени, так и отдельные вершины, степень которых на 2-3 порядка выше средней степени.
    
    \item \textbf{SSCA2-графы}. SSCA2 графы представляют из себя множество небольших клик, между которыми случайно сгенерировано некоторое число рёбер \cite{ssca2-graph}.
    
    \item \textbf{Двумерные и трёхмерные решётки}. Графы, структура которых является $N$-мерной решёткой: каждая вершина графа, за исключением крайних, соединена рёбрами с $2^{N+1}$ соседними вершинами.
    
    Данный граф можно схематично представить как решётку в $N$-мерном пространстве, где каждая вершина $v$ имеет целочисленные координаты ($v_0$, $v_1$, $\ldots$, $v_{N-1}$), $0 \leq v_i < L_i$, где $L_i$ --- длина $i$-ой размерности решётки. Расстояние между двумя вершинами $v$ и $u$ в такой решётки полагается равным сумме модулей разностей по каждой координате: $\displaystyle \sum_{i=0}^{N-1} |v_i - u_i|$. 
    Всего в решётке будет $L_0 \cdot L_1 \cdot \ldots \cdot L_{N-1}$ вершин и смежными являются те вершины, расстояние между которыми равно 1.
    
    \item \textbf{Случайные графы}. 
        При генерации случайных графов задаётся количество вершин графа и требуемое количество рёбер. Затем генерируются рёбра графа: для каждого ребра случайно выбираются обе инцидентные ему вершины, при этом каждая из вершин может быть выбрана с равной вероятностью.
\end{itemize}

Вес каждого ребра графа генерировался независимо и является случайной величиной на интервале от 0 до 1, имеющей равномерное распределение. Во всех графах, кроме решёток, допускаются петли и кратные рёбра.

В качестве формата хранения графа использовался сжатый формат хранения разреженных матриц CSR (Compressed Storage Row) \cite{matrix-csr}.
В данном формате все ненулевые значения матрицы располагаются в памяти последовательно таким образом, что все элементы одной строки идут подряд слева направо, а строки матрицы идут последовательно сверху-вниз. 
Для каждого ненулевого элемента помимо его значения хранится индекс столбца, в котором он находится. 
Также для каждого элемента необходимо уметь определять и номер строки, на которой он расположен, но за счёт того, что элементы одной строки идут подряд, достаточно для каждой строки исходной матрицы хранить индекс первого и последнего элемента в массиве элементов, а за счёт того, что строки идут последовательно, индекс последнего элемента строки $i$ будет на единицу меньше, чем индекс первого элемента строки $i+1$ (на практике обычно для хранения индексов обычно используют полуоткрытые интервалы --- в этом случае данные индексы будут совпадать).

Формат CSR является достаточно компактным и хорошо подходит для хранения рарзеженных графов.
Независимо от числа в графе, объём используемой памяти пропорционален количеству рёбер.
К преимуществам CSR формата можно отнести возможность последовательного обхода всех списков смежности: поскольку для каждой вершины все рёбра, инцидентные ей, идут последовательно, то реализация обхода в коде заключается в написании двух вложенных циклов.
Из недостатков CSR формата стоит отметить невозможность модифицировать матрицу, но поскольку данный граф во время исполнения алгоритма не изменяется, то данный недостаток не является существенным в задаче. 
Так же CSR формат не позволяет быстро получить значение элемента матрицы по номеру строки и столбца, однако, в реализациях исследуемых алгоритмов произвольный доступ к элементам матрицы не требовался.

Запуски проводились на двухсокетной машине с процессорами Intel Xeon CPU E5-2690. Каждый процессор состоит из 8 ядер с тактовой частотой 2.9 GHz, каждое ядро имеет кэш первого уровня 32 килобайта и   кэш второго уровня 256 килобайт. Так же каждый процессор имеет общий для всех ядер кэш третьего уровня 20 мегабайт.
На тестируемой машине была включена технология Hyper Threading, позволяющая исполнять на каждом ядре процессора по 2 аппаратных потока.

Важным вопросом при измерении производительность является выбор метода для измерения времени.
Все запуски производились на ОС Linux, для которой реализованы различные внешние средства для измерения затраченных ресурсов, в том числе и реальное и процессорное время работы программы. 
Недостатком таких средств для измерения производительности является невозможность замерить время выполнения отдельных участков кода.
Измерение времени  не для всей программы целиком требуется, чтобы исключить из итогового времени работы такие шаги как чтение входных данных с диска. 
Так же достаточно полезным является возможность собирать время исполнения для каждого шага алгоритма по каждому потоку.
Из средств, которые можно использовать непосредственно в коде самой программы, рассматривались следующие:
\begin{itemize}
    \item Функция \texttt{clock} из стандартной библиотеки языка С, возвращает процессорное время работы программы. 
    \item Системный вызов \texttt{time}, возвращает астрономическое время с точностью до секунды. 
    \item Системный вызов \texttt{gettimeofday} (get time of day~---~получить астрономическое время), возвращает астрономическое время с точностью $10^{-6}$ секунды.
    \item Системный вызов \texttt{clock\_gettime}. Позволяет получить процессорное время как по всей программе, так и по каждому потоку отдельно. 
    Так же позволяет узнать астрономическое время, которое установлено на данный момент в системе, и астрономическое время, прошедшее с некоторой неопределённой отметки, но не подверженное факторам, изменяющих время системных часов (такие как смена часовых поясов, автоматическая корректировка времени по расписанию).
    Так же позволяет узнать и астрономическое время, не привязанное к часовым поясам и их смене.
    \item Ассемблерная инструкция \texttt{rdtsc}, позволяет получить количество тактов с момента последнего сброса процессора.
\end{itemize}
Недостатками системных вызовов являются большие накладные расходы. Время работы алгоритма измеряется от сотен миллисекунд до нескольких десятков секунд, таким образом, требуемая точность к измерение времени как минимум $10^{-3}$ секунды.
В результате анализ была выбрана ассемблерная инструкция \texttt{rdtsc}, обеспечивающая высокую точность и имеющая минимальные накладные расходы.

Дополнительно к выбору точного метода измерения времени были так же минимизировано влияния со стороны системы. 
Использовалась жёсткая привязка потоков программы к ядрам процессора, чтобы избежать перемещения потоков между разными узлами NUMA.
На кластерах для сокращения энергопотребления включена технология SpeedStep, сбрасывающая тактовую частоту ядер процессора, если они не загружены работой. 
Для устранения эффекта, когда первые несколько сотен миллисекунд программа работает на пониженной частоте, использовался ``прогрев'': первые 2-3 секунды запускался холостой цикл на всех ядрах, приводящий к поднятию частоты до максимального значения.
Другой технологией, влияющей на тактовую частоту, является Turbo Boost: повышение тактовой частоты одного ядра, когда работой загружено только оно.
Для устранения эффектов, связанных с технологией Turbo Boost, одновременно вместе с программой запускались холостые циклы на неиспользуемых ядрах.

Каждая реализация была запущена на каждом из графов 5 раз и в качестве итогового значения времени выбирался минимальный результат.
Поскольку на машинах, которые входят в состав кластеров, запущенно окружение содержит только основные для работы операционной системы сервисы, то её влияние на программу минимально и разброс между запусками достаточно низкий.
Так, на практике разница между минимальным и максимальным временем составляла менее 1\%.

На всех графиках результаты представлены в MTEPS (TEPS, traversed edges per second --- количество обработанных рёбер в секунду, приставка M означает mega) --- величина, обратно пропорциональная времени и равная:
$$MTEPS = \frac{\texttt{количество рёбер в графе}}{(\texttt{время работы программы в секундах}) \cdot 10^6}$$

На рисунке \ref{fig:resultGridRand} представлено сравнение описанных выше алгоритмов на графах следующих размерах:
\begin{itemize}
    \item RMAT-22-32 --- RMAT-граф с $2^{22}$ вершинами и средней степенью вершины 32.
    \item SSCA2-22 --- SSCA2-граф, в котором $2^{22}$ вершин и примерно $2^{27}$ рёбер.
    \item Random-22-27 --- случайный граф в котором, соответственно, $2^{22}$ вершин и $2^{27}$ рёбер.
    \item Grid-8000$\times$8000 --- двумерная решётка размера 8000 на 8000. В такой решётке находится $2^{26}$ вершин и приблизительно $2^{27}$ рёбер.
\end{itemize}

Размеры графов выбирались таким образом, чтобы количество рёбер было примерно одинаковым. Количество вершин в разных графах, за исключением решётки, так же примерно одинаково. 

На графиках отображена зависимость производительности от числа используемых потоков.
Результаты алгоритма EA заметно лучше остальных. Огромная разница в производительности обосновывается тем, что не все оптимизации, описанные в разделе \ref{sec:eaopt} были применены и для остальных алгоритмов, но даже неоптимизированный вариант показывал лучшие результаты.
Среди остальных алгоритмов относительно неплохую производительность показывает VL-алгоритм на динамических массивах с дополнительной балансировкой нагрузки, однако, имеются проблемы с масштабируемостью на два сокета.

Решётка же получается более разреженной и имеет при таком же количестве рёбер в 16 раз больше вершин. 
Это ведёт к большему количеству итераций, который должен выполнить алгоритм Борувки прежде, чем остовное дерево будет построено, и как следствие увеличивается время работы. Так, для построения остовного дерева в графе RMAT-22-32 требуется 6 итераций, а в решётке 8000$\times$8000~---~13 итераций, чем и объясняется более низкая производительность при равном количестве рёбер.




На рисунке \ref{fig:resultSize} представлено изменение производительности алгоритма EA в зависимости от размера графа. Сравнение проводилось на RMAT графах  и на SSCA2 графах со средней степенью вершины 32. 

На малых размерах графа производительность низкая, поскольку в реализации присутствуют барьерные синхронизации между шагами алгоритма, а такие шаги, как \textbf{перенумерация вершин}, дополнительно содержат барьерные синхронизации и внутри себя. На больших графах объём вычислений  между синхронизациями достаточно большой и время, затраченное на такие синхронизации, очень мало. На графах же небольшого размера время, которое потоки проверили на синхронизации, уже негативно сказывается на производительности.


\section{Заключение}
\label{sec:conclusion}

% Что было сделано.
Были исследованы последовательные алгоритмы построения остовных деревьев: алгоритмы Прима, Крускала и Борувки. 
Каждый из алгоритмов был проанализирован на возможность его эффективного распараллеливания, были изучены статьи по распараллеливанию данных алгоритмов, исследованы имеющиеся результаты, подходы к внутреннему представлению графа в памяти.

После предварительного анализа был выбран алгоритм Борувки, который в своём оригинальном варианте наиболее пригоден для распараллеливания.
Были реализованы несколько вариантов алгоритма Борувки, использующие разные структуры данных для хранения графа, часть из которых была основана на вариантах, описанных в статьях.
На основе полученных реализаций
Затем, на основе полученных рекомендаций, был предложен собственный вариант алгоритма Борувки.

К полученной реализации были применены многочисленные алгоритмические и архитектурные оптимизации, ориентированные на общее повышение производительности и на улучшение масштабируемости алгоритма для повышения производительности на большом количестве потоков.

Был сделан анализ Прима и Крускала.

%В чём польза обществу, актуальность проделанной работы ???

%Каковы дальнейшие направления работы.
Реализация над распределённой памятью.


% СТАРЫЙ ТЕКСТ

%На данный момент исследованы последовательные алгоритмы построения остовных деревьев и выбраны из них те, которые или модификации которых могут дать хорошую масштабируемость при распараллеливании. Так же изучены статьи  \cite{dense-mst,boruvka-prima,boruvka-cm5} по распараллеливанию данных алгоритмов.

%Были получены последовательные реализации алгоритмов для дальнейшей проверки корректности получаемых результатов. Затем был написан и распараллелен алгоритм Борувки в нескольких реализациях, использующих разные структуры данных для хранения графа.

%В дальнейших планах есть как оптимизация существующих алгоритмов, так и реализация новых.

%В уже реализованных алгоритмах ближайшей целью является использование таких подходов как параллельные алгоритмы поиска компонент связности в тех шагах, где происходит объединение вершин одной компоненты.

%Далее возможно использование других  структур данных в алгоритме Борувки. Рассматриваются такие структуры, как списки отсортированных списков смежностей, являющиеся промежуточным вариантом между поддержанием списков смежностей отсортированными на каждой итерации и полным отказом от сортировки списков, и деревья или кучи, позволяющие при дополнительных условиях производить их слияние за время, пропорциональное их высоте.

%Так же планируется не только модификация алгоритма Борувки, но и реализация модифицированного алгоритмы Примы.

\newpage

\bibliographystyle{unsrt}
\bibliography{conference}

\end{document}
