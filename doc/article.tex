\documentclass{article}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{textcomp}
%\usepackage{expdlist}
%\usepackage{textpos}
\usepackage{cmap}
%\usepackage[left=30mm,right=15mm,top=20mm,bottom=20mm]{geometry}

%\hoffset=-3cm
%\textwidth=18cm
%\voffset=-3cm
%\textheight=23cm

\date{}
\title{Построение MST на мультипроцессоре с ccNUMA архитектурой}
\author{Зайцев Вадим, zaic101@gmail.com \\ Новосибирский государственный университет\thanks{Работа поддержана Грантом Президента РФ для молодых учёных МК-3644.2014.9}}

\usepackage{indentfirst}


\begin{document}

%\maketitle
%\newpage

\tableofcontents



\newpage
\section{Введение}
% 1     Введение
% 1.1   Актуальность обработки графов

% 1.2   Постановка задачи MST
В данной работе рассматривается задача построения минимального остовного дерева (minimum spanning tree --- MST) на мультипроцессоре с ccNUMA архитектурой.
Задача построения MST формулируется следующим образом: дан взвешенный, неориентированный граф и требуется найти остовное дерево (максимальный по включению рёбер подграф, не имеющий циклов), в котором сумма весов рёбер будет минимальна.
В случае, когда исходный граф связный, в итоге будет построено остовное дерево, если же в исходном графе несколько компонент, то результатом будет лес.

% 1.3   Применение MST (из английской википедии) % TODO ссылки, более подробное описание
Минимальные остовные деревья имеют широкое практическое применение.
Они используются при построении различных сетей: коммуникационных линий, компьютерных сетей, транспортных сетей.
Так же они используются в кластеризации, сегментации при обработке изображений, распознавании рукописного ввода.

% 1.4   Обзор существующих статей
% ToDo Возможно, полностью перенести в 2.1

\newpage
\section{Обзор алгоритмов построения MST}
% 2     Подробно об алгоритмах
% 2.1   Обзор существующих
%Существует несколько различных последовательных алгоритмов построения MST. %, которые, в зависимости от используемых в реализации структур данных, имеют асимптотическую оценку времени работы $O(E\cdot\log E)$ для разреженных  и $O(V^2)$ для полных графов.
Существует несколько различных последовательных алгоритмов построения MST, наиболее распространёнными из которых являются алгоритмы Крускала, Прима и Борувки \cite{cormen}.
Алгоритм Крускала состоит из шагов (на каждом шаге добавляется одно новое ребро в текущий остов), каждый следующий из которых зависит от результата предыдущего, что делает распараллеливание данного алгоритма неэффективным.
% TODO описать шаг точно так же
В алгоритме Прима шаги так же связаны между собой, а распараллеливание одного шага не даст большого выигрыша в силу большого количества шагов и малой вычислительной сложности одного шага.
Однако, существует параллельный алгоритм построения MST, являющийся модификацией алгоритма Прима.
Алгоритм Борувки в своём оригинальном виде является наиболее пригодным для распараллеливания. 
%TODO возможно, заменить на псевдокод
Далее опишем алгоритм Борувки и модифицированный алгоритм Прима.


% 2.1.1 Разные реализации Борувки, ПочтиПрима
\subsection{Алгоритм Борувки}
Изначально каждая вершина графа считается отдельной компонентой, затем компоненты объединяются до тех пор, пока не останется ровно одна.
Объединение компонент происходит итеративно: на каждой итерации для каждой компоненты просматривается список всех инцидентных ей рёбер и выбирается минимальное из них, затем компоненты объединяются по найденным рёбрам.

За счёт того, что основная часть алгоритма -- обход всех рёбер, который может быть разбит на независимые части и выполнятся параллельно, данный алгоритм в перспективе может дать хорошую масштабируемость.
В статьях \cite{dense-mst,boruvka-prima,boruvka-cm5} представлены различные варианты параллельных реализаций алгоритма Борувки.
Разные реализации используют разные структуры данных для хранения рёбер (хранение рёбер одним большим списком или хранение для каждой вершины списка инцидентных ей рёбер) и разные способы их объединения (слияние и копирование списков, объединение списков за константное время и т. д.).

\subsection{Модифицированный алгоритм Прима}
В статье \cite{boruvka-prima} представлен параллельный алгоритм построения MST на основе последовательного алгоритма Прима.
Суть данного алгоритма в том, что каждый поток выбирает случайную вершину в графе и начинает ``растить'' дерево из выбранной вершины, пока не попытается присоединить вершину, уже принадлежащую другому дереву, после чего два дерева встретившихся потоков объединяются, один из них продолжает ``растить'' объединённое дерево, а второй заново выбирает вершину графа. % TODO перечитать их алгоритм
К преимуществам данного подхода относится отсутствие барьерной синхронизации, которая требуется в алгоритме Борувки после каждой итерации и, в зависимости от реализации, между разными шагами одной итерации.

\newpage
\section{Разработка параллельного алгоритма}
% 2.2   Обзор недостатков существующих
В данных работах \cite{dense-mst,boruvka-prima,boruvka-cm5} результаты производительности показаны либо для старых архитектур \cite{dense-mst,boruvka-cm5}, либо масштабируемость была ограничена шестью одноядерными процессорами (SMP  UMA, UltraSPARC II) \cite{boruvka-prima} .
% 2.2.1 Малое количество ядер
% 2.2.2 SMP системы

% 2.3   Цель работы
Настоящая работа направлена на адаптацию существующих и реализацию новых алгоритмов, ориентированных на высокую эффективность на современных вычислителях с общей памятью с ccNUMA архитектурой.

\subsection{Алгоритм Борувки, использующий список рёбер}
% 2.4   Мой алгоритм один
Первая параллельная реализация построения MST основана на алгоритме Борувки. 
Изначально множество вершин графа разделяется между потоками равномерно по количеству инцидентных рёбер.
Далее на каждой итерации выполняются следующие шаги:
\begin{enumerate}
    \item \textit{Минимальное инцидентное ребро (1)}.
          Каждый поток просматривает своё подмножество рёбер и для каждой компоненты находит инцидентное ребро минимального веса. 
          В результате каждый поток будет иметь массив, содержащий минимальное ребро для каждой компоненты среди просмотренного подмножества.
    \item \textit{Минимальное инцидентное ребро (2)}.
          Происходит редукция: для каждой компоненты находится ребро минимального веса по всем потокам. 
          Таким образом, для каждой компоненты определяется минимальное ребро уже по всему графу.
    \item \textit{Объединение деревьев (1)}.
          Для каждой компоненты определяется её номер на следующей итерации.
          Так же решается проблема с возможными циклами (когда более двух компонент по кругу выберут следующую в качестве ближайшей), которые возможны в алгоритме Борувки при наличии рёбер одинакового веса.
    \item \textit{Объединение деревьев (2)}.
          Осуществляется перенумерация компонент: для каждой вершины вычисляется номер компоненты, в которую она входит, используя параллельный алгоритм Pointer Jumping \cite{pointer-jumping}.
\end{enumerate}
Каждый шаг исполняется параллельно всеми потоками, однако после каждого шага требуется барьерная синхронизация всех потоков.
Далее были сделаны следующие оптимизации:
\begin{itemize}
    \item Сортировка рёбер по весу и удаление петель, за счёт чего в среднем сокращается количество рёбер, которые необходимо просмотреть на первом шаге.
    \item Выделение и инициализация памяти с ориентацией на NUMA архитектуру.
    \item Иерархическая редукция по дереву на втором шаге с учётом NUMA архитектуры.
\end{itemize}



% 2.5.3 Результаты
%\textit{ToDo Красивые мимимишные графики}.

\subsection{Алгоритм Борувки, использующий отсортированные списки смежности}
% 2.6   Планы по алгоритму два
% TODO
%Альтернативная параллельная реализация построения MST так же основана на алгоритме Борувки, но для хранения рёбер используются списки смежности для каждой компоненты. 
Наибольшая вычислительная сложность первого алгоритма заключается в первом шаге, в котором необходимо обойти б\`oльшую часть рёбер графа, однако, основным препятствием для хорошей масштабируемости является то, что размер массива, редуцируемого на втором шаге, увеличивается с ростом количества потоков.

Вторая реализация алгоритма Борувки для хранения рёбер использует списки смежности. 
Изначально для каждой вершины сортируется список инцидентных ей рёбер по увеличению веса. 
Таким образом, получить самое лёгкое ребро, инцидентное вершине, возможно за $O(1)$, не выполняя проход по массиву.
Далее выполняются следующие шаги, пока не останется одна компонента:
\begin{enumerate}
    \item \textit{Минимальное инцидентное ребро}.
        Для каждой компоненты берётся инцидентное ей ребро минимального веса. Как отмечено выше, это будет первое ребро из списка смежности.
    \item \textit{Объединение деревьев}.
        Объединение компонент, для каждой компоненты определяется её номер на следующей итерации. 
        Аналогично шагам \textit{Объединение деревьев 1-2} в первом алгоритме.
    \item \textit{Слияние списков}.
        Происходит объединение компонент путём слияния списка рёбер. 
        Поскольку, списки уже отсортированы по возрастанию веса, то возможно слияние, при котором в результате так же будет получен отсортированный список, с сохранением линейного времени работы.
    \item \textit{Перенумерация}.
        Обход списков рёбер и перенумерация компонент: старые номера заменяются на новые, полученные на шаге \textit{Объединения деревьев}.
\end{enumerate}

В ходе анализа работы шага \textit{Объединение деревьев} на тестируемых типах графов было выяснено, что количество объединяемых компонент в одну в большинстве случаев не превосходит трёх и это позволяет быстро и эффективно отсеивать петли на шаге \textit{Слияния списков} за счёт сокращения нерегулярных обращений в память.

\subsection{Алгоритм Борувки, использующий неотсортированные списки смежности}

% TODO ударения в слове большИх
Поддержка списков смежности отсортированными при слиянии требует больших временных затрат и несмотря на получившийся выигрыш в первом шаге, общее время выполнение алгоритма увеличилось.
В связи с этим было решено отказаться от поддержания списков отсортированными. Таким образом, поиск минимума на первом шаге осуществляется обходом всего списка, но объединение списков стало возможно простым копированием.

Общая схема алгоритма осталась прежней, однако, реализация шага поиска минимального ребра и слияния списков значительно изменилась:
\begin{enumerate}
    \item \textit{Минимальное инцидентное ребро}.
        Для каждой компоненты находится инцидентное ей ребро минимального веса простым линейным поиском.
    \item \textit{Объединение деревьев}.
        Объединение компонент, для каждой компоненты определяется её номер на следующей итерации. 
        Аналогично шагам \textit{Объединение деревьев 1-2} в первом алгоритме.
    \item \textit{Слияние списков}.
        Происходит объединение компонент путём объединения списка рёбер.
    \item \textit{Перенумерация}.
        Обход списков рёбер и перенумерация компонент: старые номера заменяются на новые, полученные на шаге \textit{Объединения деревьев}.
\end{enumerate}

%\newpage
%\section{Результаты}
% 2.5   На чём проводилось тестирование
% 2.5.1 Параметры графов
%Тестирование проводилась на графах, состоящих из $10^6-10^8$ вершин и $10^7-10^9$ рёбер: это RMAT-графы %степени $20\,-\,23$, двумерные и трёхмерные решётки, а так же случайные графы.

% 2.5.2 Характеристика систем
%Характеристики систем, на которых производились запуски:
%\begin{itemize}
%    \item 2 $\times$ Intel Xeon CPU E5-2690 (8 ядер 2.9 GHz, 32KB L1 cache, 256KB L2 cache, 20MB L3 cache)
%    \item 8 $\times$ Intel Xeon CPU Е7-4870 (10 ядер 2.4 GHz, 32KB L1 cache, 256KB L2 cache, 30MB L3 cache)
%\end{itemize}

%[Позже будут добавлены результаты тестирования двух описанных алгоритмов].

\newpage
\section{Оптимизации EA реализации}

\subsection{Алгоритмические оптимизации}

\textbf{Предварительная сортировка рёбер.}
Алгоритм Борувки предполагает на каждой итерации просмотр всех рёбер графа, что и создаёт наибольшую вычислительную сложность шага ???. Первой проблемой такого подхода являются петли, который будут образовываться начиная с первой же итерации и который затем будут каждый раз просматриваться. Удаление же петель повлечёт за собой перестроение графа, что, как было выявлено в ходе исследования, негативно сказывается на производительности. Второй проблемой является то, что одни и те же рёбра просматриваются многократно.

Решить данную проблему возможно предварительной сортировкой списков смежности каждой вершины по невозрастанию веса. Затем для каждой вершины хранится индекс последнего просмотренного ребра: изначальной данный индекс указывает на первое ребро, затем, по мере отбрасывания петель, он сдвигается и на следующей итерации поиск минимального ребра начинается не с начала списка, а с позиции, на которую указывает индекс.

Данная оптимизация хорошо масштабируется и на большом количестве потоков время выполнения невелико.



\textbf{Переупорядочивание вершин.}
Вершины переупорядочивались в порядке модифицированного обхода в ширину (ссылка ???). Это позволяло уменьшить количество кэш-промахов.



\textbf{Отдельный цикл пропуска петель.}
В шаге а??? для каждой вершины ищется ребро минимального веса, ведущее в другую компоненту. С учётом оптимизации \textbf{предварительной сортировки рёбер} данный шаг выглядит следующим образом (упрощённо, конечно же):
myComp = component[v]
for (int edgeId = startEdge[v]; edgeId < endEdges[v]; edgeId += 1)
  destVertex = edges[edgeId].destination
  destComp = component[destVertex]
  if (destComp == myComp) then
    continue;
  if (edges[edgeId] < bestResult[myComp])
    bestResult[myComp] = edges[edgeId]
  break;
Данный цикл можно  упростить до:
while (loop) ++startEdge[v]; 
if (лучше) then присвоить
Написать, что петель отбрасывается очень много и потому данная модификация даёт улучшение производительности.

\textbf{Балансировка больших вершин.}
Одной из особенностей RMAT-графов являет наличие вершин, степень которых значительно отличается от средней степени всех вершин графа. Например, в тестируемом RMAT-графе с $2^{20}$ вершинами (???) и со средней степенью 32, есть более ??? вершин степени выше 1000. Такие вершины создают дисбаланс на последних итерациях, когда просматривается большое количество рёбер и отбрасываются петли.

С целью устранения данного дисбаланса на стадии предобработки графа выделяются вершины степени более 1000 и равномерно распределяются между потоками. Значение степени 1000 было подобрано эмпирически и хорошо показало себя на практике.

\subsection{Оптимизация редукции}

\textbf{Отсутствие редукции на первой итерации.}
Поскольку каждая компонента изначально представлена одной вершиной, то от редукции на первой итерации можно отказаться. Данная оптимизация выглядит простой и очевидной, однако, объём редуцируемого массива на первой итерации больше, чем на всех следующих, и данная модификация даёт существенное ускорение.

\textbf{Перенумерация и сжатие массива компонент по ходу исполнения алгоритма.}
В начальной реализации при объединении компонент в качестве её номера выбирался один из номеров вершин, которые в неё входят. Таким образом, несмотря на сокращение числа компонент, диапазон используемых номеров не изменялся (минимальный и максимальный номер были приблизительно равны соответственно первой и последней вершине). Такой подход затруднял обход всех компонент на шаге редукции: требовалось либо обходить весь диапазон номеров и совершать лишнюю работу, просматривая ``пустые'' номера, не являющиеся компонентами, либо отдельно хранить массив, в которым хранить индексы всех ``живых'' на данный момент компонент, что усложняло реализацию и приводило к увеличению кэш-промахов из-за обхода массива с непостоянным шагом.

Явная перенумерация компонент на последовательные номера позволила решить обозначенную проблему. 
Более того, это позволило уменьшить объём используемой памяти: в начальной реализации для каждого потока создавался двумерный массив размера \texttt{количество\_потоков}$\times$\texttt{количество\_вершин}
На системах с больш\`{и}м количеством ядер, например, на Intel Xeon Phi, где используется до 240 потоков, объём такого массива заметно превосходит объём всех других данных и его сокращение в 2 раза приводит к значительному уменьшению потребляемой памяти (???).

\textbf{Иерархическая редукция.}
Особенностью NUMA архитектуры являются высокие задержки при обращении в память другого узла NUMA.
При стандартном подходе к редукции, когда для каждой компоненты последовательно обходятся все потоки и выбирается лучший результат, таких обращений при двух NUMA узлах будет как минимума, а при большем количестве узлов NUMA --- ещё больше.

Данную проблему можно решить за счёт иерархического подхода к редукции. При таком подходе шаг редукции разбивается на два этапа: на первом происходит стандартная редукция внутри NUMA узла, а на втором  --- между узлами. Количество обращений к чужому узлу NUMA в этом случае уменьшается в количество раз, равное количеству используемых потоков в одном узле NUMA.
Может, добавить красивую картинку(???)

\textbf{Сообщения в редукции.}
В редуцируемом массиве много пустых элементов. Через сообщения можно уменьшить объём редуцируемых данных.

\subsection{Программные/процессорные оптимизации ???}

\textbf{Программная предвыборка.}
Обход рёбер в общем случае неизбежно связан со случайными обращениями в память:.
Аппаратная предвыборка современных процессоров ориентирована только на последовательные обращения в память (точнее, на обход с постоянным шагом, размер которого не превосходит размер страницы памяти).
Но не так всё плохо в этом грешном мире. Адреса случайны обращений в память в большинстве случаев можно предсказать.

Сказать про двойную предвыборку.



\textbf{Выделение памяти с учётом NUMA архитектуры}
Как уже отмечалось ранее, обращение в память другого узла NUMA связано с высокими задержками. Выделение памяти на тех ядрах, где она используется, является более правильным на NUMA архитектуре. Использовался как подход с выделением лалала, так и подход с выделением частей одного массива на разных ядрах.
Во втором подходе использовалась особенность ядра Linux (или Unix???) memory overcommit. Возможно, так же, libnuma.

Был так же опробован подход с дублированием массива, который используют одновременно несколько NUMA nodes. Одним из примеров таких данных является массив, где для каждой вершины хранится индекс компоненты, в которую она входит на данный момент. Однако, из-за необходимости после каждой итерации дополнительно обновлять массив на каждой NUMA node данный подход себя не оправдал.



\textbf{Аппаратные потоки процессора.}
Современные процессоры позволяют на одном ядре исполнять (???) одновременно несколько аппаратных потоков. Так в десктопных (домашние???) и серверныз процессорах Intel и AMD данные технологии называются соответственно Hyper-Threading и Modules и позволяют запускать по 2 аппаратных потока на ядро, а ускоритель Intel Xeon Phi на данный момент имеет 4 аппаратных потока на каждое ядро. Использование такого вида многозадачности позволяет не только более эффективно использовать processor units, но и скрыть задержки в память (за счёт переключение на другой поток???).

Проблема использования аппаратных потоков для EA-реализации заключается в увеличении объёма шага редукции. В начальных реализациях использование Hyper-Threading давало небольшое (какое???) ускорение на малом количестве потоков, но ухудшало время на 16 потоках. После применения описанных выше оптимизаций редукции Hyper-Threading стал давать выигрыш в среднем 5\%.



\textbf{Linux huge pages.}
Увеличение объёма страниц памяти $\Rightarrow$ уменьшение количества страниц $\Rightarrow$ меньше промахов в TLB кэш.
К сожалению, на данный момент хоть и huge pages включены в ядре Linux, однако, настройки системы по умолчанию не позволяют их использовать без дополнительных действий со стороны администратора системы, потому данная оптимизация не была протестирована на Intel Xeon.

Чуть лучше дела обстоят на ускорителе Intel Xeon Phi, где huge pages разрешены ``из коробки''. Использование huge pages на данном ускорителе дало такой-то выигрыш.


\subsection{Результаты}
Тут должны быть графики.

\newpage
\section{Заключение}
На данный момент исследованы последовательные алгоритмы построения остовных деревьев и выбраны из них те, которые или модификации которых могут дать хорошую масштабируемость при распараллеливании. Так же изучены статьи  \cite{dense-mst,boruvka-prima,boruvka-cm5} по распараллеливанию данных алгоритмов.

Были написаны последовательные реализации алгоритмов для дальнейшей проверки корректности получаемых результатов. Затем был написан и распараллелен алгоритм Борувки в нескольких реализациях, использующих разные структуры данных для хранения графа.

В дальнейших планах есть как оптимизация существующих алгоритмов, так и реализация новых.

В уже реализованных алгоритмах ближайшей целью является использование таких подходов как параллельные алгоритмы поиска компонент связности в тех шагах, где происходит объединение вершин одной компоненты.

Далее возможно использование других  структур данных в алгоритме Борувки. Рассматриваются такие структуры, как списки отсортированных списков смежностей, являющиеся промежуточным вариантом между поддержанием списков смежностей отсортированными на каждой итерации и полным отказом от сортировки списков, и деревья или кучи, позволяющие при дополнительных условиях производить их слияние за время, пропорциональное их высоте.

Так же планируется не только модификация алгоритма Борувки, но и реализация модифицированного алгоритмы Примы.

\newpage
\bibliographystyle{unsrt}
\bibliography{conference}

\end{document}
