\documentclass[a4paper,10pt]{extarticle}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}

\usepackage{graphicx}
\graphicspath{ {./plots/} }

\usepackage{amsmath,amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{textcomp}
%\usepackage{expdlist}
%\usepackage{textpos}
\usepackage{cmap}

\usepackage{pgfplots}

\usepackage[left=25mm,right=15mm,top=28mm,bottom=29mm]{geometry}

%\usepackage{algorithm}
%\usepackage{algpseudocode} % for \begin{algorithm}
\usepackage[lined,linesnumbered]{algorithm2e}

%\hoffset=-3cm
%\textwidth=18cm
%\voffset=-3cm
%\textheight=23cm

\date{}
\title{Построение MST на мультипроцессоре с ccNUMA архитектурой}
\author{Зайцев Вадим, zaic101@gmail.com \\ Новосибирский государственный университет\thanks{Работа поддержана Грантом Президента РФ для молодых учёных МК-3644.2014.9}}

\usepackage{indentfirst}
\tikzset{every mark/.append style={scale=1.65}}
\pgfplotsset{compat=1.3}

\begin{document}

%\maketitle
%\newpage

\tableofcontents



\newpage
\section{Введение}
% 1     Введение
% 1.1   Актуальность обработки графов
Задача обработки и анализа больших данных стоит повсеместно и возникает во множестве областей, как то известные поисковики, провайдеры, социальные сети, сотовые операторы, такие области науки как биоинформатика (обработка генов и генных сетей) \cite{graph-usage-bio} и многие другие.
Объёмы обрабатываемых данных составляют от десятков гигабайт до террабайт и выше в зависимости от области.
Такие данные зачастую представимы в виде графов, где вся необходимая информация хранится в вершинах и рёбрах или дугах графах и анализ таких данных сводится к классическим алгоритмам на графах.
Большие объёмы данных неизбежно ведут к тому, что размеры получаемых графов так же достаточно велики. В ряде работ исследуется проблематика получения эффективных параллельных реализаций алгоритмов на графах \cite{large-graph-0, large-graph-a, large-graph-b}.
Одним из таких алгоритмов является алгоритм построения минимального остовного дерева.

% 1.2   Постановка задачи MST
В данной работе рассматривается задача построения минимального остовного дерева (minimum spanning tree --- MST) на мультипроцессоре с ccNUMA архитектурой.
В теории графов остовным деревом называется ацикличный связный подграф данного связного неориентированного  графа, в который входят все его вершины. Минимальными остовным деревом называется остовное дерево во взвешенном графе с минимальной суммой весов рёбер.
В случае, когда данный граф не является связным, для каждой компоненты будет построено своё остовное дерево и полученные деревья называются остовным лесом.

% 1.3   Применение MST (из английской википедии) % TODO ссылки, более подробное описание
Минимальные остовные деревья имеют широкое практическое применение.
Они используются при построении различных сетей: коммуникационных линий, компьютерных сетей, транспортных сетей \cite{mst-usage-network}.
Так же они используются в задачах кластеризации \cite{mst-usage-cluster}, сегментации при обработке изображений \cite{mst-usage-image}, распознавании рукописного ввода \cite{mst-usage-handwrite}.
Минимальные остовные деревья  используются как приближённое решение переборной задачи: например, задачи Штейнера --- построение кратчайшей сети, соединяющей заданный конечный набор точек на плоскости \cite{shtree}.

% 1.4   Обзор существующих статей
% ToDo Возможно, полностью перенести в 2.1

%\newpage
\section{Обзор алгоритмов построения MST}
% 2     Подробно об алгоритмах
% 2.1   Обзор существующих
%Существует несколько различных последовательных алгоритмов построения MST. %, которые, в зависимости от используемых в реализации структур данных, имеют асимптотическую оценку времени работы $O(E\cdot\log E)$ для разреженных  и $O(V^2)$ для полных графов.
Существуют различные последовательные алгоритмы построения MST, наиболее распространёнными из которых являются алгоритмы Крускала, Прима и Борувки \cite{cormen}.
Не каждый из алгоритмов в его оригинальном варианте возможно эффективно распараллелить, однако, для некоторых из них существуют модификации, за счёт которых использование нескольких ядер одного узла кластера и даже использование нескольких узлов кластера может оказаться оправданным \cite{boruvka-prima,kruskal-parallel}.

%\subsection{Последовательные алгоритмы}

\textbf{Алгоритм Крускала} строит остовное дерево в два этапа: сначала все рёбра графа сортируются в порядке неубывания веса (рёбра одинакового веса могут идти в произвольном порядке), затем рёбра последовательно обходятся и в остовное дерево добавляются те из них, которые не создают цикла.

Сортировка рёбер в общем случае может быть выполнена за время $O(E \cdot \log(E))$, проверка образования цикла для каждого ребра может быть реализована с помощью системы непересекающихся множеств и выполняться за время $O(\alpha(E))$, где $\alpha(E)$~---~обратная функция Аккермана, значения которой малы и, например, для тестируемых RMAT и SSCA2 графов, в которых количество рёбер от 10 до 100 миллионов, не превосходят 5. Итоговая оценка времени работы получается $O(E \cdot \log(E) + E \cdot \alpha(E))$.

%, каждый следующий из которых зависит от результата предыдущего, что делает распараллеливание данного алгоритма неэффективным.
% TODO описать шаг точно так же

\textbf{Алгоритм Прима} начинает построение остовного дерева с произвольно выбранной вершины. Затем, пока дерево не будет построено полностью, выбирается ребро минимального веса, соединяющее вершину уже построенной части дерева с вершиной не из дерева, и выбранное ребро добавляется в строящееся остовное дерево.

Число шагов в алгоритме Прима равно числу вершин графе. Время поиска ребра минимального веса на каждом шаге зависит от выбранной структуры данных: при использовании матрицы смежности для поиска минимального ребра потребуется просмотреть всю строку матрицы за линейное время, а при использовании кучи добавление и удаление каждого ребра будет происходить за логарифмическое время. 
Таким образом, алгоритм Прима возможно реализовать со временем работы $O(V^2)$, что является лучшей оценкой для полных графов, либо со временем $O(E \cdot \log(V))$, что более предпочтительно для разреженных графов.

%===
%В алгоритме Прима шаги так же связаны между собой, а распараллеливание одного шага не даст большого %выигрыша в силу большого количества шагов и малой вычислительной сложности одного шага.
%Однако, существует параллельный алгоритм построения MST, являющийся модификацией алгоритма Прима.
%Алгоритм Борувки в своём оригинальном виде является наиболее пригодным для распараллеливания. 
%TODO возможно, заменить на псевдокод
%Далее опишем алгоритм Борувки и модифицированный алгоритм Прима.
%===

% 2.1.1 Разные реализации Борувки, ПочтиПрима
\textbf{Алгоритм Борувки}.
Это итерационный алгоритм: изначально каждая вершина графа считается отдельной компонентой, затем на каждой итерации для каждой компоненты находится инцидентное ей ребро, соединяющее её с другой компонентой, минимального веса и по найденным рёбрам компоненты объединяются. Алгоритм работает до тех пор, пока не останется одна компонента и пока между имеющимися компонентами есть рёбра.

На каждой итерации алгоритма множество компонент уменьшается не менее, чем в два раза, следовательно количество итераций можно оценить сверху как $\lceil \log_2(V) \rceil$. На каждой итерации в худшем случае необходимо просмотреть все рёбра, при этом процедура обработки одного ребра достаточно простая (определение каким компонентам принадлежат инцидентные вершины и, возможно, обновление рекорда для данных компонент). Итоговая временная сложность получается $O(E \cdot \log(V))$.

\subsection{Параллельные алгоритмы}

С точки зрения параллелизма про алгоритмы Крускала и Прима можно сказать следующее:
\begin{itemize}
	\item они состоят из большого количества шагов, которые зависимы между собой и не могут исполняться параллельно
	\item вычислительная сложность одного шага достаточно маленькая и её распараллеливание будет неэффективно
\end{itemize}
Это делает распараллеливание данных алгоритмов в оригинальном варианте бесперспективным. 

Исключением является реализация алгоритма Прима для плотных графов с обновлением матрицы смежности вместо использования кучи: в этом случае сложность одного шага составляет $O(V)$ и её возможно распараллелить, разделив матрицу между потоками. Однако, не для плотных графов такой подход асимптотически хуже других алгоритмов и при распараллеливании даже на большое число вычислителей будет медленнее последовательных реализаций других алгоритмов на больших графах.

В то же время алгоритм Борувки обладает противоположными свойствами:
\begin{itemize}
	\item количество итераций небольшое
	\item вычислительная сложность одной итерации большая и может быть распределена между потоками
\end{itemize}
Это делает алгоритм Борувки наиболее пригодным для распараллеливания и в перспективе может дать хорошую масштабируемость.

В статьях \cite{dense-mst,boruvka-prima,boruvka-cm5} представлены различные варианты параллельных реализаций алгоритма Борувки.
Разные реализации используют разные структуры данных для хранения рёбер (хранение рёбер одним большим списком или хранение для каждой вершины списка инцидентных ей рёбер) и разные способы их объединения (слияние и копирование списков, объединение списков за константное время и т. д.).

%\subsubsection{Модифицированный алгоритм Прима}
В статье \cite{boruvka-prima} представлен параллельный алгоритм построения MST на основе последовательного алгоритма Прима.
Суть данного алгоритма заключается в том, что каждый поток выбирает случайную вершину в графе и начинает ``растить'' дерево из выбранной вершины, пока не попытается присоединить вершину, уже принадлежащую другому дереву, после чего два дерева встретившихся потоков объединяются, один из них продолжает ``растить'' объединённое дерево, а второй заново выбирает вершину графа. % TODO перечитать их алгоритм
К преимуществам данного подхода относится отсутствие барьерной синхронизации, которая требуется в алгоритме Борувки после каждой итерации и, в зависимости от реализации, между разными шагами одной итерации. Другим преимуществом перед алгоритмом Борувки является то, что каждое ребро будет просмотрено ровно один раз.

% статья про Крускала ???

%\newpage
\section{Варианты алгоритма Борувки}
\label{sec:boruvkaIntro}
% 2.2   Обзор недостатков существующих
В данных работах \cite{dense-mst,boruvka-prima,boruvka-cm5} результаты производительности показаны либо для старых архитектур \cite{dense-mst,boruvka-cm5}, либо масштабируемость была ограничена шестью одноядерными процессорами (SMP  UMA, UltraSPARC II) \cite{boruvka-prima}.
% 2.2.1 Малое количество ядер
% 2.2.2 SMP системы

% 2.3   Цель работы
Настоящая работа направлена на адаптацию существующих и реализацию новых алгоритмов, ориентированных на высокую эффективность на больших графах на современных вычислителях с общей памятью с ccNUMA архитектурой.
Исследование началось с реализаций, предложенных в статье \cite{boruvka-prima}, а так же их модификаций. Затем, в разделе \ref{subsec:BoruvkaEA} на основе сделанных выводов будет предложен собственный подход к хранению графа в алгоритме Борувки.

В частности, далее будут представлены результаты тестирования описанных реализаций на двухсокетной системе $2$~$\times$~Intel Xeon CPU E5-2690 (8 ядер 2.9 GHz, 32KB L1 cache, 256KB L2 cache, 20MB L3 cache). Производительность полученных реализаций будет показана в MTEPS~---~величине, обратно пропорциональной времени. Более подробно об используемом окружение и замерах времени описано в разделе \ref{sec:results}.

\subsection{Списки смежности (Adjacency Lists --- AL)}
\label{subsec:boruvkaAL}
%Наибольшая вычислительная сложность первого алгоритма заключается в первом шаге, в котором необходимо обойти б\`oльшую часть рёбер графа, однако, основным препятствием для хорошей масштабируемости является то, что размер массива, редуцируемого на втором шаге, увеличивается с ростом количества потоков.

Первый вариант алгоритма Борувки для хранения графа использует списки смежности для каждой компоненты. Изначально каждая компонента представлена одной вершиной и её список смежности совпадает со списком смежности вершины, затем после каждой итерации для каждой образовавшейся компоненты явно строится список всех рёбер, инцидентных данной компоненте.
В качестве списков может быть использована любая структура данных, позволяющая последовательно обходить элементы. В данном подходе использовались динамически выделяемые массивы.

Изначально множество вершин графа разделяется между потоками равномерно по количеству инцидентных вершинам рёбер.
Далее на каждой итерации алгоритма Борувки выполняются следующие шаги, пока не останется одна компонента или между несколькими оставшимися компонентами не будет рёбер:
\begin{enumerate}
    \item \textit{Минимальное инцидентное ребро}.
        Каждый поток для каждой своей компоненты находит инцидентное ей ребро минимального веса. Это делается обходом всех инцидентных компоненте рёбер.
    \item \textit{Объединение деревьев}.
% используемый алгоритм для выделения компонент ???
        Компоненты объединяются по найденным рёбрам: выделяются образовавшиеся компоненты, для каждой такой компоненты определяется номер на следующей итерации.
        В качестве номера компоненты используется номер одной из вершин, входящих в данную компоненту.
          Так же решается проблема с возможными циклами (когда более двух компонент по кругу выберут следующую компоненту в качестве ближайшей), которые возможны в алгоритме Борувки при наличии в графе рёбер одинакового веса.
          % описать алгоритм разрешения петель ???
    \item \textit{Перенумерация компонент}.
          Осуществляется перенумерация компонент: для каждой вершины вычисляется номер компоненты, в которую она входит, используя параллельный алгоритм Pointer Jumping \cite{pointer-jumping}. 
    \item \textit{Слияние списков}.
        Происходит объединение компонент путём слияния списка рёбер. В модификации с неотсортированными списками рёбер слияние делается последовательным копированием одного списка в другой. При использовании отсортированных по весу списков вместо копирования и последующей сортировки рёбер происходит слияние с использованием приёма, который используется в сортировки слиянием: из голов копируемых списков выбирается минимальные элемент, извлекается и добавляется в создаваемый список.
        % это как асимптотическое улучшение, так и практическое
%    \item \textit{Перенумерация}.
%        Обход списков рёбер и перенумерация компонент: старые номера заменяются на новые, полученные на шаге \textit{Объединения деревьев}.
\end{enumerate}
%Для балансировки нагрузки необходимо  после каждой итерации распределять компоненты между потоками. Изначально для каждой компоненты случайно выбирался номер потока, которому она принадлежит, но такой подход создавал большую разницу в количестве рёбер???


Были опробованы два подхода относительно сортированности списков смежности:
\begin{itemize}
    \item \textbf{Отсортированные по весу списки смежности}. 
        Отсортированные списки позволяют осуществлять шаг \textit{минимальное инцидентное ребро} за константное время, просмотрев лишь голову списка, однако поддержание таких списков сортированными на шаге \textit{слияния списков} требует дополнительного времени.
    \item \textbf{Неотсортированные списки смежности}.
        Когда поддержание списков отсортированными не требуется, их объединение возможно осуществлять простым копированием памяти, но поиск по неотсортированному списку возможен только за линейное время.
\end{itemize}

На практике подход с сортировкой списков по весу оказался заметно медленнее. 
На рисунке \ref{fig:BorvukaAlCmp} показано сравнение производительности обоих подходов на RMAT и SSCA2 графах: реализация со слиянием отсортированных списков обозначена как AL-Merge, реализация с копированием неотсортированных списков~---~AL-Copy. Подробное описание графов, на которых проводилось тестирование, приведено в разделе \ref{sec:results}.

\noindent \begin{figure}
\centering
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = RMAT-22-32,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{ 
    AL-Merge, 
    AL-Copy, 
};
\addplot[mark=square] coordinates {
    (1, 1.8524391711609425)
    (2, 0.9615400357340184)
    (4, 2.348982519632473)
    (8, 3.1259152510733618)
    (16, 4.846732624575107)
};
\addplot[mark=square*] coordinates {
    (1, 6.2414876971021908) 
    (2, 10.680330634169807) 
    (4, 16.072761217370383) 
    (8, 18.8400317131250874) 
    (16, 22.17363702963703)
};
\end{semilogxaxis}
\end{tikzpicture}
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = SSCA2-22,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{ 
    AL-Merge, 
    AL-Copy, 
};
\addplot[mark=square] coordinates {
    (1, 5.505532774483746) 
    (2, 2.9371248691099474) 
    (4, 4.780153518426471) 
    (8, 5.195762898931038) 
    (16, 5.966136571099393)
};
\addplot[mark=square*] coordinates {
    (1, 12.738934998580755) 
    (2, 19.93157720207254) 
    (4, 28.350769425142136) 
    (8, 37.203040618955505) 
    (16, 35.71294535809019)
};
\end{semilogxaxis}
\end{tikzpicture}
\caption{Сравнение производительности реализаций AL-реализаций}
\label{fig:BorvukaAlCmp}
\end{figure}

В  подходе со списками смежности имеется две существенные проблемы. 
Первая из них заключается в том, что на шаге \textit{слияния списков} происходит копирования большого объёма данных и этот шаг исполняется долго.
Вторая проблема лежит в том, что при распределении компонент между потоками на шагах \textit{минимальное инцидентное ребро} и \textit{слияния списков} происходит дисбаланс нагрузки на последних итерациях, когда количество оставшихся компонент становится меньше числа потоков~---~в этом случае некоторые потоки просто простаивают без работы, что негативно сказывается на масштабируемости алгоритма.

%В ходе анализа работы шага \textit{Объединение деревьев} на тестируемых типах графов было выяснено, что количество объединяемых компонент в одну в большинстве случаев не превосходит трёх и это позволяет быстро и эффективно отсеивать петли на шаге \textit{Слияния списков} за счёт сокращения нерегулярных обращений в память.

\subsection{Списки вершин (Vertexes lists --- VL)}
\label{subsec:boruvkaVL}

% TODO ударения в слове большИх
%Основная проблема при реализации алгоритма Борувки, явно строящих список инцидентных рёбер каждой компоненты перед каждой итерации заключается в большом объёме копируемых на каждой итерации данных. 
%С целью уменьшить объём копируемых данных при первом и ускорить шаг слияния списков было решено для каждой компоненты хранить не список инцидентных рёбер, а список входящих в неё вершин.

В качестве решения первой проблемы предыдущего алгоритма~---~большого объёма копируемых данных после каждой итерации~---~списки смежности каждой компоненты были заменены на список входящих в неё вершин. Во-первых, такая модификация минимально влияет на другие шаги алгоритма. Во-вторых, на шаге \textit{слияния списков} это позволяет в несколько раз сократить размер объединяемых списков.

Общая схема алгоритма осталась прежней со следующими изменениями:
\begin{enumerate}
    \item На шаге \textit{минимальное инцидентное ребро} теперь для обхода рёбер требуется обойти не список рёбер, а список входящих в компоненту вершин и уже для каждой вершины обойти список инцидентных ей рёбер.
    \item На шаге \textit{слияние списков} теперь копируются не списки рёбер, а списки вершин, что значительно сокращает объём перемещаемых данных.
\end{enumerate}

Для хранения списка вершин были опробованы две структуры данных:
\begin{itemize}
	\item \textbf{Односвязные списки}. Их преимущество заключается в возможности объединения за константное время, однако, обход таких списков связан со случайными обращениями в память.
	\item \textbf{Динамические массивы}. Объединение массивов возможно только за линейное время путём копирования одного из них в другой (на практике используется копирование меньшего массива в больший). Но во время обхода массива хорошо работает аппаратная предвыборка, что позволяет в значительной степени избежать кэш-промахов.
\end{itemize}
%Данные модификации показывали примерно одинаковую производительность, однако, в среднем реализация с использованием динамических массивов оказалась на 5-10\% быстрее. - заменено картиной

В качестве решения второй проблемы~---~дисбаланс на последних итерациях~---~шаг \textit{минимальное инцидентное ребро} был разделён на два: сначала выделяются компоненты с небольшим количеством входящих в них вершин и обрабатываются как и раньше. Затем остаётся несколько компонент, состоящих из большого числа вершин, и работа по таким компонентам уже разделяется между потоками: каждый поток обрабатывает свою часть вершин, находит среди них минимальное ребро и в конце по всеми потокам находится итоговое ребро минимального веса.
%Данная оптимизация улучшила производительность алгоритма и позволила получить ускорение на 2 сокетах. --- описано в следующем абзаце

%\includegraphics[scale=0.45]{partvl_rmat22}
%\includegraphics[scale=0.45]{partvl_ssca22}

\noindent \begin{figure}
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = RMAT-22-32,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{ 
    VL-List, 
    VL-Vec, 
    VL-Vec-Bal,
};
\addplot[mark=o] coordinates {
(1, 15.206127620990592) 
(2, 23.018857535187093) 
(4, 31.616371435305207) 
(8, 38.83494468578048) 
(16, 35.44427921734532)
};
\addplot[mark=otimes] coordinates {
(1, 21.671353312813866) 
(2, 32.05475215311005) 
(4, 43.63822453628376) 
(8, 50.643226586102716) 
(16, 37.67731758087201)
};
\addplot[mark=*] coordinates {
(1, 38.684420566146733) 
(2, 67.44000201106083) 
(4, 107.80270200803212) 
(8, 127.652392007611805) 
(16, 124.82685023255814)
};
\end{semilogxaxis}
\end{tikzpicture}
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = SSCA2-22,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{ 
    VL-List, 
    VL-Vec, 
    VL-Vec-Bal,
};
\addplot[mark=o] coordinates {
(1, 18.385607537894305) 
(2, 31.130128092485545) 
(4, 52.1044133126935) 
(8, 81.0582805538832) 
(16, 104.6950264385692)
};
\addplot[mark=otimes] coordinates {
(1, 20.331894291754757) 
(2, 32.7585897810219) 
(4, 52.16497636574971) 
(8, 65.35815728155339) 
(16, 56.73738053097345)
};
\addplot[mark=*] coordinates {
(1, 43.586210424085465) 
(2, 74.22150165380376) 
(4, 114.29355178268253) 
(8, 127.98270342205323) 
(16, 114.87867235494882)
};
\end{semilogxaxis}
\end{tikzpicture}
\caption{Сравнение производительности FL-реализаций}
\label{fig:BorvukaVLCmp}
\end{figure}

На рисунке \ref{fig:BorvukaVLCmp} отображено сравнение производительности обоих описанных подходов: с использованием односвязных списков (график VL-List) и с использование динамических массивов (график VL-Vec).
Для реализации на векторах так же показано её сравнение с оптимизацией (график VL-Vec-Bal), устраняющей дисбаланс и без неё: как видно из графиков, это заметно увеличило производительность и сделало подход более масштабируемым. 
Для реализации на связных списках применить описанную оптимизацию в простом варианте не удастся, поскольку при делении списка между потоками требуется обращение к произвольному элементу списка, чего односвязные списки в простой реализации дать не могут.

\subsection{Массив рёбер (Edges Array --- EA)}
\label{subsec:BoruvkaEA}

Поскольку за счёт предыдущей модификации полностью решить проблему копирования больших объёмов данных не удалось, то следующий алгоритм разрабатывался с целью полностью избежать перемещения списков рёбер или вершин после каждой итерации.
Если ранее использовался подход, когда для каждой компоненты хранилась информация, позволявшая восстановить список инцидентных рёбер, то теперь будет использоваться информация для каждой вершины о том, какой компоненте она принадлежит.

Изначально все вершины распределяются между потоками равномерно по количеству рёбер. Далее на каждой итерации алгоритма Борувки выполняются следующие шаги:

\begin{enumerate}
    \item \textit{Минимальное инцидентное ребро}.
		Каждый поток обходит все свои вершины и находит минимальное ребро для всех компонент, которые представлены в данном потоке хотя бы одной вершиной.
        В результате каждый поток будет иметь массив, содержащий минимальное ребро для каждой компоненты среди просмотренного подмножества.
    \item \textit{Редукция}.
          Происходит редукция полученного на предыдущем шаге массива: для каждой компоненты находится ребро минимального веса по всем потокам. 
          Таким образом, для каждой компоненты определяется минимальное ребро уже во всём графе.
    \item \textit{Объединение деревьев}.
          Для каждой компоненты определяется её номер на следующей итерации.
          Так же решается проблема с возможными циклами (когда более двух компонент по кругу выберут следующую в качестве ближайшей), которые возможны в алгоритме Борувки при наличии рёбер одинакового веса.
    \item \textit{Перенумерация}.
          Осуществляется перенумерация компонент: для каждой вершины вычисляется номер компоненты, в которую она входит, используя параллельный алгоритм Pointer Jumping \cite{pointer-jumping}.
\end{enumerate}

Основная проблема данного подхода заключается в шаге \textit{редукции}: объём редуцируемого массива растёт линейно с ростом числа потоков, таким образом, среднее время выполнения данного шага почти не уменьшается с ростом количества потоков.
Однако, даже с описанной проблемой подход с уменьшением объёма копируемых данных себя оправдал и данный подход показала лучшие результаты производительности среди описанных алгоритмов.
Далее будут подробно рассмотрены оптимизации, применённые к данному подходу хранения графа.

%\newpage
%\section{Результаты}
% 2.5   На чём проводилось тестирование
% 2.5.1 Параметры графов
%Тестирование проводилась на графах, состоящих из $10^6-10^8$ вершин и $10^7-10^9$ рёбер: это RMAT-графы %степени $20\,-\,23$, двумерные и трёхмерные решётки, а так же случайные графы.

% 2.5.2 Характеристика систем
%Характеристики систем, на которых производились запуски:
%\begin{itemize}
%    \item 2 $\times$ Intel Xeon CPU E5-2690 (8 ядер 2.9 GHz, 32KB L1 cache, 256KB L2 cache, 20MB L3 cache)
%    \item 8 $\times$ Intel Xeon CPU Е7-4870 (10 ядер 2.4 GHz, 32KB L1 cache, 256KB L2 cache, 30MB L3 cache)
%\end{itemize}

%[Позже будут добавлены результаты тестирования двух описанных алгоритмов].

\newpage
\section{Оптимизации EA реализации}
\label{sec:eaopt}

\subsection{Алгоритмические оптимизации}
\label{subsec:optAlgo}

\textbf{Предварительная сортировка рёбер.}
Алгоритм Борувки предполагает на каждой итерации просмотр всех рёбер графа, что и создаёт наибольшую вычислительную сложность первого шага.
Объём ``лишней'' работы при этом достаточно велик: во-первых, постоянно будет просматриваться большое количество петель (рёбер, которые на данной итерации соединяют компоненту саму с собой), которых с каждой итерацией становится всё больше и больше, во-вторых, при обходе рёбер на шаге \textit{поиска минимального ребра} хотелось бы уменьшить количество просматриваемых рёбер за счёт тех, вес которых уже больше, чем рекорд для текущей компоненты.

Проблему с петлями возможно попытаться решить их удалением, однако, это повлечёт за собой частичное перестроение внутреннего представления графа, что, как было выявлено в ходе исследования, негативно сказывается на производительности.

Решить обе обозначенные проблемы возможно за счёт предварительной сортировки списков смежности каждой вершины по возрастанию веса рёбер. Затем для каждой вершины поддерживается индекс последнего просмотренного ребра: изначальной данный индекс указывает на первое ребро в списке, затем, по мере отбрасывания петель, он сдвигается и на следующей итерации поиск минимального ребра начинается не с начала списка, а с позиции, на которую указывает индекс. С другой стороны, если мы берём очередное ребро и его вес больше, чем текущий рекорд для компоненты, то поиск можно прервать, так как вес последующих рёбер данной вершины заведомо больше текущего рекорда.

Данная оптимизация хорошо масштабируется и на большом количестве потоков время выполнения невелико. В среднем производительность от данной оптимизации увеличивается на 20\%.



\textbf{Перенумерация вершин.}
В работе \cite{sparse-matrix-renum} предлагается алгоритм перенумерации вершин, который повышает локальность данных при последующих обходах графа, за счёт чего уменьшается количество кэш-промахов. %(Статистика по кэш-промахам из intel vtune???)
Предложенный алгоритм перенумеровывает вершины в порядке обхода в ширину с предварительной отсортировкой списков смежности каждой вершины по возрастанию степени вершины, в которую ведёт ребро.


\textbf{Балансировка больших вершин.}
Одной из особенностей RMAT-графов являет наличие вершин, степень которых значительно отличается от средней степени всех вершин графа. Например, в RMAT-графе с $2^{20}$ вершинами есть 1351 вершина степени выше 1000, а максимальная степень вершины достигает 15078, при этом средняя степень вершины равна 32. Такие вершины создают дисбаланс на последних итерациях, когда просматривается большое количество рёбер и отбрасываются петли.

С целью устранения данного дисбаланса на стадии предварительно обработки графа выделяются вершины степени более 1000 и равномерно распределяются между потоками. Значение степени 1000 было подобрано эмпирически и хорошо показало себя на практике.

В среднем оптимизации \textbf{перенумерация вершин} и \textbf{балансировки больших вершин} дают увеличение производительности в 11\%.



\textbf{Отдельный цикл пропуска петель.}
Шаг \textit{поиск минимального ребра} с учётом оптимизации \textbf{предварительной сортировки рёбер} данный шаг выглядит следующим образом:

\begin{algorithm}[H]
    \SetAlgoLined
    \KwData{ $v$ --- индекс обрабатываемой вершины }
%    \KwData{ $component[]$ --- массив компонент }
    $myComp \gets component[v]$\;
    \ForEach{$edgeId$ $\gets$ $edgesIdsBegin[v]$ \textbf{to} $edgesIdsEnd[v]$}{
        $destVertex \gets edges[edgeId].destination$\;
        $destComp \gets component[destVertex]$\;
        \lIf{$destComp = myComp$}{ перейти к следующей итерации }
        \lIf{$edges[edgeId] < currentRecord[myComp]$}{ $currentRecord[myComp] \gets edges[edgeId]$ }
        закончить цикл\;
    }
%    \caption{Какой-то шаг до какой-то оптимизации}
\end{algorithm}

Б\`oльшая часть времени исполнения цикла находится в строках 2-5 и заключается в пропуске рёбер до тех пор, пока не найдётся ребро, ведущее в другую компоненту. Явное вынесение этих строк в отдельный цикл и разбиение цикла на две части ведёт к тому, что более просто цикл исполняется быстрее:

\begin{algorithm}[H]
    \SetAlgoLined
    \KwData{ $v$ --- индекс обрабатываемой вершины }
    $myComp \gets component[v]$\;
    $edgeId \gets edgesIdsBegin[v]$\;
    \While{$edgeId \neq edgesIdsEnd[v]$ \textbf{and} $component[edges[edgeId].destination]$ = $myComp$}{
        $edgeId \gets edgeId + 1$\;
    }
    \If{$edges[edgeId] < currentRecord[myComp]$}{
        $currentRecord[myComp] \gets edges[edgeId]$
    }
%    \caption{Какой-то шаг после этой оптимизации}
\end{algorithm}

%Написать, что петель отбрасывается очень много и потому данная модификация даёт улучшение производительности. Где статистика по петлям???

В среднем данная оптимизация ведёт к увеличению производительности на 10\%.


\subsection{Оптимизация редукции}
\label{subsec:optReduction}

Поскольку основные проблемы масштабируемости лежат именно в шаге \textit{редукции}, то было сделано несколько оптимизаций, непосредственно затрагивающих данный шаг. 
Приведённые оценки увеличения производительности получены при запуске 32 потоков на всех 16 ядрах процессоров (исполнялось по 2 потока на одно ядро, поскольку в процессоре была включена технология Hyper Threading, использование которой описано далее в разделе \ref{subsec:optArch})
%(ссылка???)
и показывают ускорение не одного только шага \textit{редукции}, а исполнения всего алгоритма.

\textbf{Отсутствие редукции на первой итерации.}
Поскольку каждая компонента изначально представлена одной вершиной, то от редукции на первой итерации можно отказаться. Данная оптимизация выглядит простой и очевидной, однако, объём редуцируемого массива на первой итерации больше, чем на всех последующих, и данная модификация даёт ускорение в 20\%.

\textbf{Перенумерация и сжатие массива компонент по ходу исполнения алгоритма.}
В начальной реализации при объединении компонент в качестве её номера выбирался один из номеров вершин, которые в неё входят. Таким образом, несмотря на сокращение числа компонент, диапазон используемых номеров не изменялся (минимальный и максимальный номер были приблизительно равны соответственно первой и последней вершине). Такой подход затруднял обход всех компонент на шаге редукции: требовалось либо обходить весь диапазон номеров и совершать лишнюю работу, просматривая ``пустые'' номера, не являющиеся компонентами, либо отдельно поддерживать массив, в которым хранить индексы всех ``живых'' на данный момент компонент, что усложняло реализацию и приводило бы к увеличению кэш-промахов из-за обхода массива с непостоянным шагом.

Явная перенумерация компонент на каждой итерации на последовательные номера позволила решить обозначенную проблему. В среднем производительность увеличилась на 20\%.

%Более того, это позволило уменьшить объём используемой памяти: в начальной реализации для каждого потока создавался двумерный массив размера \texttt{количество\_потоков}$\times$\texttt{количество\_вершин}
%На системах с больш\`{и}м количеством ядер, например, на Intel Xeon Phi, где используется до 240 потоков, объём такого массива заметно превосходит объём всех других данных и его сокращение в 2 раза приводит к значительному уменьшению потребляемой памяти (описать про память более понятно???).
%подумать и, возможно, вернуть ???

\textbf{Иерархическая редукция.}
Особенностью NUMA архитектуры являются высокие задержки при обращении в память другого узла NUMA.
При стандартном подходе к редукции, когда для каждой компоненты последовательно обходятся все потоки и выбирается лучший результат, таких обращений при двух NUMA узлах будет как минимум половина, а при большем количестве узлов NUMA~---~ещё больше. 
%Долю обращений к другому узлу NUMA 
%(тут можно указать достаточно точную оценку $\displaystyle \frac{\texttt{число NUMA узлов - 1}}{\texttt{число NUMA узлов}}$, но стоит ли???)

Данную проблему можно решить за счёт иерархического подхода к редукции. При таком подходе шаг редукции разбивается на два этапа: на первом происходит стандартная редукция внутри NUMA узла, а на втором~---~между узлами. Количество обращений к чужому узлу NUMA в этом случае уменьшается в количество раз, равное количеству используемых потоков в одном узле NUMA. Иерархическая редукция повысила производительность на 5\%.
%Может, добавить красивую картинку(???)

%\textbf{Сообщения в редукции.}
%В редуцируемом массиве много пустых элементов. Через сообщения можно уменьшить объём редуцируемых данных.

\subsection{Архитектурные оптимизации}
\label{subsec:optArch}

\textbf{Программная предвыборка.}
Обход рёбер в общем случае неизбежно связан со случайными обращениями в память: невозможно отсортировать рёбра так, чтобы индексы обеих инцидентных вершин шли последовательно.
Аппаратная предвыборка современных процессоров ориентирована только на последовательные обращения в память (на обход с постоянным, возможно отрицательным, шагом, размер которого не превосходит размер страницы памяти) и подобный обход рёбер вызывает простои, связанные с ожиданием данных.

Однако, адреса случайных обращений в память при таких обходах в большинстве случаев можно предсказать: обходя рёбра последовательно, нам известны индексы обеих инцидентных вершин вершин для следующих итераций. Как раз в таком случае и помогает программная предвыборка, давая возможность заранее запросить нужные данные для будущих вершин (например, какой компоненте они принадлежат) и сократить время ожидания.

%Другой особенностью аппаратной предвыборки является то, что данные не всегда загружаются в кэш первого уровня (например, на Intel Xeon Phi). Дополнить про L1 cache???

В среднем программная предвыборка позволила повысить производительность на 30\%, а шаг \textit{перенумерация вершин}, где используется алгоритм Pointer Jumping, ускоряется до 2-3 раз. %Сказать про то, что стадии типа PJ и того можно ускорить в несколько раз.

%Сказать про двойную предвыборку ???
Иногда, в одном цикле целесообразно использование программной предвыборки для двух массивов с разным шагом. Так, в коде шага \textit{поиски минимального ребра}:

\begin{algorithm}[H]
    \SetAlgoLined
    \For{$vertexId$ from $1$ to $vertexCount$}{
    	$edgeId \gets startEdge[vertexId]$\;
	    $destComp \gets component[edges[edgeId].destination]$\;
   	    \ldots
    }
%    \caption{возможно, данный заголовок стоит выпилить}
\end{algorithm}
предвыборка для переменной $edgeId$ делается достаточно легко, а вот переменная $destComp$ зависит от значения $edgeId$ и прежде, чем будет возможно сделать предвыборку для $destComp$, необходим получить значение $edgeId$.
Предвыборки для обеих переменных без лишних простоев возможно реализовать, делая их с разным шагом: если предвыбирать $edgeId$ с удвоенным шагом относительно $destComp$, то обе предвыборки не будут зависеть друг от друга:

%\begin{algorithm}[H]
%    \SetAlgoLined
%    \For{$vertexId$ from $1$ to $vertexCount$}{
%    	$prefetch(\&component[edge[startEdge[vertexId + prefetchStep]].dest])$\;
%    	$edgeId \gets startEdge[vertexId]$\;
%	    $destComp \gets component[edges[star%tEdge].dest]$\;
%   	    \ldots
%    }
%    \caption{возможно, данный заголовок стоит выпилить}
%\end{algorithm}

%Однако, здесь адрес второй предвыборки зависит от случайного обращения к элементу $edge[startEdge[vertexId + prefetchStep]$ и более эффективным будет заранее загрузить в кэш данный элемент:

\begin{algorithm}[H]
    \SetAlgoLined
    \For{$vertexId$ from $1$ to $vertexCount$}{
	    $prefetch(\&edge[startEdge[vertexId + prefetchStep \times 2]])$\;
    	$prefetch(\&component[edge[startEdge[vertexId + prefetchStep].dest]])$\;
    	$edgeId \gets startEdge[vertexId]$\;
	    $destComp \gets component[edges[edgeid].destination]$\;
   	    \ldots
    }
%    \caption{возможно, данный заголовок стоит выпилить}
\end{algorithm}



\textbf{Выделение памяти с учётом NUMA архитектуры}
Как уже отмечалось ранее, обращение в память другого узла NUMA связано с высокими задержками. Выделение памяти на тех ядрах, где она используется, является более правильным на NUMA архитектуре.

%В случае использования двумерных массивов, когда первая размерность соответствует номеру потока (например, массив в котором хранится текущий лучший результат для каждой компоненты), основной интерес представляет вторая размерность, поскольку к первой будет только одно обращение за итерацию, а ко второй --- на каждой вершине. Таким образом, первая размерность выделяется на произвольном узле NUMA, а затем каждой поток выделяет необходимую ему память (написано криво и, возможно, стоит улучшить???).

Все используемые в реализации массивы ограничиваются двумя размерностями. Более того, во всех двумерных массивах первая размерность соответствует индексу потока, в котором он используется (например, таким является массив, над которым происходит редукция: первая размерность соответствует номеру потока, вторая~---~компоненте, а значением является ребро минимального веса, которое данный поток нашёл для данной компоненты), и с точки зрения NUMA архитектуры такие массивы проблем не создают.

% написать про безысходность ситуации, когда один и те же страницы будут использоваться разными потоками

Когда разные части одномерного массива одновременно использует несколько потоков (например,  таким является массив рёбер), то возникает необходимость выделить непрерывную область в памяти на разных узлах NUMA. Ядро Linux предоставляет разработчику возможность явно управлять выделением страниц памяти на NUMA системах с использованием библиотеки libnuma. Однако, в реализациях использовалась особенность ядра Linux известная как memory overcommit: для программы выделение страниц памяти происходит не в момент вызова функции malloc (или аналогичной, запрашивающей у ядра операционной системы страницы памяти, но не инициализирующей их), а в момент первого обращения к странице. Таким образом, для разделения массива по узлам NUMA сначала с использованием функции malloc выделялся весь массив нужного размера, далее, каждый поток инициализировал те страницы, которые он будет использовать. При таком подходе, конечно, может возникнуть пересечение, когда два потока используют одну страницу, но размеры таких пересечений невелики по сравнению с размером всего массива, а их количество ограничено количеством потоков.

Был также опробован подход с дублированием массива, который используют одновременно несколько узлов NUMA. Одним из примеров таких данных является массив, где для каждой вершины хранится индекс компоненты, в которую она входит на текущей итерации. Однако, из-за необходимости после каждой итерации дополнительно обновлять массив на каждом узле NUMA данный подход себя не оправдал и производительность в лучшем случае не уменьшалась.



\textbf{Аппаратные потоки процессора.}
Современные процессоры позволяют на одном ядре исполнять одновременно несколько аппаратных потоков. Так в процессорах Intel и AMD данные технологии называются соответственно Hyper-Threading и Modules и позволяют запускать по 2 аппаратных потока на ядро, а ускоритель Intel Xeon Phi на данный момент имеет 4 аппаратных потока на каждое ядро. Использование такого вида многозадачности позволяет не только более эффективно использовать процессорные элементы, но и скрыть задержки в память за счёт переключения на другой поток.
% быть может, описать как-нить более литературно

Проблема использования аппаратных потоков для алгоритма EA заключается в увеличении объёма данных на шаге \textit{редукции}. В начальных реализациях использование Hyper-Threading давало небольшое
%какое?
ускорение на малом количестве потоков, но ухудшало время на 16 потоках. После применения описанных выше оптимизаций редукции Hyper-Threading стал давать выигрыш в среднем 5\%.



\textbf{Linux Huge Pages.}
Объём обрабатываемых данных, находящихся в памяти, составляет гигабайты, что во много раз больше размера одной страницы памяти в процессорах архитектуры x86, равного 4 килобайтам. Использование большого числа страниц виртуальной памяти приводит к частым промахам в TLB кэше, что, конечно же, отрицательно сказывается на производительности.
Размер страницы памяти зависит от архитектуры и во многих архитектурах, в том числе и в x86, реализована поддержка ``больших страниц''~---~страниц, размер которых равен нескольким мегабайтам или даже гигабайтам.

Увеличение объёма страниц памяти ведёт к уменьшению количества используемых страниц, что в свою очередь уменьшает число промахов в TLB кэше.
К сожалению, на данный момент хоть и huge pages включены в ядре Linux, однако, настройки системы по умолчанию не позволяют их использовать без дополнительных действий со стороны администратора системы, потому данная оптимизация не была протестирована на центральном процессоре Intel Xeon.

Лучше дела обстоят на ускорителе Intel Xeon Phi, где Huge Pages разрешены ``из коробки'' и не требуют дополнительных настроек. Использование Huge Pages на данном ускорителе дало выигрыш от 5\% до 15\%.

%\newpage
\section{Результаты}
\label{sec:results}

\noindent \begin{figure}[t]
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = RMAT-22-32,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{ EA, VL-List, VL-Vec-Bal, AL-Copy };
\addplot[mark=triangle*] coordinates { (2, 342.3921632653061) (4, 568.719186440678) (8, 794.1877396449704) (16, 1427.848170212766) };
\addplot[mark=o] coordinates { (1, 15.212255241981184) (2, 23.037715070374187) (4, 31.632742870610414) (8, 38.86988937156096) (16, 35.48855843469064) };
\addplot[mark=*] coordinates { (1, 38.76884113229347) (2, 67.48000402212166) (4, 107.80540401606424) (8, 127.70478401522361) (16, 124.85370046511628) };
\addplot[mark=square*] coordinates { (1, 6.2429753942043815) (2, 10.760661268339614) (4, 16.145522434740766) (8, 18.80063426250175) (16, 22.34727405927406) };
\end{semilogxaxis}
\end{tikzpicture}
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = SSCA2-22,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{ EA, VL-List, VL-Vec-Bal, AL-Copy };
\addplot[mark=triangle*] coordinates {(2, 397.16166371681413) (4, 673.18902) (8, 868.6309935483871) (16, 1583.9741647058822) };
\addplot[mark=o] coordinates { (1, 18.385607537894305) (2, 31.130128092485545) (4, 52.1044133126935) (8, 81.0582805538832) (16, 104.6950264385692) };
\addplot[mark=*] coordinates { (1, 43.586210424085465) (2, 74.22150165380376) (4, 114.29355178268253) (8, 127.98270342205323) (16, 114.87867235494882) };
\addplot[mark=square*] coordinates { (1, 12.738934998580755) (2, 19.93157720207254) (4, 28.350769425142136) (8, 37.203040618955505) (16, 35.71294535809019) };
\end{semilogxaxis}
\end{tikzpicture}
%\caption{Сравнение производительности разных реализаций}
%\label{fig:resultAllRmatSsca}
%\end{figure}
%
%\noindent \begin{figure}[t]
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = Random-22-27,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{     EA,     VL-List,    VL-Vec-Bal,    AL-Copy };
\addplot[mark=triangle*] coordinates { (2, 280.7902259414226) (4, 498.9506617100372) (8, 787.2007507331377) (16, 1420.293417989418) };
\addplot[mark=o] coordinates { (1, 20.05794336098035) (2, 30.709925180185333) (4, 42.96342125480153) (8, 54.82750326797385) (16, 52.46979202501955) };
\addplot[mark=*] coordinates { (1, 50.57186435568953) (2, 88.0116249180328) (4, 141.87920507399576) (8, 158.9315902901125) (16, 152.86757175398634) };
\addplot[mark=square*] coordinates { (1, 4.958264024086149) (2, 8.986490442234945) (4, 13.286253019204118) (8, 18.587138623459353) (16, 20.362243495410755) };
\end{semilogxaxis}
\end{tikzpicture}
\begin{tikzpicture}
\begin{semilogxaxis}[
    legend pos = north west,
    title = Grid-8000$\times$8000,
    xlabel = {Количество потоков},
    ylabel = {Производительность, MTEPS},
    xmin = 1,
    xmax = 16,
    log ticks with fixed point,
    log basis x = 2,
    grid = major,
]
\legend{     EA,     VL-List,    VL-Vec-Bal,    AL-Copy,};
\addplot[mark=triangle*] coordinates { (2, 65.89470974385378) (4, 119.77912962096396) (8, 179.81594661046717) (16, 317.18463444857497) };
\addplot[mark=o] coordinates { (1, 6.2560918978369795) (2, 11.24022395433088) (4, 19.313238012600443) (8, 30.601709606073285) (16, 33.43801436969301) };
\addplot[mark=*] coordinates { (1, 14.931777745369697) (2, 25.7538987825737) (4, 38.66002114484216) (8, 31.94209771011418) (16, 27.697668127468486) };
\addplot[mark=square*] coordinates { (1, 4.958264024086149) (2, 8.986490442234945) (4, 13.286253019204118) (8, 18.587138623459353) (16, 20.362243495410755) };
\end{semilogxaxis}
\end{tikzpicture}
\caption{Производительности алгоритмов на разных графах}
\label{fig:resultGridRand}
\end{figure}

\noindent \begin{figure}[t]
\begin{tikzpicture}
\begin{axis}[
    legend pos = north west,
    title = RMAT-32,
    xlabel = {Число вершин, степень 2},
    ylabel = {Производительность, MTEPS},
    xmin = 16,
    xmax = 25,
    xtick = data,
    grid = major,
]
\legend{ EA };
\addplot[mark=triangle*] coordinates {
(16, 419.4304) (17, 699.0506666666666) (18, 699.0506666666666) (19, 932.0675555555556) (20, 1198.3725714285715) (21, 1369.5686530612245) (22, 1412.8181894736842) (23, 1242.7567407407407) (24, 1376.592082051282) (25, 1063.1107168316832)
};
\end{axis}
\end{tikzpicture}
\begin{tikzpicture}
\begin{axis}[
    legend pos = north west,
    title = SSCA2,
    xlabel = {Число вершин, степень 2},
    ylabel = {Производительность, MTEPS},
    xmin = 16,
    xmax = 25,
    xtick = data,
    grid = major,
]
\legend{ EA };
\addplot[mark=triangle*] coordinates {
(16, 352.109) (17, 526.8495) (18, 700.6315) (19, 934.9746666666667) (20, 1246.2312592592593) (21, 1431.997574468085) (22, 1583.9741647058822) (23, 1652.0263312883435) (24, 1709.897834920635) (25, 1717.709658692185)
};
\end{axis}
\end{tikzpicture}
\caption{Сравнение производительности алгоритма EA на графах разного размера}
\label{fig:resultSize}
\end{figure}

Тестирование проводилось на следующих графах:
\begin{itemize}
    \item \textbf{RMAT-графы}. Структура RMAT-графа, процесс генерации которого подробно описан в \cite{rmat-graph}, напоминает структуру социальной сети. Особенностью таких графов является наличие одной большой компоненты, в которую входят почти все вершины графа, а так же множество небольших компонент, в том числе и отдельно висячие вершины. Степень вершин в таких графах различна и может очень сильно отличаться от средней степени вершин во всём графе: присутствуют как множество вершин небольшой степени, так и отдельные вершины, степень которых на 2-3 порядка выше средней степени.
    
    \item \textbf{SSCA2-графы}. SSCA2 графы представляют из себя множество небольших клик, между которыми случайно сгенерировано некоторое число рёбер \cite{ssca2-graph}.
    
    \item \textbf{Двумерные и трёхмерные решётки}. Графы, структура которых является $N$-мерной решёткой: каждая вершина графа, за исключением крайних, соединена рёбрами с $2^{N+1}$ соседними вершинами.
    
    Данный граф можно схематично представить как решётку в $N$-мерном пространстве, где каждая вершина $v$ имеет целочисленные координаты ($v_0$, $v_1$, $\ldots$, $v_{N-1}$), $0 \leq v_i < L_i$, где $L_i$ --- длина $i$-ой размерности решётки. Расстояние между двумя вершинами $v$ и $u$ в такой решётки полагается равным сумме модулей разностей по каждой координате: $\displaystyle \sum_{i=0}^{N-1} |v_i - u_i|$. 
    Всего в решётке будет $L_0 \cdot L_1 \cdot \ldots \cdot L_{N-1}$ вершин и смежными являются те вершины, расстояние между которыми равно 1.
    
    \item \textbf{Случайные графы}. 
        При генерации случайных графов задаётся количество вершин графа и требуемое количество рёбер. Затем генерируются рёбра графа: для каждого ребра случайно выбираются обе инцидентные ему вершины, при этом каждая из вершин может быть выбрана с равной вероятностью.
\end{itemize}

Вес каждого ребра графа генерировался независимо и является случайной величиной на интервале от 0 до 1, имеющей равномерное распределение. Во всех графах, кроме решёток, допускаются петли и кратные рёбра.

В качестве формата хранения графа использовался сжатый формат хранения разреженных матриц CSR (compressed storage row) 
%(ссылочку бы???). 
В данном формате все ненулевые значения матрицы располагаются в памяти последовательно таким образом, что все элементы одной строки идут подряд слева направо, а строки матрицы идут последовательно сверху-вниз. 
Для каждого ненулевого элемента помимо его значения так же хранится и индекс столбца, в котором он находится. 
Так же для каждого элемента необходимо уметь определять и номер строки, на которой он расположен, но за счёт того, что элементы одной строки идут подряд, достаточно для каждой строки исходной матрицы хранить индекс первого и последнего элемента в массиве элементов, более того, за счёт того, что строки идут последовательно, индекс последнего элемента строки $i$ будет на единицу меньше, чем индекс первого элемента строки $i+1$ (на практике обычно для хранения индексов обычно используют полуоткрытые интервалы --- в этом случае данные индексы будут совпадать).
% недостаток --- нельзя быстро определить положение элемента
% преимущесвто --- легко итерироваться
%то есть ненулевые элементы обходятся сверху-вниз слева-направо.
% матрицы смежности записывается в CSR

Запуски проводились на двухсокетной машине с процессорами Intel Xeon CPU E5-2690. Каждый процессор состоит из 8 ядер с тактовой частотой 2.9 GHz, каждое ядро имеет кэша первого уровня 32 килобайта и   кэш второго уровня 256 килобайт. Так же каждый процессор имеет общий для всех ядер кэш третьего уровня 20 мегабайт.
На тестируемой машине была включена технология Hyper Threading, позволяющая исполнять на каждом ядре процессора по 2 аппаратных потока.

Время работы программы измерялось с помощью ассемблерной инструкции rdtsc.
% для диплома описать преимущества перед другими подходами ???
Каждая реализация была запущена на каждом из графов 5 раз и в качестве итогового значения времени выбирался минимальный результат. Сказать почему???

На всех графиках результаты представлены в MTEPS (TEPS, traversed edges per second --- количество обработанных рёбер в секунду, приставка M означает mega) --- величина, обратно пропорциональная времени и равная:
$$MTEPS = \frac{\texttt{количество рёбер в графе}}{(\texttt{время работы программы в секундах}) \cdot 10^6}$$



%\subsection{Непосредственно графики ???}

%Тут должны быть графики и числа.
%Сравнение всех реализаций на RMAT-22, SSCA2-22 (возможно, решётки и случайные графы).
%Сравнение лучшей реализации на нескольких RMAT и SSCA2.
%Возможно, графики для Intel Xeon Phi.



На рисунке \ref{fig:resultGridRand} представлено сравнение описанных выше алгоритмов на графах следующих размерах:
\begin{itemize}
    \item RMAT-22-32 --- RMAT-граф с $2^{22}$ вершинами и средней степенью вершины 32.
    \item SSCA2-22 --- SSCA2-граф, в котором $2^{22}$ вершин и примерно $2^{27}$ рёбер.
    \item Random-22-27 --- случайный граф в котором, соответственно, $2^{22}$ вершин и $2^{27}$ рёбер.
    \item Grid-8000$\times$8000 --- двумерная решётка размера 8000 на 8000. В такой решётке находится $2^{26}$ вершин и приблизительно $2^{27}$ рёбер.
\end{itemize}

Размеры графов выбирались таким образом, чтобы количество рёбер было примерно одинаковым. Количество вершин в разных графах, за исключением решётки, так же примерно одинаково. 

На графиках отображена зависимость производительности от числа используемых потоков.
Алгоритм EA показывает заметно лучшие результаты.
Результаты алгоритма EA заметно лучше остальных. Огромная разница в производительности обосновывается тем, что не все оптимизации, описанные в разделе \ref{sec:eaopt} были применены и для остальных алгоритмов, но даже неоптимизированный вариант показывал лучшие результаты.
Среди остальных алгоритмов относительно неплохую производительность показывает VL-алгоритм на динамических массивах с дополнительной балансировкой нагрузки, однако, имеются проблемы с масштабируемостью на два сокета.

Решётка же получается более разреженной и имеет при таком же количестве рёбер в 16 раз больше вершин. 
Это ведёт к большему количеству итераций, который должен выполнить алгоритм Борувки прежде, чем остовное дерево будет построено, и как следствие увеличивается время работы. Так, для построения остовного дерева в графе RMAT-22-32 требуется 6 итераций, а в решётке 8000$\times$8000~---~13 итераций, чем и объясняется более низкая производительность.




На рисунке \ref{fig:resultSize} представлено изменение производительности алгоритма EA в зависимости от размера графа. Сравнение проводилось на RMAT графах  и на SSCA2 графах со средней степенью вершины 32. 

На малых размерах графа производительность низкая, поскольку в реализации присутствуют барьерные синхронизации между шагами алгоритма, а такие шаги, как \textit{перенумерация вершин}, дополнительно содержат барьерные синхронизации и внутри себя. На больших графах объём вычислений  между синхронизациями достаточно большой и время, затраченное на такие синхронизации, очень мало. На графах же небольшого размера время, которое потоки проверили на синхронизации, уже негативно сказывается на производительности.

%Производительность выравнивается на графах размера $2^{20}$-$2^{21}$ вершин и достигает максимального значения в 1400-1550 MTEPS на граф


\newpage
\section{Заключение}
На данный момент исследованы последовательные алгоритмы построения остовных деревьев и выбраны из них те, которые или модификации которых могут дать хорошую масштабируемость при распараллеливании. Так же изучены статьи  \cite{dense-mst,boruvka-prima,boruvka-cm5} по распараллеливанию данных алгоритмов.

Были получены последовательные реализации алгоритмов для дальнейшей проверки корректности получаемых результатов. Затем был написан и распараллелен алгоритм Борувки в нескольких реализациях, использующих разные структуры данных для хранения графа.

В дальнейших планах есть как оптимизация существующих алгоритмов, так и реализация новых.

В уже реализованных алгоритмах ближайшей целью является использование таких подходов как параллельные алгоритмы поиска компонент связности в тех шагах, где происходит объединение вершин одной компоненты.

Далее возможно использование других  структур данных в алгоритме Борувки. Рассматриваются такие структуры, как списки отсортированных списков смежностей, являющиеся промежуточным вариантом между поддержанием списков смежностей отсортированными на каждой итерации и полным отказом от сортировки списков, и деревья или кучи, позволяющие при дополнительных условиях производить их слияние за время, пропорциональное их высоте.

Так же планируется не только модификация алгоритма Борувки, но и реализация модифицированного алгоритмы Примы.

\newpage
???
\bibliographystyle{unsrt}
\bibliography{conference}

\end{document}
