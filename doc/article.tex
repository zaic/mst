\documentclass{article}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{textcomp}
%\usepackage{expdlist}
%\usepackage{textpos}
\usepackage{cmap}

%\usepackage{algorithm}
%\usepackage{algpseudocode} % for \begin{algorithm}
\usepackage[lined]{algorithm2e}

%\usepackage[left=30mm,right=15mm,top=20mm,bottom=20mm]{geometry}

%\hoffset=-3cm
%\textwidth=18cm
%\voffset=-3cm
%\textheight=23cm

\date{}
\title{Построение MST на мультипроцессоре с ccNUMA архитектурой}
\author{Зайцев Вадим, zaic101@gmail.com \\ Новосибирский государственный университет\thanks{Работа поддержана Грантом Президента РФ для молодых учёных МК-3644.2014.9}}

\usepackage{indentfirst}


\begin{document}

%\maketitle
%\newpage

\tableofcontents



\newpage
\section{Введение}
% 1     Введение
% 1.1   Актуальность обработки графов
Задача обработки и анализа больших данных стоит повсеместно и возникает во множестве областей, как то известные поисковики, провайдеры, социальные сети, сотовые операторы, такие области науки как биоинформатика (обработка генов и генных сетей) и многие другие.
Объёмы обрабатываемых данных от десятков гигабайт до террабайт и выше в зависимости от области.
Такие данные зачастую представимы в виде графов, где вся необходимая информация хранится в вершинах и рёбрах или дугах графа и анализ таких данных сводится к классическим алгоритмам на графах.
Одним из таких алгоритмов является алгоритм построения минимального остовного дерева.

% 1.2   Постановка задачи MST
В данной работе рассматривается задача построения минимального остовного дерева (minimum spanning tree --- MST) на мультипроцессоре с ccNUMA архитектурой.
Задача построения MST формулируется следующим образом: дан взвешенный, неориентированный граф и требуется найти остовное дерево (максимальный по включению рёбер подграф, не имеющий циклов), в котором сумма весов рёбер будет минимальна.
В случае, когда исходный граф связный, в итоге будет построено остовное дерево, если же в исходном графе несколько компонент, то результатом будет лес.

% 1.3   Применение MST (из английской википедии) % TODO ссылки, более подробное описание
Минимальные остовные деревья имеют широкое практическое применение.
Они используются при построении различных сетей: коммуникационных линий, компьютерных сетей, транспортных сетей.
Так же они используются в задачах кластеризации, сегментации при обработке изображений, распознавании рукописного ввода.
Минимальные остовные деревья  используются как приближённое решение переборной задачи: например, задачи Штейнера --- построение кратчайшей сети, соединяющей заданный конечный набор точек на плоскости.

% 1.4   Обзор существующих статей
% ToDo Возможно, полностью перенести в 2.1

\newpage
\section{Обзор алгоритмов построения MST}
% 2     Подробно об алгоритмах
% 2.1   Обзор существующих
%Существует несколько различных последовательных алгоритмов построения MST. %, которые, в зависимости от используемых в реализации структур данных, имеют асимптотическую оценку времени работы $O(E\cdot\log E)$ для разреженных  и $O(V^2)$ для полных графов.
Существуют различные последовательные алгоритмы построения MST, наиболее распространёнными из которых являются алгоритмы Крускала, Прима и Борувки \cite{cormen}.
Не каждый из алгоритмов в его оригинальном варианте возможно эффективно распараллелить, однако, для некоторых из них существуют модификации, за счёт которых использование нескольких ядер одного узла кластера и даже использование нескольких узлов кластера может оказаться оправданным \cite{boruvka-prima,kruskal-parallel}.

\subsection{Последовательные алгоритмы}

\textbf{Алгоритм Крускала} строит остовное дерево в два этапа: сначала все рёбра графа сортируются в порядке неубывания веса, затем рёбра последовательно обходятся и в остовное дерево добавляются те из них, которые не создают цикла.

Сортировка рёбер в общем случае может быть выполнена за время $O(E \cdot \log(E))$, проверка образования цикла для каждого ребра может быть реализована с помощью системы непересекающихся множеств и выполняться за время $O(\alpha(E, V))$. Итоговая оценка времени работы получается $O(E \cdot \log(E) + \alpha(E, V))$.

%, каждый следующий из которых зависит от результата предыдущего, что делает распараллеливание данного алгоритма неэффективным.
% TODO описать шаг точно так же

\textbf{Алгоритм Прима} начинает построение остовного дерева с произвольно выбранной вершины. Затем, пока дерево не будет построено полностью, выбирается ребро минимального веса, соединяющее вершину уже построенного дерева с вершиной не из дерева и данное ребро добавляется в строящееся остовное дерево.

Число шагов в алгоритме Прима равно числу вершин графе. Время поиска ребра минимального веса на каждом шаге зависит от выбранной структуры данных: при использовании матрицы смежности для поиска минимального ребра потребуется просмотреть всю строку матрицы за линейное время, а при использовании кучи добавление и удаление каждого ребра будет происходить за логарифмическое время. Таким образом, алгоритм Прима возможно реализовать со временем работы $O(V^2)$, что является лучшей оценки для полных графов, либо со временем $O(E \log (V))$, что более предпочтительно для разреженных графов.

%===
%В алгоритме Прима шаги так же связаны между собой, а распараллеливание одного шага не даст большого %выигрыша в силу большого количества шагов и малой вычислительной сложности одного шага.
%Однако, существует параллельный алгоритм построения MST, являющийся модификацией алгоритма Прима.
%Алгоритм Борувки в своём оригинальном виде является наиболее пригодным для распараллеливания. 
%TODO возможно, заменить на псевдокод
%Далее опишем алгоритм Борувки и модифицированный алгоритм Прима.
%===

% 2.1.1 Разные реализации Борувки, ПочтиПрима
\textbf{Алгоритм Борувки}.
Это итерационный алгоритм: изначально каждая вершина графа считается отдельной компонентой, затем на каждой итерации для каждой компоненты находится инцидентное ей ребро минимального веса и по найденным рёбрам компоненты объединяются. Алгоритм работает до тех пор, пока не останется одна компонента.

На каждой итерации алгоритма множество компонент уменьшается не менее, чем в два раза, следовательно количество итераций можно оценить сверху как $\lceil \log_2(V) \rceil$. На каждой итерации в худшем случае необходимо просмотреть все рёбра, при этом процедура обработки одного ребра достаточно простая (определение каким компонентам принадлежат инцидентные вершины и, возможно, обновление рекорда для данных компонент). Итоговая временная сложность получается $O(E \cdot \log(V))$.

\subsection{Параллельные алгоритмы}

С точки зрения параллелизма про алгоритмы Крускала и Прима можно сказать следующее:
\begin{itemize}
	\item они состоят из большого количества шагов, которые зависимы между собой и не могут исполняться параллельно
	\item вычислительная сложность одного шага достаточно маленькая и её распараллеливание будет неэффективно
\end{itemize}
Это делает распараллеливание данных алгоритмов в оригинальном варианте бесперспективным.

В то же время алгоритм Борувки обладает противоположными свойствами:
\begin{itemize}
	\item количество итераций небольшое
	\item вычислительная сложность одной итерации большая и может быть распределена между потоками
\end{itemize}
Это делает алгоритм Борувки наиболее пригодным для распараллеливания и в перспективе может дать хорошую масштабируемость.

В статьях \cite{dense-mst,boruvka-prima,boruvka-cm5} представлены различные варианты параллельных реализаций алгоритма Борувки.
Разные реализации используют разные структуры данных для хранения рёбер (хранение рёбер одним большим списком или хранение для каждой вершины списка инцидентных ей рёбер) и разные способы их объединения (слияние и копирование списков, объединение списков за константное время и т. д.).

\subsection{Модифицированный алгоритм Прима}
В статье \cite{boruvka-prima} представлен параллельный алгоритм построения MST на основе последовательного алгоритма Прима.
Суть данного алгоритма в том, что каждый поток выбирает случайную вершину в графе и начинает ``растить'' дерево из выбранной вершины, пока не попытается присоединить вершину, уже принадлежащую другому дереву, после чего два дерева встретившихся потоков объединяются, один из них продолжает ``растить'' объединённое дерево, а второй заново выбирает вершину графа. % TODO перечитать их алгоритм
К преимуществам данного подхода относится отсутствие барьерной синхронизации, которая требуется в алгоритме Борувки после каждой итерации и, в зависимости от реализации, между разными шагами одной итерации. Другим преимуществом перед алгоритмом Борувки является то, что каждое ребро будет просмотрено ровно один раз.

\newpage
\section{Варианты алгоритма Борувки}
% 2.2   Обзор недостатков существующих
В данных работах \cite{dense-mst,boruvka-prima,boruvka-cm5} результаты производительности показаны либо для старых архитектур \cite{dense-mst,boruvka-cm5}, либо масштабируемость была ограничена шестью одноядерными процессорами (SMP  UMA, UltraSPARC II) \cite{boruvka-prima} .
% 2.2.1 Малое количество ядер
% 2.2.2 SMP системы

% 2.3   Цель работы
Настоящая работа направлена на адаптацию существующих и реализацию новых алгоритмов, ориентированных на высокую эффективность на современных вычислителях с общей памятью с ccNUMA архитектурой.

\subsection{Списки смежности (Adjacency Lists --- AL)}
%Наибольшая вычислительная сложность первого алгоритма заключается в первом шаге, в котором необходимо обойти б\`oльшую часть рёбер графа, однако, основным препятствием для хорошей масштабируемости является то, что размер массива, редуцируемого на втором шаге, увеличивается с ростом количества потоков.

Первая реализация алгоритма Борувки для хранения графа использует списки смежности для каждой компоненты. Изначально каждая компонента представлена одной вершиной и её список смежности совпадает со списком смежности вершины, затем после каждой итерации для каждой образовавшейся компоненты явно строится список всех рёбер, инцидентных данной компоненте.
В качестве списков может быть использована любая структура данных, позволяющая последовательный обход элементов. В данном подходе использовались динамически выделяемые массивы.

Изначально множество вершин графа разделяется между потоками равномерно по количеству инцидентных рёбер.
Далее на каждой итерации алгоритма Борувки выполняются следующие шаги, пока не останется одна компонента или между несколькими оставшимися компонентами не будет рёбер:
\begin{enumerate}
    \item \textit{Минимальное инцидентное ребро}.
        Каждый поток для каждой своей компоненты находит инцидентное ей ребро минимального веса. Это делается обходом всех инцидентных компоненте рёбер.
    \item \textit{Объединение деревьев (1)}.
          Для каждой компоненты определяется её номер на следующей итерации.
          Так же решается проблема с возможными циклами (когда более двух компонент по кругу выберут следующую в качестве ближайшей), которые возможны в алгоритме Борувки при наличии рёбер одинакового веса.
    \item \textit{Объединение деревьев (2)}.
          Осуществляется перенумерация компонент: для каждой вершины вычисляется номер компоненты, в которую она входит, используя параллельный алгоритм Pointer Jumping \cite{pointer-jumping}.
    \item \textit{Слияние списков}.
        Происходит объединение компонент путём слияния списка рёбер. 
        Поскольку, списки уже отсортированы по возрастанию веса, то возможно слияние, при котором в результате так же будет получен отсортированный список, с сохранением линейного времени работы.
    \item \textit{Перенумерация}.
        Обход списков рёбер и перенумерация компонент: старые номера заменяются на новые, полученные на шаге \textit{Объединения деревьев}.
\end{enumerate}

Были опробованы два подхода относительно сортированности списков смежности:
\begin{itemize}
    \item \textbf{Отсортированные по весу списки смежности}. 
        Отсортированные списки позволяют осуществлять шаг \textit{минимальное инцидентное ребро} за константное время, просмотрев лишь голову списка, однако поддержание таких списков сортированными на шаге \textit{слияния списков} требует дополнительного времени. Сказать про оптимизацию???
    \item \textbf{Неотсортированные списки смежности}.
        Когда поддержание списков отсортированными не требуется, их объединение возможно осуществлять простым копированием памяти, но поиск по неотсортированному списку возможен только за линейное время.
\end{itemize}

На практике подход с сортировкой списков по весу оказался медленнее. цирфы???


В данном подходе имеется две существенные проблемы. 
Первая из них заключается в том, что на шаге \textit{слияния списков} происходит копирования большого объёма данных и этот шаг исполняется долго.
Вторая проблема лежит в том, что при распределении компонент между потоками на шагах \textit{минимальное инцидентное ребро} и \textit{слияния списков} происходит дисбаланс нагрузки на последних итерациях, когда количество оставшихся компонент становится меньше числа потоков --- в этом случае некоторые потоки просто простаивают без работы, что негативно сказывается на масштабируемости алгоритма.

%В ходе анализа работы шага \textit{Объединение деревьев} на тестируемых типах графов было выяснено, что количество объединяемых компонент в одну в большинстве случаев не превосходит трёх и это позволяет быстро и эффективно отсеивать петли на шаге \textit{Слияния списков} за счёт сокращения нерегулярных обращений в память.

\subsection{Списки вершин (f??? lists --- FL) Rename to VL?}

% TODO ударения в слове большИх
%Основная проблема при реализации алгоритма Борувки, явно строящих список инцидентных рёбер каждой компоненты перед каждой итерации заключается в большом объёме копируемых на каждой итерации данных. 
%С целью уменьшить объём копируемых данных при первом и ускорить шаг слияния списков было решено для каждой компоненты хранить не список инцидентных рёбер, а список входящих в неё вершин.

В качестве решения первой проблемы --- большого объёма копируемых данных после каждой итерации --- было решено (???) заменить списки смежности каждой компоненты на список входящих в неё вершин. Во-первых, такая модификация минимально влияет на другие шаги алгоритма. Во-вторых, на шаге \textit{слияния списков} это позволяет в несколько раз сократить размер объединяемых списков.

Общая схема алгоритма осталась прежней со следующими изменениями:
\begin{enumerate}
    \item На шаге \textit{минимальное инцидентное ребро} теперь для обхода рёбер требуется обойти не список рёбер, а список входящих в компоненту вершин и уже для каждой вершины обойти список инцидентных ей рёбер.
    \item На шаге \textit{слияние списков} теперь копируются не списки рёбер, а списки вершин, что значительно сокращает объём перемещаемых данных.
\end{enumerate}

Для хранения списка вершин были опробованы две структуры данных:
\begin{itemize}
	\item \textbf{Односвязные списки}. Их преимущество заключается в возможности объединения за константное время, однако, обход таких списков связан со случайными обращениями в память.
	\item \textbf{Динамические массивы}. Объединение массивов возможно только за линейное время путём копирования одного из них в другой (на практике используется копирование меньшего массива в больший). Но во время обхода массива хорошо работает аппаратная предвыборка, что позволяет в значительной степени избежать кэш-промахов.
\end{itemize}
Данные модификации показывали примерно одинаковую производительность, однако, в среднем реализация с использованием динамических массивов оказалась на 5-10\% быстрее.

В качестве решения второй проблемы --- дисбаланс на последних итерациях --- шаг \textit{минимальное инцидентное ребро} был разделён на два: сначала выделяются компонент с небольшим количеством входящих в них вершин и обрабатываются как и раньше. Затем остаётся несколько компоненты, состоящие из большого числа вершин, и работа по таким компонентам уже разделяется между потоками: каждый поток обрабатывает свою часть вершин, находит среди них минимальное ребро и в конце по всеми потокам находится . Данная оптимизация улучшила производительность алгоритма и позволила получить ускорение на 2 сокетах.

\subsection{Массив рёбер (Edges Array --- EA)}

Поскольку за счёт предыдущей модификации полностью решить проблему копирования больших объёмов данных не удалось, то следующий алгоритм разрабатывался с целью полностью избежать перемещения списков рёбер или вершин после каждой итерации.
Если ранее использовался подход, когда для каждой компонента хранилась информация, позволявшая восстановить список инцидентных рёбер, то теперь будет хранится информация для каждой вершины о том, какой компоненте она принадлежит.

Изначально все вершины распределяются между потоками равномерно по количеству рёбер. Далее на каждой итерации алгоритма Борувки выполняются следующие шаги:

\begin{enumerate}
    \item \textit{Минимальное инцидентное ребро}.
		Каждый поток обходит все свои вершины и находит минимально ребро для всех компонент, которые представлены в данном потоке хотя бы одной вершиной.
        В результате каждый поток будет иметь массив, содержащий минимальное ребро для каждой компоненты среди просмотренного подмножества.
    \item \textit{Редукция}.
          Происходит редукция полученного на предыдущем шаге массива: для каждой компоненты находится ребро минимального веса по всем потокам. 
          Таким образом, для каждой компоненты определяется минимальное ребро уже по всему графу.
    \item \textit{Объединение деревьев}.
          Для каждой компоненты определяется её номер на следующей итерации.
          Так же решается проблема с возможными циклами (когда более двух компонент по кругу выберут следующую в качестве ближайшей), которые возможны в алгоритме Борувки при наличии рёбер одинакового веса.
    \item \textit{Перенумерация}.
          Осуществляется перенумерация компонент: для каждой вершины вычисляется номер компоненты, в которую она входит, используя параллельный алгоритм Pointer Jumping \cite{pointer-jumping}.
\end{enumerate}

Основная проблема данного подхода заключается в шаге \textit{редукции}: объём редуцируемого массива растёт линейно с ростом числа потоков, таким образом, среднее время выполнения данного шага почти не уменьшается с ростом количества потоков.
Однако, даже с описанной проблемой подход с уменьшением объёма копируемых данных себя оправдал и данная реализации показала лучшие результаты производительности среди описанных алгоритмов.

%\newpage
%\section{Результаты}
% 2.5   На чём проводилось тестирование
% 2.5.1 Параметры графов
%Тестирование проводилась на графах, состоящих из $10^6-10^8$ вершин и $10^7-10^9$ рёбер: это RMAT-графы %степени $20\,-\,23$, двумерные и трёхмерные решётки, а так же случайные графы.

% 2.5.2 Характеристика систем
%Характеристики систем, на которых производились запуски:
%\begin{itemize}
%    \item 2 $\times$ Intel Xeon CPU E5-2690 (8 ядер 2.9 GHz, 32KB L1 cache, 256KB L2 cache, 20MB L3 cache)
%    \item 8 $\times$ Intel Xeon CPU Е7-4870 (10 ядер 2.4 GHz, 32KB L1 cache, 256KB L2 cache, 30MB L3 cache)
%\end{itemize}

%[Позже будут добавлены результаты тестирования двух описанных алгоритмов].

\newpage
\section{Оптимизации EA реализации}

\subsection{Алгоритмические оптимизации}

\textbf{Предварительная сортировка рёбер.}
Алгоритм Борувки предполагает на каждой итерации просмотр всех рёбер графа, что и создаёт наибольшую вычислительную сложность первого шага.
Объём ``лишней'' работы при этом достаточно велик: во-первых, постоянно будет просматриваться большое количество петель, которых с каждой итерацией становится всё больше и больше, во-вторых, почти все рёбра, не являющиеся петлями, будут отбрасываться \textit{(в значении пропускаться до следующей итерации???)}, как более тяжёлые.


Проблему с петлями возможно попытаться решить их удалением, однако, это повлечёт за собой частичное перестроение \textit{структуры?внутреннего представления???} графа, что, как было выявлено в ходе исследования, негативно сказывается на производительности.

Решить обе обозначенные проблемы возможно за счёт предварительной сортировки списков смежности каждой вершины по возрастанию веса рёбер. Затем для каждой вершины \textit{хранится???} индекс последнего просмотренного ребра: изначальной данный индекс указывает на первое ребро в списке, затем, по мере отбрасывания петель, он сдвигается и на следующей итерации поиск минимального ребра начинается не с начала списка, а с позиции, на которую указывает индекс. С другой стороны, если мы берём очередное ребро и его вес больше, чем текущий рекорд для компоненты, то поиск можно прервать, так как вес последующих рёбер данной вершины заведомо больше текущего рекорда.

Данная оптимизация хорошо масштабируется и на большом количестве потоков время выполнения невелико. В среднем производительность от данной оптимизации увеличивается на 20\%.



\textbf{Перенумерация вершин.}
В работе \cite{sparse-matrix-renum} предлагается алгоритм перенумерации вершин, который повышает локальность данных при последующих обходах графа, за счёт чего уменьшается количество кэш-промахов. (Статистика по кэш-промахам из intel vtune???)
Предложенный алгоритм перенумеровывает вершины в порядке обхода в ширину с предварительной отсортировкой списков смежности каждой вершины по возрастанию степени вершины, в которую ведёт ребро.


\textbf{Балансировка больших вершин.}
Одной из особенностей RMAT-графов являет наличие вершин, степень которых значительно отличается от средней степени всех вершин графа. Например, в тестируемом RMAT-графе с $2^{20}$ вершинами (???) и со средней степенью 32, есть более ??? вершин степени выше 1000. Такие вершины создают дисбаланс на последних итерациях, когда просматривается большое количество рёбер и отбрасываются петли.

С целью устранения данного дисбаланса на стадии предобработки графа выделяются вершины степени более 1000 и равномерно распределяются между потоками. Значение степени 1000 было подобрано эмпирически и хорошо показало себя на практике.

В среднем оптимизации \textbf{перенумерация вершин} и \textbf{балансировки больших вершин} дают увеличение производительности в 11\%.



\textbf{Отдельный цикл пропуска петель.}
В шаге а??? для каждой вершины ищется ребро минимального веса, ведущее в другую компоненту. С учётом оптимизации \textbf{предварительной сортировки рёбер} данный шаг выглядит следующим образом (упрощённо, конечно же):

\begin{algorithm}
    \SetAlgoLined
    \KwData{vertex $v$}
    $myComp \gets component[v]$\;
    \ForEach{$edgeId$ \textbf{from} $edgesIdsBegin[v]$ \textbf{to} $edgesIdsEnd[v]$}{
        $destVertex \gets edges[edgeId].destination$\;
        $destComp \gets component[destVertex]$\;
        \If{$destComp = myComp$}{
            continue
        }
        \If{$edges[edgeId] < currentRecord[myComp]$}{
            $currentRecord[myComp] \gets edges[edgeId]$
        }
        break\;
    }
    \caption{Какой-то шаг до какой-то оптимизации}
\end{algorithm}

Цикл может быть разбит и упрощён на более простой:

\begin{algorithm}
    \SetAlgoLined
    \KwData{vertex $v$}
    $myComp \gets component[v]$\;
    $edgeId \gets edgesIdsBegin[v]$\;
    \While{$edgeId \neq edgesIdsEnd[v]$ and $comp = myComp$}{
        $edgeId \gets edgeId + 1$\;
    }
    \If{$edges[edgeId] < currentRecord[myComp]$}{
        $currentRecord[myComp] \gets edges[edgeId]$
    }
    \caption{Какой-то шаг после этой оптимизации}
\end{algorithm}

Написать, что петель отбрасывается очень много и потому данная модификация даёт улучшение производительности. Где статистика по петлям???

В среднем данная оптимизация ведёт к увеличению производительности на 10\%.


\subsection{Оптимизация редукции}

Поскольку основные проблемы масштабируемости лежат именно в шаге редукции, то было сделано несколько оптимизаций, непосредственно затрагивающих данный шаг. Оценки увеличения производительности получены при запуске 32 потоков на всех 16 ядрах процессоров и показывают ускорение (не шага редукции, а общего времени построения mst???).

\textbf{Отсутствие редукции на первой итерации.}
Поскольку каждая компонента изначально представлена одной вершиной, то от редукции на первой итерации можно отказаться. Данная оптимизация выглядит простой и очевидной, однако, объём редуцируемого массива на первой итерации больше, чем на всех следующих, и данная модификация даёт ускорение в 20\%.

\textbf{Перенумерация и сжатие массива компонент по ходу исполнения алгоритма.}
В начальной реализации при объединении компонент в качестве её номера выбирался один из номеров вершин, которые в неё входят. Таким образом, несмотря на сокращение числа компонент, диапазон используемых номеров не изменялся (минимальный и максимальный номер были приблизительно равны соответственно первой и последней вершине). Такой подход затруднял обход всех компонент на шаге редукции: требовалось либо обходить весь диапазон номеров и совершать лишнюю работу, просматривая ``пустые'' номера, не являющиеся компонентами, либо отдельно поддерживать массив, в которым хранить индексы всех ``живых'' на данный момент компонент, что усложняло реализацию и приводило к увеличению кэш-промахов из-за обхода массива с непостоянным шагом.

Явная перенумерация компонент на последовательные номера позволила решить обозначенную проблему. В среднем производительность увеличилась на 20\%.

Более того, это позволило уменьшить объём используемой памяти: в начальной реализации для каждого потока создавался двумерный массив размера \texttt{количество\_потоков}$\times$\texttt{количество\_вершин}
На системах с больш\`{и}м количеством ядер, например, на Intel Xeon Phi, где используется до 240 потоков, объём такого массива заметно превосходит объём всех других данных и его сокращение в 2 раза приводит к значительному уменьшению потребляемой памяти (описать про память более понятно???).

\textbf{Иерархическая редукция.}
Особенностью NUMA архитектуры являются высокие задержки при обращении в память другого узла NUMA.
При стандартном подходе к редукции, когда для каждой компоненты последовательно обходятся все потоки и выбирается лучший результат, таких обращений при двух NUMA узлах будет как минимум ???, а при большем количестве узлов NUMA --- ещё больше.

Данную проблему можно решить за счёт иерархического подхода к редукции. При таком подходе шаг редукции разбивается на два этапа: на первом происходит стандартная редукция внутри NUMA узла, а на втором  --- между узлами. Количество обращений к чужому узлу NUMA в этом случае уменьшается в количество раз, равное количеству используемых потоков в одном узле NUMA. В результате иерархическая редукция повысила производительность на 5\%.
Может, добавить красивую картинку(???)

\textbf{Сообщения в редукции.}
В редуцируемом массиве много пустых элементов. Через сообщения можно уменьшить объём редуцируемых данных.

\subsection{Архитектурные оптимизации}

\textbf{Программная предвыборка.}
Обход рёбер в общем случае неизбежно связан со случайными обращениями в память: невозможно отсортировать рёбра так, чтобы индексы обеих инцидентных вершин шли последовательно.
Аппаратная предвыборка современных процессоров ориентирована только на последовательные обращения в память (точнее, на обход с постоянным, возможно отрицательным, шагом, размер которого не превосходит размер страницы памяти) и подобный обход рёбер вызывает простои, связанные с ожиданием данных.

Однако, адреса случайных обращений в память при таких обходах в большинстве случаев можно предсказать: обходя рёбра последовательно, нам известны индексы вершин для следующих итераций. Как раз в таком случае и помогает программная предвыборка, давая возможность заранее запросить нужные данные для будущих вершин (например, какой компоненте они принадлежат) и сократить время ожидания.

Другой особенностью аппаратной предвыборки является то, что данные не всегда загружаются в кэш первого уровня (например, на Intel Xeon Phi). Дополнить про L1 cache???

В среднем программная предвыборка позволила повысить производительность на 30\%. Сказать про то, что стадии типа PJ и того можно ускорить в несколько раз.

Сказать про двойную предвыборку ???
Иногда, в одном цикле целесообразно использование программной предвыборки для двух массивов с разным шагом. В коде:
\begin{algorithm}
    \SetAlgoLined
    \For{$vertexId$ from $1$ to $vertexCount$}{
    	$edgeId \gets startEdge[vertexId]$\;
	    $destComp \gets component[edges[startEdge].dest]$\;
   	    \ldots
    }
    \caption{возможно, данный заголовок стоит выпилить}
\end{algorithm}

обращение к массиву $component$ есть возможность 
\begin{algorithm}
    \SetAlgoLined
    \For{$vertexId$ from $1$ to $vertexCount$}{
    	$prefetch(\&component[edge[startEdge[vertexId + prefetchStep]].dest])$\;
    	$edgeId \gets startEdge[vertexId]$\;
	    $destComp \gets component[edges[startEdge].dest]$\;
   	    \ldots
    }
    \caption{возможно, данный заголовок стоит выпилить}
\end{algorithm}

Однако, здесь адрес второй предвыборки зависит от случайного обращения к элементу $edge[startEdge[vertexId + prefetchStep]$ и более эффективным будет заранее загрузить в кэш данный элемент:
\begin{algorithm}
    \SetAlgoLined
    \For{$vertexId$ from $1$ to $vertexCount$}{
	    $prefetch(\&edge[startEdge[vertexId + prefetchStep \times 2]])$\;
    	$prefetch(\&component[edge[startEdge[vertexId + prefetchStep].dest]])$\;
    	$edgeId \gets startEdge[vertexId]$\;
	    $destComp \gets component[edges[startEdge].dest]$\;
   	    \ldots
    }
    \caption{возможно, данный заголовок стоит выпилить}
\end{algorithm}



\textbf{Выделение памяти с учётом NUMA архитектуры}
Как уже отмечалось ранее, обращение в память другого узла NUMA связано с высокими задержками. Выделение памяти на тех ядрах, где она используется, является более правильным на NUMA архитектуре.

В случае использования двумерных массивов, когда первая размерность соответствует номеру потока (например, массив в котором хранится текущий лучший результат для каждой компоненты), основной интерес представляет вторая размерность, поскольку к первой будет только одно обращение за итерацию, а ко второй --- на каждой вершине. Таким образом, первая размерность выделяется на произвольном узле NUMA, а затем каждой поток выделяет необходимую ему память (написано криво???).

Когда одномерный массив одновременно использует несколько потоков (например,  массив рёбер), то возникает необходимость выделить непрерывную область в памяти на разных узлах NUMA. Ядро Linux предоставляет разработчику возможность явно управлять выделением страниц памяти на NUMA системах с использованием libnuma. Однако, в реализациях использовалась особенность ядра Linux известная как memory overcommit: выделение страниц памяти происходит не в момент вызова функции malloc, а в момент первого обращения к странице. Таким образом, для разделения массива по узлам NUMA сначала с использованием функции malloc выделялся весь, далее, каждый поток инициализировал те страницы, которые он будет использовать. При таком подходе, конечно же, может возникнуть пересечение, когда два потока используют одну страницу, но размеры таких пересечений невелики по сравнению с размером всего массива.

Был также опробован подход с дублированием массива, который используют одновременно несколько узлов NUMA. Одним из примеров таких данных является массив, где для каждой вершины хранится индекс компоненты, в которую она входит на данный момент. Однако, из-за необходимости после каждой итерации дополнительно обновлять массив на каждом узле NUMA данный подход себя не оправдал.



\textbf{Аппаратные потоки процессора.}
Современные процессоры позволяют на одном ядре исполнять (???) одновременно несколько аппаратных потоков. Так в десктопных (домашние???) и серверных процессорах Intel и AMD данные технологии называются соответственно Hyper-Threading и Modules и позволяют запускать по 2 аппаратных потока на ядро, а ускоритель Intel Xeon Phi на данный момент имеет 4 аппаратных потока на каждое ядро. Использование такого вида многозадачности позволяет не только более эффективно использовать processor units, но и скрыть задержки в память (за счёт переключение на другой поток???).

Проблема использования аппаратных потоков для EA-реализации заключается в увеличении объёма шага редукции. В начальных реализациях использование Hyper-Threading давало небольшое (какое???) ускорение на малом количестве потоков, но ухудшало время на 16 потоках. После применения описанных выше оптимизаций редукции Hyper-Threading стал давать выигрыш в среднем 5\%.



\textbf{Linux huge pages.}
Увеличение объёма страниц памяти $\Rightarrow$ уменьшение количества страниц $\Rightarrow$ меньше промахов в TLB кэш.
К сожалению, на данный момент хоть и huge pages включены в ядре Linux, однако, настройки системы по умолчанию не позволяют их использовать без дополнительных действий со стороны администратора системы, потому данная оптимизация не была протестирована на Intel Xeon.

Чуть лучше дела обстоят на ускорителе Intel Xeon Phi, где huge pages разрешены ``из коробки''. Использование huge pages на данном ускорителе дало такой-то выигрыш.


\newpage
\section{Результаты}

\subsection{Тестирование}

Описание характеристик используемых машин (2xIntelXeon, Intel Xeon Phi), описание используемых графов (rmat, ssca2, возможно решётку и случайные графы), формат входных данных (матрица в формаате CSR), как измерялось время (rdtsc, сколько замеров, минимальный результат).

\subsection{Непосредственно графики}

Тут должны быть графики и числа.
Сравнение всех реализаций на RMAT-22, SSCA2-22 (возможно, решётки и случайные графы).
Сравнение лучшей реализации на нескольких RMAT и SSCA2.
Возможно, графики для Intel Xeon Phi.

\includegraphics[scale=0.35]{rmat22}
\includegraphics[scale=0.35]{rmat22_8}

\newpage
\section{Заключение}
На данный момент исследованы последовательные алгоритмы построения остовных деревьев и выбраны из них те, которые или модификации которых могут дать хорошую масштабируемость при распараллеливании. Так же изучены статьи  \cite{dense-mst,boruvka-prima,boruvka-cm5} по распараллеливанию данных алгоритмов.

Были написаны последовательные реализации алгоритмов для дальнейшей проверки корректности получаемых результатов. Затем был написан и распараллелен алгоритм Борувки в нескольких реализациях, использующих разные структуры данных для хранения графа.

В дальнейших планах есть как оптимизация существующих алгоритмов, так и реализация новых.

В уже реализованных алгоритмах ближайшей целью является использование таких подходов как параллельные алгоритмы поиска компонент связности в тех шагах, где происходит объединение вершин одной компоненты.

Далее возможно использование других  структур данных в алгоритме Борувки. Рассматриваются такие структуры, как списки отсортированных списков смежностей, являющиеся промежуточным вариантом между поддержанием списков смежностей отсортированными на каждой итерации и полным отказом от сортировки списков, и деревья или кучи, позволяющие при дополнительных условиях производить их слияние за время, пропорциональное их высоте.

Так же планируется не только модификация алгоритма Борувки, но и реализация модифицированного алгоритмы Примы.

\newpage
\bibliographystyle{unsrt}
\bibliography{conference}

\end{document}
