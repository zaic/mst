\documentclass{article}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{textcomp}
%\usepackage{expdlist}
%\usepackage{textpos}
\usepackage{cmap}
%\usepackage{soul} % for \ul

%\usepackage{algorithm}
%\usepackage{algpseudocode} % for \begin{algorithm}
\usepackage[lined]{algorithm2e}

%\usepackage[left=30mm,right=15mm,top=20mm,bottom=20mm]{geometry}

%\hoffset=-3cm
%\textwidth=18cm
%\voffset=-3cm
%\textheight=23cm

\date{}
\title{Построение MST на мультипроцессоре с ccNUMA архитектурой}
\author{Зайцев Вадим, zaic101@gmail.com \\ Новосибирский государственный университет\thanks{Работа поддержана Грантом Президента РФ для молодых учёных МК-3644.2014.9}}

\usepackage{indentfirst}


\begin{document}

\begin{center}
МИНИСТЕРСТВО  ОБРАЗОВАНИЯ  И  НАУКИ  РОССИЙСКОЙ  ФЕДЕРАЦИИ

Федеральное государственное автономное образовательное учреждение 

высшего образования

<<Новосибирский национальный исследовательский государственный университет>>

Факультет информационных технологий

Кафедра Параллельных вычислений

Образовательная программа: 230100.68 Информатика и вычислительная техника 

{\bfseries ОТЧЕТ

$\underset {\textnormal{(наименование практики)}} {\underline{\textup{о прохождении производственной практики}}}$}
\end{center}

\noindent Тема задания: \underline{Параллельный алгоритм построения остовного дерева   }\\
\underline{для больших графов на мультипроцессоре.}\\\\
Студент $\underset{\textnormal{(Фамилия, Имя, отчество, подпись)}} {\underline{\textup{\textbf{Зайцев Вадим Евгеньевич}}}}$ Группа \underline{\textbf{13221}} \\
\textbf{Место прохождения практики} $\underset{\textnormal{(название организации и структурного подразделения)}} {\underline{\textup{ИВМиМГ СО РАН}}}$ \\
\textbf{Руководитель практики от организации}  $\underset{\textnormal{(фамилия, имя, отчество, должность, подпись)}} {\underline{\textup{Калгин Константин Викторович, к. ф.-м. н.}}}$ \\
\textbf{Руководитель практики  от выпускающей кафедры} \\
$\underset{\textnormal{(фамилия, имя, отчество, должность, подпись)}} {\underline{\textup{Калгин Константин Викторович, к. ф.-м. н.}}}$ \\

\newpage
%\maketitle
%\newpage

\tableofcontents



\newpage
\section{Введение}
% 1     Введение
% 1.1   Актуальность обработки графов
Задача обработки и анализа больших данных стоит повсеместно и возникает во множестве областей, как то известные поисковики, провайдеры, социальные сети, сотовые операторы, такие области науки как биоинформатика (обработка генов и генных сетей) и многие другие.
Объёмы обрабатываемых данных от десятков гигабайт до террабайт и выше в зависимости от области.
Такие данные зачастую представимы в виде графов, где вся необходимая информация хранится в вершинах и рёбрах или дугах графа и анализ таких данных сводится к классическим алгоритмам на графах.
Одним из таких алгоритмов является алгоритм построение минимального остовного дерева.

% 1.2   Постановка задачи MST
В данной работе рассматривается задача построения минимального остовного дерева (minimum spanning tree --- MST) на мультипроцессоре с ccNUMA архитектурой.
Задача построения MST формулируется следующим образом: дан взвешенный, неориентированный граф и требуется найти остовное дерево (максимальный по включению рёбер подграф, не имеющий циклов), в котором сумма весов рёбер будет минимальна.
В случае, когда исходный граф связный, в итоге будет построено остовное дерево, если же в исходном графе несколько компонент, то результатом будет лес.

% 1.3   Применение MST (из английской википедии) % TODO ссылки, более подробное описание
Минимальные остовные деревья имеют широкое практическое применение.
Они используются при построении различных сетей: коммуникационных линий, компьютерных сетей, транспортных сетей.
Так же они используются в кластеризации, сегментации при обработке изображений, распознавании рукописного ввода.
MST может использоваться как приближённое решение переборной задачи: например, задачи Штейнера --- построение кратчайшей сети, соединяющей заданный конечный набор точек на плоскости.

% 1.4   Обзор существующих статей
% ToDo Возможно, полностью перенести в 2.1

\newpage
\section{Обзор алгоритмов построения MST}
% 2     Подробно об алгоритмах
% 2.1   Обзор существующих
%Существует несколько различных последовательных алгоритмов построения MST. %, которые, в зависимости от используемых в реализации структур данных, имеют асимптотическую оценку времени работы $O(E\cdot\log E)$ для разреженных  и $O(V^2)$ для полных графов.
Существуют различные последовательные алгоритмы построения MST, наиболее распространёнными из которых являются алгоритмы Крускала, Прима и Борувки \cite{cormen}.
Не каждый из алгоритмов в его оригинальном варианте возможно эффективно распараллелить, однако, для некоторых из них существуют модификации, за счёт которых использование нескольких ядер одной машины и даже использование нескольких машин может оказаться оправданным \cite{boruvka-prima,kruskal-parallel}.

\subsection{Последовательные алгоритмы}

\textbf{Алгоритм Крускала} строит остовное дерево в два этапа: сначала все рёбра графа сортируются в порядке неубывания веса, затем рёбра последовательно обходятся и в остовное дерево добавляются те из них, которые не создают цикла.

Сортировка рёбер в общем случае может быть выполнена за время $O(E \cdot \log(E))$, проверка образования цикла для каждого ребра может быть реализована с помощью системы непересекающихся множеств и выполняться за время $O(\alpha(E, V))$. Итоговая оценка времени работы получается $O(E \cdot \log(E) + \alpha(E, V))$.

%, каждый следующий из которых зависит от результата предыдущего, что делает распараллеливание данного алгоритма неэффективным.
% TODO описать шаг точно так же

\textbf{Алгоритм Прима} начинает построение остовного дерева с произвольно выбранной вершины. Затем, пока дерево не будет построено полностью, выбирается ребро минимального веса, соединяющее вершину уже построенного дерева с вершиной не из дерева и данное ребро добавляется в строящееся остовное дерево.

Число шагов в алгоритме Прима равно числу вершин графе. Время поиска ребра минимального веса на каждом шаге зависит от выбранной структуры данных: при использовании матрицы смежности для поиска минимального ребра потребуется просмотреть всю строку матрицы за линейное время, а при использовании кучи добавление и удаление каждого ребра будет происходить за логарифмическое время. Таким образом, алгоритм Прима возможно реализовать со временем работы $O(V^2)$, что является лучшей оценки для полных графов, либо со временем $O(E \log (V))$, что более предпочтительно для разреженных графов.

%===
%В алгоритме Прима шаги так же связаны между собой, а распараллеливание одного шага не даст большого %выигрыша в силу большого количества шагов и малой вычислительной сложности одного шага.
%Однако, существует параллельный алгоритм построения MST, являющийся модификацией алгоритма Прима.
%Алгоритм Борувки в своём оригинальном виде является наиболее пригодным для распараллеливания. 
%TODO возможно, заменить на псевдокод
%Далее опишем алгоритм Борувки и модифицированный алгоритм Прима.
%===

% 2.1.1 Разные реализации Борувки, ПочтиПрима
\textbf{Алгоритм Борувки}.
Это итерационный алгоритм: изначально каждая вершина графа считается отдельной компонентой, затем на каждой итерации для каждой компоненты находится инцидентное ей ребро минимального веса и по найденным рёбрам компоненты объединяются. Алгоритм работает до тех пор, пока не останется одна компонента.

На каждой итерации алгоритма множество компонент уменьшается не менее, чем в два раза, следовательно количество итераций можно оценить сверху как $\lceil \log_2(V) \rceil$. На каждой итерации в худшем случае необходимо просмотреть все рёбра, при этом процедура обработки одного ребра достаточно простая (определение каким компонентам принадлежат инцидентные вершины и, возможно, обновление рекорда для данных компонент). Итоговая временная сложность получается $O(E \cdot \log(V))$.

\subsection{Параллельные алгоритмы}

С точки зрения параллелизма про алгоритма Крускала и Прима можно сказать следующее:
\begin{itemize}
	\item они состоят из большого количества шагов, которые зависимы между собой и не могут исполняться параллельно
	\item вычислительная сложность одного шага достаточно маленькая и её распараллеливание будет неэффективно
\end{itemize}
Это делает распараллеливание данных алгоритмов в оригинальном варианте бесперспективным.

В то же время алгоритм Борувки обладает противоположными свойствами:
\begin{itemize}
	\item количество итераций небольшое
	\item вычислительная сложность одной итерации большая и может быть распределена между потоками
\end{itemize}
Что делает алгоритм Борувки наиболее пригодным для распараллеливания и в перспективе может дать хорошую масштабируемость.

В статьях \cite{dense-mst,boruvka-prima,boruvka-cm5} представлены различные варианты параллельных реализаций алгоритма Борувки.
Разные реализации используют разные структуры данных для хранения рёбер (хранение рёбер одним большим списком или хранение для каждой вершины списка инцидентных ей рёбер) и разные способы их объединения (слияние и копирование списков, объединение списков за константное время и т. д.).

%\subsection{Модифицированный алгоритм Прима}
В статье \cite{boruvka-prima} представлен параллельный алгоритм построения MST на основе последовательного алгоритма Прима.
Суть данного алгоритма в том, что каждый поток выбирает случайную вершину в графе и начинает ``растить'' дерево из выбранной вершины, пока не попытается присоединить вершину, уже принадлежащую другому дереву, после чего два дерева встретившихся потоков объединяются, один из них продолжает ``растить'' объединённое дерево, а второй заново выбирает вершину графа. % TODO перечитать их алгоритм
К преимуществам данного подхода относится отсутствие барьерной синхронизации, которая требуется в алгоритме Борувки после каждой итерации и, в зависимости от реализации, между разными шагами одной итерации.

\newpage
\section{Разработка параллельного алгоритма}
% 2.2   Обзор недостатков существующих
В данных работах \cite{dense-mst,boruvka-prima,boruvka-cm5} результаты производительности показаны либо для старых архитектур \cite{dense-mst,boruvka-cm5}, либо масштабируемость была ограничена шестью одноядерными процессорами (SMP  UMA, UltraSPARC II) \cite{boruvka-prima} .
% 2.2.1 Малое количество ядер
% 2.2.2 SMP системы

% 2.3   Цель работы
Настоящая работа направлена на адаптацию существующих и реализацию новых алгоритмов, ориентированных на высокую эффективность на современных вычислителях с общей памятью с ccNUMA архитектурой.



% 2.5.3 Результаты
%\textit{ToDo Красивые мимимишные графики}.

\subsection{Алгоритм Борувки, использующий отсортированные списки смежности}
% 2.6   Планы по алгоритму два
% TODO
%Альтернативная параллельная реализация построения MST так же основана на алгоритме Борувки, но для хранения рёбер используются списки смежности для каждой компоненты. 
Наибольшая вычислительная сложность первого алгоритма заключается в первом шаге, в котором необходимо обойти б\`oльшую часть рёбер графа, однако, основным препятствием для хорошей масштабируемости является то, что размер массива, редуцируемого на втором шаге, увеличивается с ростом количества потоков.

Первая реализация алгоритма Борувки для хранения рёбер использует списки смежности. 
Изначально множество вершин графа разделяется между потоками равномерно по количеству инцидентных рёбер.
Затем для каждой вершины сортируется список инцидентных ей рёбер по увеличению веса и 
таким образом получить самое лёгкое ребро, инцидентное вершине, возможно за $O(1)$, не выполняя проход по массиву.
Далее на каждой итерации алгоритма Борувки выполняются следующие шаги, пока не останется одна компонента:
\begin{enumerate}
    \item \textit{Минимальное инцидентное ребро}.
        Для каждой компоненты берётся инцидентное ей ребро минимального веса. Как отмечено выше, это будет первое ребро из списка смежности.
    \item \textit{Объединение деревьев (1)}.
          Для каждой компоненты определяется её номер на следующей итерации.
          Так же решается проблема с возможными циклами (когда более двух компонент по кругу выберут следующую в качестве ближайшей), которые возможны в алгоритме Борувки при наличии рёбер одинакового веса.
    \item \textit{Объединение деревьев (2)}.
          Осуществляется перенумерация компонент: для каждой вершины вычисляется номер компоненты, в которую она входит, используя параллельный алгоритм Pointer Jumping \cite{pointer-jumping}.
    \item \textit{Слияние списков}.
        Происходит объединение компонент путём слияния списка рёбер. 
        Поскольку, списки уже отсортированы по возрастанию веса, то возможно слияние, при котором в результате так же будет получен отсортированный список, с сохранением линейного времени работы.
    \item \textit{Перенумерация}.
        Обход списков рёбер и перенумерация компонент: старые номера заменяются на новые, полученные на шаге \textit{Объединения деревьев}.
\end{enumerate}

В ходе анализа работы шага \textit{Объединение деревьев} на тестируемых типах графов было выяснено, что количество объединяемых компонент в одну в большинстве случаев не превосходит трёх и это позволяет быстро и эффективно отсеивать петли на шаге \textit{Слияния списков} за счёт сокращения нерегулярных обращений в память.

\subsection{Алгоритм Борувки, использующий неотсортированные списки смежности}

% TODO ударения в слове большИх
Поддержка списков смежности отсортированными при слиянии требует больших временных затрат и несмотря на получившийся выигрыш в первом шаге, общее время выполнение алгоритма увеличилось.
В связи с этим было решено отказаться от поддержания списков отсортированными. Таким образом, поиск минимума на первом шаге осуществляется обходом всего списка, но объединение списков стало возможно простым копированием.

Общая схема алгоритма осталась прежней, однако, реализация шага поиска минимального ребра и слияния списков значительно изменилась:
\begin{enumerate}
    \item \textit{Минимальное инцидентное ребро}.
        Для каждой компоненты находится инцидентное ей ребро минимального веса простым линейным поиском.
    \item \textit{Объединение деревьев}.
        Объединение компонент, для каждой компоненты определяется её номер на следующей итерации. 
        Аналогично шагам \textit{Объединение деревьев 1-2} в первом алгоритме.
    \item \textit{Слияние списков}.
        Происходит объединение компонент путём объединения списка рёбер.
    \item \textit{Перенумерация}.
        Обход списков рёбер и перенумерация компонент: старые номера заменяются на новые, полученные на шаге \textit{Объединения деревьев}.
\end{enumerate}

\subsection{Алгоритм Борувки, использующий списки вершин}

% TODO ударения в слове большИх
Основная проблема при реализации алгоритма Борувки, явно строящих список инцидентных рёбер каждой компоненты перед каждой итерации заключается в большом объёме копируемых на каждой итерации данных. С целью уменьшить данный объём и ускорить шаг слияния списков было решено для каждой компоненты хранить не список инцидентных рёбер, а список входящих в неё вершин.

Общая схема алгоритма осталась прежней со следующими изменениями:
\begin{enumerate}
    \item На шаге \textit{минимальное инцидентное ребро} теперь для обхода рёбер требуется обойти не список рёбер, а список входящих в компоненту вершин и уже для каждой вершины обойти список инцидентных ей рёбер.
    \item На шаге \textit{слияние списков} теперь копируются не списки рёбер, а списки вершин, что значительно сокращает объём перемещаемых данных.
\end{enumerate}

Для хранения списка вершин были опробованы две структуры данных:
\begin{itemize}
	\item \textbf{Односвязные списки}. Их преимущество заключается в возможности объединения за константное время, однако, обход таких списков связан со случайными обращениями в память.
	\item \textbf{Динамические массивы}. Объединение массивов возможно только за линейное время путём копирования одного из них в другой (на практике используется копирование меньшего массива в больший). Но во время обхода массива хорошо работает аппаратная предвыборка, что позволяет в значительной степени избежать кэш-промахов.
\end{itemize}
Данные модификации показывали примерно одинаковую производительность, однако, в среднем реализация с использованием динамических массивов оказалась на 5-10\% быстрее.

В данном подходе имеется две существенные проблемы. Первая из них заключается в том, что шаг \textit{слияния списков} выполняется по-прежнему долго, хотя и значительно быстрее, чем в предыдущих реализациях.
Вторая проблема лежит в том, что при распределении компонент между потоками происходит дисбаланс нагрузки на последних итерациях, когда количество оставшихся компонент становится меньше числа потоков --- в этом случае некоторые потоки просто простаивают без работы, что негативно сказывается на масштабируемости алгоритма. В качестве решения проблемы шаг \textit{минимальное инцидентное ребро} был разделён на два: сначала выделяются компонент с небольшим количеством входящих в них вершин и обрабатываются как и раньше, затем остаются компоненты, состоящие из большого числа вершин, и работа по таким компонентам разделяется между потоками. Данная оптимизация улучшила производительность алгоритма и позволила получить ускорение на 2 сокетах.

\subsection{Алгоритм Борувки, использующий массив рёбер}

Поскольку за счёт предыдущей модификации полностью решить проблему копирования больших объёмов данных не удалось, то следующий алгоритм разрабатывался с целью полностью избежать перемещения списков рёбер или вершин после каждой итерации.
Если ранее использовался подход, когда для каждой компонента хранилась информация, позволявшая восстановить список инцидентных рёбер, то теперь будет хранится информация для каждой вершины о том, какой компоненте она принадлежит.

Изначально все вершины распределяются между потоками равномерно по количеству рёбер. Далее на каждой итерации алгоритма Борувки выполняются следующие шаги:

\begin{enumerate}
    \item \textit{Минимальное инцидентное ребро}.
		Каждый поток обходит все свои вершины и находит минимально ребро для всех компонент, которые представлены в данном потоке хотя бы одной вершиной.
        В результате каждый поток будет иметь массив, содержащий минимальное ребро для каждой компоненты среди просмотренного подмножества.
    \item \textit{Редукция}.
          Происходит редукция: для каждой компоненты находится ребро минимального веса по всем потокам. 
          Таким образом, для каждой компоненты определяется минимальное ребро уже по всему графу.
    \item \textit{Объединение деревьев}.
          Для каждой компоненты определяется её номер на следующей итерации.
          Так же решается проблема с возможными циклами (когда более двух компонент по кругу выберут следующую в качестве ближайшей), которые возможны в алгоритме Борувки при наличии рёбер одинакового веса.
    \item \textit{Перенумерация}.
          Осуществляется перенумерация компонент: для каждой вершины вычисляется номер компоненты, в которую она входит, используя параллельный алгоритм Pointer Jumping \cite{pointer-jumping}.
\end{enumerate}

Основная проблема данного подхода заключается в шаге \textit{редукции}: объём редуцируемого массива растёт линейно с ростом числа потоков, таким образом, среднее время выполнения данного почти не уменьшается с ростом количества потоков.
Однако, даже с описанной проблемой подход с уменьшением объёма копируемых данных себя оправдал и данная реализации показала лучшие результаты производительности среди описанных алгоритмов.

%\newpage
%\section{Результаты}
% 2.5   На чём проводилось тестирование
% 2.5.1 Параметры графов
%Тестирование проводилась на графах, состоящих из $10^6-10^8$ вершин и $10^7-10^9$ рёбер: это RMAT-графы %степени $20\,-\,23$, двумерные и трёхмерные решётки, а так же случайные графы.

% 2.5.2 Характеристика систем
%Характеристики систем, на которых производились запуски:
%\begin{itemize}
%    \item 2 $\times$ Intel Xeon CPU E5-2690 (8 ядер 2.9 GHz, 32KB L1 cache, 256KB L2 cache, 20MB L3 cache)
%    \item 8 $\times$ Intel Xeon CPU Е7-4870 (10 ядер 2.4 GHz, 32KB L1 cache, 256KB L2 cache, 30MB L3 cache)
%\end{itemize}

%[Позже будут добавлены результаты тестирования двух описанных алгоритмов].

\newpage
\section{Оптимизации реализации с массивом рёбер}

\subsection{Алгоритмические оптимизации}

\textbf{Предварительная сортировка рёбер.}
Алгоритм Борувки предполагает на каждой итерации просмотр всех рёбер графа, что и создаёт наибольшую вычислительную сложность первого шага.
Объём ``лишней'' работы при этом достаточно велик: во-первых, постоянно будет просматриваться большое количество петель, которых с каждой итерацией становится всё больше и больше, во-вторых, почти все рёбра, не являющиеся петлями, будут отбрасываться  как более тяжёлые.


Проблему с петлями возможно попытаться решить их удалением, однако, это повлечёт за собой частичное перестроение структуры графа, что, как было выявлено в ходе исследования, негативно сказывается на производительности.

Решить обе обозначенные проблемы возможно за счёт предварительной сортировки списков смежности каждой вершины по возрастанию веса рёбер. Затем для каждой вершины хранится индекс последнего просмотренного ребра: изначальной данный индекс указывает на первое ребро в списке, затем, по мере отбрасывания петель, он сдвигается и на следующей итерации поиск минимального ребра начинается не с начала списка, а с позиции, на которую указывает индекс. С другой стороны, если мы берём очередное ребро и его вес больше, чем текущий рекорд для компоненты, то поиск можно прервать, так как вес последующих рёбер данной вершины заведомо больше текущего рекорда.

Данная оптимизация хорошо масштабируется и на большом количестве потоков время выполнения невелико. В среднем производительность от данной оптимизации увеличивается на 20\%.



\textbf{Переупорядочивание вершин.}
Вершины перенумеровывались в порядке обхода в ширину с предварительной отсортировкой списков смежности каждой вершины по возрастанию степени вершины, в которую ведёт ребро. Переупорядочивание вершин позволяет повысить локальность данных при последующих обходах графа \cite{sparse-matrix-renum} и, как следствие, ведёт к уменьшению кэш-промахов.


\textbf{Балансировка больших вершин.}
Одной из особенностей RMAT-графов являет наличие вершин, степень которых значительно отличается от средней степени всех вершин графа. Такие вершины создают дисбаланс на последних итерациях, когда просматривается большое количество рёбер и отбрасываются петли.

С целью устранения данного дисбаланса на стадии предобработки графа выделяются вершины степени более 1000 и равномерно распределяются между потоками. Значение степени 1000 было подобрано эмпирически и хорошо показало себя на практике.

В среднем оптимизации \textbf{переупорядочивания вершин} и \textbf{балансировки больших вершин} дают увеличение производительности в 11\%.






\subsection{Оптимизация редукции}

Поскольку основные проблемы масштабируемости лежат именно в шаге редукции, то было сделано несколько оптимизаций, непосредственно затрагивающих данный шаг. Оценки увеличения производительности получены при запуске 32 потоков на всех 16 ядрах процессоров и показывают ускорение.

\textbf{Отсутствие редукции на первой итерации.}
Поскольку каждая компонента изначально представлена одной вершиной, то от редукции на первой итерации можно отказаться. Данная оптимизация выглядит простой и очевидной, однако, объём редуцируемого массива на первой итерации больше, чем на всех следующих, и данная модификация даёт ускорение в 20\%.

\textbf{Перенумерация и сжатие массива компонент по ходу исполнения алгоритма.}
В начальной реализации при объединении компонент в качестве её номера выбирался один из номеров вершин, которые в неё входят. Таким образом, несмотря на сокращение числа компонент, диапазон используемых номеров не изменялся (минимальный и максимальный номер были приблизительно равны соответственно первой и последней вершине). Такой подход затруднял обход всех компонент на шаге редукции: требовалось либо обходить весь диапазон номеров и совершать лишнюю работу, просматривая ``пустые'' номера, не являющиеся компонентами, либо отдельно поддерживать массив, в которым хранить индексы всех ``живых'' на данный момент компонент, что усложняло реализацию и приводило к увеличению кэш-промахов из-за обхода массива с непостоянным шагом.

Явная перенумерация компонент на последовательные номера позволила решить обозначенную проблему. В среднем производительность увеличилась на 20\%.

Более того, это позволило уменьшить объём используемой памяти: в начальной реализации для каждого потока создавался двумерный массив размера \texttt{количество\_потоков}$\times$\texttt{количество\_вершин}
На системах с больш\`{и}м количеством ядер, например, на Intel Xeon Phi, где используется до 240 потоков, объём такого массива заметно превосходит объём всех других данных и его сокращение в 2 раза приводит к значительному уменьшению потребляемой памяти.

\textbf{Иерархическая редукция.}
Особенностью NUMA архитектуры являются высокие задержки при обращении в память другого узла NUMA.
При стандартном подходе к редукции, когда для каждой компоненты последовательно обходятся все потоки и выбирается лучший результат, таких обращений при двух NUMA узлах будет как минимума, а при большем количестве узлов NUMA --- ещё больше.

Данную проблему можно решить за счёт иерархического подхода к редукции. При таком подходе шаг редукции разбивается на два этапа: на первом происходит стандартная редукция внутри NUMA узла, а на втором  --- между узлами. Количество обращений к чужому узлу NUMA в этом случае уменьшается в количество раз, равное количеству используемых потоков в одном узле NUMA. В результате иерархическая редукция повысила производительность на 5\%.


\subsection{Архитектурные оптимизации}

\textbf{Программная предвыборка.}
Обход рёбер в общем случае неизбежно связан со случайными обращениями в память: невозможно отсортировать рёбра так, чтобы индексы обеих инцидентных вершин шли последовательно.
Аппаратная предвыборка современных процессоров ориентирована только на последовательные обращения в память (точнее, на обход с постоянным, возможно отрицательным, шагом, размер которого не превосходит размер страницы памяти) и подобный обход рёбер вызывает простои, связанные с ожиданием данных.

Однако, адреса случайны обращений в память при таких обходах в большинстве случаев можно предсказать: обходя рёбра последовательно, нам известны индексы вершин для следующих итераций. Как раз в таком случае и помогает программная предвыборка, давая возможность заранее запросить нужные данные для будущих вершин (например, какой компоненте они принадлежат) и сократить время ожидания.

Другой особенностью аппаратной предвыборки является то, что данные не всегда загружаются в кэш первого уровня (например, на Intel Xeon Phi).




\textbf{Выделение памяти с учётом NUMA архитектуры}
Как уже отмечалось ранее, обращение в память другого узла NUMA связано с высокими задержками. Выделение памяти на тех ядрах, где она используется, является более правильным на NUMA архитектуре.

В случае использования двумерных массивов, когда первая размерность соответствует номеру потока (например, массив в котором хранится текущий лучший результат для каждой компоненты), основной интерес представляет вторая размерность, поскольку к первой будет только одно обращение за итерацию, а ко второй --- на каждой вершине. Таким образом, первая размерность выделяется на произвольном узле NUMA, а затем каждой поток выделяет необходимую ему память.

Когда одномерный массив одновременно использует несколько потоков (например,  массив рёбер), то возникает необходимость выделить непрерывную область в памяти на разных узлах NUMA. Ядро Linux предоставляет разработчику возможность явно управлять выделением страниц памяти на NUMA системах с использованием libnuma. Однако, в реализациях использовалась особенность ядра Linux известная как memory overcommit: выделение страниц памяти происходит не в момент вызова функции malloc, а в момент первого обращения к странице. Таким образом, для разделения массива по узлам NUMA сначала с использованием функции malloc выделялся весь, далее, каждый поток инициализировал те страницы, которые он будет использовать. При таком подходе, конечно же, может возникнуть пересечение, когда два потока используют одну страницу, но размеры таких пересечений невелики по сравнению с размером всего массива.

Был также опробован подход с дублированием массива, который используют одновременно несколько узлов NUMA. Одним из примеров таких данных является массив, где для каждой вершины хранится индекс компоненты, в которую она входит на данный момент. Однако, из-за необходимости после каждой итерации дополнительно обновлять массив на каждом узле NUMA данный подход себя не оправдал.



\textbf{Аппаратные потоки процессора.}
Современные процессоры позволяют на одном ядре исполнять одновременно несколько аппаратных потоков. . Использование такого вида многозадачности позволяет не только более эффективно использовать процессорные компоненты, но и скрыть задержки в память.

Проблема использования аппаратных потоков для EA-реализации заключается в увеличении объёма шага редукции. В начальных реализациях использование Hyper-Threading давало небольшое ускорение на малом количестве потоков, но ухудшало время на 16 потоках. После применения описанных выше оптимизаций редукции Hyper-Threading стал давать выигрыш в среднем 5\%.





\newpage
\section{Заключение}

На данный момент исследованы последовательные алгоритмы построения минимальных остовных деревьев. Были получены их последовательные реализации с целью дальнейшего распараллеливания, а так же использования для проверки корректности результата. Проведена оценка данных алгоритмов с точки зрения распараллеливания: были выявлены алгоритмы, которые пригодны для распараллеливания в своей оригинальной реализации и алгоритмы, эффективно распараллелить которые в их оригинальной реализации не представляется возможным, однако, возможны модификации данных алгоритмов, реализации которых всё-таки могут быть эффективно распараллелены. Так же изучены статьи  \cite{dense-mst,boruvka-prima,boruvka-cm5} по распараллеливанию последовательных алгоритмов, изучены предлагаемые в данных статьях структуры для хранения внутреннего представления графа.

Далее была проделана работа по распараллеливанию алгоритмов. Был выбран алгоритм Борувки и распараллелен в нескольких реализациях, использующих различные структуры данных для хранения графа: отсортированные и неотсортированные списки смежности для каждой компоненты, список вершин для каждой компоненты, где в качестве списков были опробованы как и односвязные списки, так и динамические массивы, и исходный массив, когда входной граф не модифицируется по ходу исполнения алгоритма.

Выполнены оптимизации различных этапов алгоритма с целью увеличения масштабируемости и повышения производительности реализаций. Были сделаны как и алгоритмические оптимизации, уменьшающие вычислительную сложность отдельных шагов алгоритма, так и архитектурные оптимизации, позволяющие более эффективно использовать ресурсы памяти и процессора.

Полученная реализация была протестирована на различных больших графах (графы, объём данных которых заметно превышает объём кэша процессора). Результаты тестирования показали, что реализация показывает хорошую масштабируемость на больших графах на 32 потоках на центральном процессоре и на 180 потоках на ускорителе Intel Xeon Phi.


\newpage
\bibliographystyle{unsrt}
\bibliography{conference}

\end{document}
